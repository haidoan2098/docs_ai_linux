# **INTERPROCESS COMMUNICATION OVERVIEW**

This chapter presents a brief overview of the facilities that processes and threads can use to communicate with one another and to synchronize their actions. The following chapters provide more details about these facilities.

## **43.1 A Taxonomy of IPC Facilities**

[Figure 43-1](#page-1-0) summarizes the rich variety of UNIX communication and synchronization facilities, dividing them into three broad functional categories:

-  Communication: These facilities are concerned with exchanging data between processes.
-  Synchronization: These facilities are concerned with synchronizing the actions of processes or threads.
-  Signals: Although signals are intended primarily for other purposes, they can be used as a synchronization technique in certain circumstances. More rarely, signals can be used as a communication technique: the signal number itself is a form of information, and realtime signals can be accompanied by associated data (an integer or a pointer). Signals are described in detail in Chapters 20 to 22.

Although some of these facilities are concerned with synchronization, the general term interprocess communication (IPC) is often used to describe them all.

```
communication
├─ data transfer
│  ├─ byte stream
│  │  ├─ pipe
│  │  ├─ FIFO
│  │  └─ stream socket
│  ├─ pseudoterminal
│  └─ message
│     ├─ System V message queue
│     ├─ POSIX message queue
│     └─ datagram socket
├─ shared memory
│  ├─ System V shared memory
│  ├─ POSIX shared memory
│  └─ memory mapping
│     ├─ anonymous mapping
│     └─ mapped file
signal
├─ standard signal
└─ realtime signal
synchronization
├─ semaphore
│  ├─ System V semaphore
│  └─ POSIX semaphore
│     ├─ named
│     └─ unnamed
├─ file lock
│  ├─ "record" lock (fcntl())
│  └─ file lock (flock())
├─ mutex (threads)
└─ condition variable (threads)
```

<span id="page-1-0"></span>**Figure 43-1:** A taxonomy of UNIX IPC facilities

As [Figure 43-1](#page-1-0) illustrates, often several facilities provide similar IPC functionality. There are a couple of reasons for this:

-  Similar facilities evolved on different UNIX variants, and later came to be ported to other UNIX systems. For example, FIFOs were developed on System V, while (stream) sockets were developed on BSD.
-  New facilities have been developed to address design deficiencies in similar earlier facilities. For example, the POSIX IPC facilities (message queues, semaphores, and shared memory) were designed as an improvement on the older System V IPC facilities.

In some cases, facilities that are grouped together in [Figure 43-1](#page-1-0) actually provide significantly different functionality. For example, stream sockets can be used to communicate over a network, while FIFOs can be used only for communication between processes on the same machine.

## **43.2 Communication Facilities**

The various communication facilities shown in [Figure 43-1](#page-1-0) allow processes to exchange data with one another. (These facilities can also be used to exchange data between the threads of a single process, but this is seldom necessary, since threads can exchange information via shared global variables.)

We can break the communication facilities into two categories:

-  Data-transfer facilities: The key factor distinguishing these facilities is the notion of writing and reading. In order to communicate, one process writes data to the IPC facility, and another process reads the data. These facilities require two data transfers between user memory and kernel memory: one transfer from user memory to kernel memory during writing, and another transfer from kernel memory to user memory during reading. [\(Figure 43-2](#page-2-0) shows this situation for a pipe.)
-  Shared memory: Shared memory allows processes to exchange information by placing it in a region of memory that is shared between the processes. (The kernel accomplishes this by making page-table entries in each process point to the same pages of RAM, as shown in [Figure 49-2](#page-149-0), on page [1026](#page-149-0).) A process can make data available to other processes by placing it in the shared memory region. Because communication doesn't require system calls or data transfer between user memory and kernel memory, shared memory can provide very fast communication.

```
                    ┌─────────────────────────────────┐
                    │         KERNEL SPACE            │
                    │                                 │
           write()  │         ┌─────────────┐         │   read()
             |----------─────►│ pipe buffer │------------------|
             |      │         └──────-──────┘         │        |
             |      │                                 │        |
             |      └────────────────-────────────────┘        |
   ─ ─ ─ ─ ─ | ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ |---─
             |       USER SPACE                                |
             |                                                 |
  ┌──────────|───────────┐                       ┌─────────────v────────┐
  │  Process A buffer    │                       │  Process B buffer    │
  │                      │                       │                      │
  └──────────--──────────┘                       └──────────-───────────┘
            
```

<span id="page-2-0"></span>**Figure 43-2:** Exchanging data between two processes using a pipe

### **Data transfer**

We can further break data-transfer facilities into the following subcategories:

 Byte stream: The data exchanged via pipes, FIFOs, and datagram sockets is an undelimited byte stream. Each read operation may read an arbitrary number of bytes from the IPC facility, regardless of the size of blocks written by the writer. This model mirrors the traditional UNIX "file as a sequence of bytes" model.

-  Message: The data exchanged via System V message queues, POSIX message queues, and datagram sockets takes the form of delimited messages. Each read operation reads a whole message, as written by the writer process. It is not possible to read part of a message, leaving the remainder on the IPC facility; nor is it possible to read multiple messages in a single read operation.
-  Pseudoterminals: A pseudoterminal is a communication facility intended for use in specialized situations. We provide details in Chapter 64.

A few general features distinguish data-transfer facilities from shared memory:

 Although a data-transfer facility may have multiple readers, reads are destructive. A read operation consumes data, and that data is not available to any other process.

> The MSG\_PEEK flag can be used to perform a nondestructive read from a socket (Section 61.3). UDP (Internet domain datagram) sockets allow a single message to be broadcast or multicast to multiple recipients (Section 61.12).

 Synchronization between the reader and writer processes is automatic. If a reader attempts to fetch data from a data-transfer facility that currently has no data, then (by default) the read operation will block until some process writes data to the facility.

## **Shared memory**

Most modern UNIX systems provide three flavors of shared memory: System V shared memory, POSIX shared memory, and memory mappings. We consider the differences between them when describing the facilities in later chapters (see Section 54.5 in particular).

Note the following general points about shared memory:

-  Although shared memory provides fast communication, this speed advantage is offset by the need to synchronize operations on the shared memory. For example, one process should not attempt to access a data structure in the shared memory while another process is updating it. A semaphore is the usual synchronization method used with shared memory.
-  Data placed in shared memory is visible to all of the processes that share that memory. (This contrasts with the destructive read semantics described above for data-transfer facilities.)

## **43.3 Synchronization Facilities**

The synchronization facilities shown in [Figure 43-1](#page-1-0) allow processes to coordinate their actions. Synchronization allows processes to avoid doing things such as simultaneously updating a shared memory region or the same part of a file. Without synchronization, such simultaneous updates could cause an application to produce incorrect results.

UNIX systems provide the following synchronization facilities:

-  Semaphores: A semaphore is a kernel-maintained integer whose value is never permitted to fall below 0. A process can decrease or increase the value of a semaphore. If an attempt is made to decrease the value of the semaphore below 0, then the kernel blocks the operation until the semaphore's value increases to a level that permits the operation to be performed. (Alternatively, the process can request a nonblocking operation; then, instead of blocking, the kernel causes the operation to return immediately with an error indicating that the operation can't be performed immediately.) The meaning of a semaphore is determined by the application. A process decrements a semaphore (from, say, 1 to 0) in order to reserve exclusive access to some shared resource, and after completing work on the resource, increments the semaphore so that the shared resource is released for use by some other process. The use of a binary semaphore—a semaphore whose value is limited to 0 or 1—is common. However, an application that deals with multiple instances of a shared resource would employ a semaphore whose maximum value equals the number of shared resources. Linux provides both System V semaphores and POSIX semaphores, which have essentially similar functionality.
-  File locks: File locks are a synchronization method explicitly designed to coordinate the actions of multiple processes operating on the same file. They can also be used to coordinate access to other shared resources. File locks come in two flavors: read (shared) locks and write (exclusive) locks. Any number of processes can hold a read lock on the same file (or region of a file). However, when one process holds a write lock on a file (or file region), other processes are prevented from holding either read or write locks on that file (or file region). Linux provides file-locking facilities via the flock() and fcntl() system calls. The flock() system call provides a simple locking mechanism, allowing processes to place a shared or an exclusive lock on an entire file. Because of its limited functionality, flock() locking facility is rarely used nowadays. The fcntl() system call provides record locking, allowing processes to place multiple read and write locks on different regions of the same file.
-  Mutexes and condition variables: These synchronization facilities are normally used with POSIX threads, as described in Chapter 30.

Some UNIX implementations, including Linux systems with a glibc that provides the NPTL threading implementation, also allow mutexes and condition variables to be shared between processes. SUSv3 permits, but doesn't require, an implementation to support process-shared mutexes and condition variables. They are not available on all UNIX systems, and so are not commonly employed for process synchronization.

When performing interprocess synchronization, our choice of facility is typically determined by the functional requirements. When coordinating access to a file, file record locking is usually the best choice. Semaphores are often the better choice for coordinating access to other types of shared resource.

Communication facilities can also be used for synchronization. For example, in Section [44.3,](#page-20-0) we show how a pipe can be used to synchronize the actions of a parent process with its children. More generally, any of the data-transfer facilities can be used for synchronization, with the synchronization operation taking the form of exchanging messages via the facility.

> Since kernel 2.6.22, Linux provides an additional, nonstandard synchronization mechanism via the eventfd() system call. This system call creates an eventfd object that has an associated 8-byte unsigned integer maintained by the kernel. The system call returns a file descriptor that refers to the object. Writing an integer to this file descriptor adds that integer to the object's value. A read() from the file descriptor blocks if the object's value is 0. If the object has a nonzero value, a read() returns that value and resets it to 0. In addition, poll(), select(), or epoll can be used to test if the object has a nonzero value; if it does, the file descriptor indicates as being readable. An application that wishes to use an eventfd object for synchronization must first create the object using eventfd(), and then call fork() to create related processes that inherit file descriptors referring to the object. For further details, see the eventfd(2) manual page.

# **43.4 Comparing IPC Facilities**

When it comes to IPC, we face a range of choices that can at first seem bewildering. In later chapters that describe each IPC facility, we include sections that compare each facility against other similar facilities. In the following pages, we consider a number of general points that may determine the choice of IPC facility.

## **IPC object identification and handles for open objects**

In order to access an IPC object, a process must have some means of identifying the object, and once the object has been "opened," the process must use some type of handle to refer to the open object. [Table 43-1](#page-5-0) summarizes these properties for the various types of IPC facilities.

<span id="page-5-0"></span>**Table 43-1:** Identifiers and handles for various types of IPC facilities

| Facility type           | Name used to<br>identify object | Handle used to refer to<br>object in programs |
|-------------------------|---------------------------------|-----------------------------------------------|
| Pipe                    | no name                         | file descriptor                               |
| FIFO                    | pathname                        | file descriptor                               |
| UNIX domain socket      | pathname                        | file descriptor                               |
| Internet domain socket  | IP address + port number        | file descriptor                               |
| System V message queue  | System V IPC key                | System V IPC identifier                       |
| System V semaphore      | System V IPC key                | System V IPC identifier                       |
| System V shared memory  | System V IPC key                | System V IPC identifier                       |
| POSIX message queue     | POSIX IPC pathname              | mqd_t (message queue descriptor)              |
| POSIX named semaphore   | POSIX IPC pathname              | sem_t * (semaphore pointer)                   |
| POSIX unnamed semaphore | no name                         | sem_t * (semaphore pointer)                   |
| POSIX shared memory     | POSIX IPC pathname              | file descriptor                               |
| Anonymous mapping       | no name                         | none                                          |
| Memory-mapped file      | pathname                        | file descriptor                               |
| flock() lock            | pathname                        | file descriptor                               |
| fcntl() lock            | pathname                        | file descriptor                               |

### **Functionality**

There are functional differences between the various IPC facilities that can be relevant in determining which facility to use. We begin by summarizing the differences between data-transfer facilities and shared memory:

-  Data-transfer facilities involve read and write operations, with transferred data being consumable by just one reader process. Flow control between writer and reader, as well as synchronization (so that a reader is blocked when trying to read data from a facility that is currently empty) is automatically handled by the kernel. This model fits well with many application designs.
-  Other application designs more naturally suit a shared-memory model. Shared memory allows one process to make data visible to any number of other processes sharing the same memory region. Communication "operations" are simple—a process can access data in shared memory in the same manner as it accesses any other memory in its virtual address space. On the other hand, the need to handle synchronization (and perhaps flow control) can add to the complexity of a shared-memory design. This model fits well with application designs that need to maintain shared state (e.g., a shared data structure).

With respect to the various data-transfer facilities, the following points are worth noting:

-  Some data-transfer facilities transfer data as a byte stream (pipes, FIFOs, and stream sockets); others are message-oriented (message queues and datagram sockets). Which approach is preferable depends on the application. (An application can also impose a message-oriented model on a byte-stream facility, by using delimiter characters, fixed-length messages, or message headers that encode the length of the total message; see Section [44.8.](#page-32-0))
-  A distinctive feature of System V and POSIX message queues, compared with other data-transfer facilities, is the ability to assign a numeric type or priority to a message, so that messages can be delivered in a different order from that in which they were sent.
-  Pipes, FIFOs, and sockets are implemented using file descriptors. These IPC facilities all support a range of alternative I/O models that we describe in Chapter 63: I/O multiplexing (the select() and poll() system calls), signaldriven I/O, and the Linux-specific epoll API. The primary benefit of these techniques is that they allow an application to simultaneously monitor multiple file descriptors to see whether I/O is possible on any of them. By contrast, System V message queues don't employ file descriptors and don't support these techniques.

On Linux, POSIX message queues are also implemented using file descriptors and support the alternative I/O techniques described above. However, this behavior is not specified in SUSv3, and is not supported on most other implementations.

 POSIX message queues provide a notification facility that can send a signal to a process, or instantiate a new thread, when a message arrives on a previously empty queue.

-  UNIX domain sockets provide a feature that allows a file descriptor to be passed from one process to another. This allows one process to open a file and make it available to another process that otherwise might not be able to access the file. We briefly describe this feature in Section 61.13.3.
-  UDP (Internet domain datagram) sockets allow a sender to broadcast or multicast a message to multiple recipients. We briefly describe this feature in Section 61.12.

With respect to process-synchronization facilities, the following points are worth noting:

-  Record locks placed using fcntl() are considered to be owned by the process placing the lock. The kernel uses this ownership property to detect deadlocks (situations where two or more processes are holding locks that block each other's further lock requests). If a deadlock situation occurs, the kernel denies the lock request of one of the processes, returning an error from the fcntl() call to indicate that a deadlock occurred. System V and POSIX semaphores don't have an ownership property; no deadlock detection occurs for semaphores.
-  Record locks placed using fcntl() are automatically released when the process that owns the locks terminates. System V semaphores provide a similar feature in the form of an "undo" feature, but this feature is not reliable in all circumstances (Section [47.8](#page-109-0)). POSIX semaphores don't provide an analog of this feature.

### **Network communication**

Of all of the IPC methods shown in [Figure 43-1,](#page-1-0) only sockets permit processes to communicate over a network. Sockets are generally used in one of two domains: the UNIX domain, which allows communication between processes on the same system, and the Internet domain, which allows communication between processes on different hosts connected via a TCP/IP network. Often, only minor changes are required to convert a program that uses UNIX domain sockets into one that uses Internet domain sockets, so an application that is built using UNIX domain sockets can be made network-capable with relatively little effort.

## **Portability**

Modern UNIX implementations support most of the IPC facilities shown in [Fig](#page-1-0)[ure 43-1.](#page-1-0) However, the POSIX IPC facilities (message queues, semaphores, and shared memory) are not quite as widely available as their System V IPC counterparts, especially on older UNIX systems. (An implementation of POSIX message queues and full support for POSIX semaphores have appeared on Linux only in the 2.6.x kernel series.) Therefore, from a portability point of view, System V IPC may be preferable to POSIX IPC.

## **System V IPC design issues**

The System V IPC facilities were designed independently of the traditional UNIX I/O model, and consequently suffer a few peculiarities that make their programming interfaces more complicated to use. The corresponding POSIX IPC facilities were designed to address these problems. The following points are of particular note:

-  The System V IPC facilities are connectionless. These facilities provide no notion of a handle (like a file descriptor) referring to an open IPC object. In later chapters, we'll sometimes talk of "opening" a System V IPC object, but this is really just shorthand to describe the process of obtaining a handle to refer to the object. The kernel does not record the process as having "opened" the object (unlike other types of IPC objects). This means that the kernel can't maintain a reference count of the number of processes that are currently using an object. Consequently, it can require additional programming effort for an application to be able to know when an object can safely be deleted.
-  The programming interfaces for the System V IPC facilities are inconsistent with the traditional UNIX I/O model (they use integer key values and IPC identifiers instead of pathnames and file descriptors). The programming interfaces are also overly complex. This last point applies particularly to System V semaphores (refer to Sections [47.11](#page-116-0) and 53.5).

By contrast, the kernel counts open references for POSIX IPC objects. This simplifies decisions about when an object can be deleted. Furthermore, the POSIX IPC facilities provide an interface that is simpler and more consistent with the traditional UNIX model.

### **Accessibility**

The second column of [Table 43-2](#page-9-0) summarizes an important characteristic of each type of IPC object: the permissions scheme that governs which processes can access the object. The following list adds some details on the various schemes:

-  For some IPC facilities (e.g., FIFOs and sockets), object names live in the file system, and accessibility is determined according to the associated file permissions mask, which specifies permissions for owner, group, and other (Section 15.4). Although System V IPC objects don't reside in the file system, each object has an associated permissions mask whose semantics are similar to those for files.
-  A few IPC facilities (pipes, anonymous memory mappings) are marked as being accessible only by related processes. Here, related means related via fork(). In order for two processes to access the object, one of them must create the object and then call fork(). As a consequence of the fork(), the child process inherits a handle referring to the object, allowing both processes to share the object.
-  The accessibility of a POSIX unnamed semaphore is determined by the accessibility of the shared memory region containing the semaphore.
-  In order to place a lock on a file, a process must have a file descriptor referring to the file (i.e., in practice, it must have permission to open the file).
-  There are no restrictions on accessing (i.e., connecting or sending a datagram to) an Internet domain socket. If necessary, access control must be implemented within the application.

<span id="page-9-0"></span>**Table 43-2:** Accessibility and persistence for various types of IPC facilities

| Facility type           | Accessibility                    | Persistence |
|-------------------------|----------------------------------|-------------|
| Pipe                    | only by related processes        | process     |
| FIFO                    | permissions mask                 | process     |
| UNIX domain socket      | permissions mask                 | process     |
| Internet domain socket  | by any process                   | process     |
| System V message queue  | permissions mask                 | kernel      |
| System V semaphore      | permissions mask                 | kernel      |
| System V shared memory  | permissions mask                 | kernel      |
| POSIX message queue     | permissions mask                 | kernel      |
| POSIX named semaphore   | permissions mask                 | kernel      |
| POSIX unnamed semaphore | permissions of underlying memory | depends     |
| POSIX shared memory     | permissions mask                 | kernel      |
| Anonymous mapping       | only by related processes        | process     |
| Memory-mapped file      | permissions mask                 | file system |
| flock() file lock       | open() of file                   | process     |
| fcntl() file lock       | open() of file                   | process     |

## **Persistence**

The term persistence refers to the lifetime of an IPC object. (Refer to the third column of [Table 43-2.](#page-9-0)) We can distinguish three types of persistence:

 Process persistence: A process-persistent IPC object remains in existence only as long as it is held open by at least one process. If the object is closed by all processes, then all kernel resources associated with the object are freed, and any unread data is destroyed. Pipes, FIFOs, and sockets are examples of IPC facilities with process persistence.

> The persistence of a FIFO's data is not the same as the persistence of its name. A FIFO has a name in the file system that persists even after all file descriptors referring to the FIFO have been closed.

-  Kernel persistence: A kernel-persistent IPC object exists until either it is explicitly deleted or the system is shut down. The lifetime of the object is independent of whether any process holds the object open. This means that, for example, one process can create an object, write data to it, and then close it (or terminate). At a later point, another process can open the object and read the data. Examples of facilities with kernel persistence are System V IPC and POSIX IPC. We exploit this property in the example programs that we present when describing these facilities in later chapters: for each facility, we implement separate programs that create an object, delete an object, and perform communication or synchronization.
-  File-system persistence: An IPC object with file-system persistence retains its information even when the system is rebooted. The object exists until it is explicitly deleted. The only type of IPC object that demonstrates file-system persistence is shared memory based on a memory-mapped file.

## **Performance**

In some circumstances, different IPC facilities may show notable differences in performance. However, in later chapters, we generally refrain from making performance comparisons, for the following reasons:

-  The performance of an IPC facility may not be a significant factor in the overall performance of an application, and it may not be the only factor in determining the choice of an IPC facility.
-  The relative performance of the various IPC facilities may vary across UNIX implementations or between different versions of the Linux kernel.
-  Most importantly, the performance of an IPC facility will vary depending on the precise manner and environment in which it is used. Relevant factors include the size of the data units exchanged in each IPC operation, the amount of unread data that may be outstanding on the IPC facility, whether or not a process context switch is required for each unit of data exchanged, and other load on the system.

If IPC performance is crucial, there is no substitute for application-specific benchmarks run under an environment that matches the target system. To this end, it may be worth writing an abstract software layer that hides details of the IPC facility from the application and then testing performance when different IPC facilities are substituted underneath the abstract layer.

## **43.5 Summary**

In this chapter, we provided an overview of various facilities that processes (and threads) can use to communicate with one another and to synchronize their actions.

Among the communication facilities provided on Linux are pipes, FIFOs, sockets, message queues, and shared memory. Synchronization facilities provided on Linux include semaphores and file locks.

In many cases, we have a choice of several possible techniques for communication and synchronization when performing a given task. In the course of this chapter, we compared the different techniques in various ways, with the aim of highlighting some differences that may influence the choice of one technique over another.

In the following chapters, we go into each of the communication and synchronization facilities in much more detail.

## **43.6 Exercises**

**43-1.** Write a program that measures the bandwidth provided by pipes. As commandline arguments, the program should accept the number of data blocks to be sent and the size of each data block. After creating a pipe, the program splits into two process: a child that writes the data blocks to the pipe as fast as possible, and a parent that reads the data blocks. After all data has been read, the parent should print the elapsed time required and the bandwidth (bytes transferred per second). Measure the bandwidth for different data block sizes.

**43-2.** Repeat the preceding exercise for System V message queues, POSIX message queues, UNIX domain stream sockets, and UNIX domain datagram sockets. Use these programs to compare the relative performance of the various IPC facilities on Linux. If you have access to other UNIX implementations, perform the same comparisons on those systems.

# **PIPES AND FIFOS**

This chapter describes pipes and FIFOs. Pipes are the oldest method of IPC on the UNIX system, having appeared in Third Edition UNIX in the early 1970s. Pipes provide an elegant solution to a frequent requirement: having created two processes to run different programs (commands), how can the shell allow the output produced by one process to be used as the input to the other process? Pipes can be used to pass data between related processes (the meaning of related will become clear later). FIFOs are a variation on the pipe concept. The important difference is that FIFOs can be used for communication between any processes.

# **44.1 Overview**

Every user of the shell is familiar with the use of pipes in commands such as the following, which counts the number of files in a directory:

\$ **ls | wc -l**

In order to execute the above command, the shell creates two processes, executing ls and wc, respectively. (This is done using fork() and exec(), which are described in Chapters 24 and 27.) [Figure 44-1](#page-13-0) shows how the two processes employ the pipe.

Among other things, [Figure 44-1](#page-13-0) is intended to illustrate how pipes got their name. We can think of a pipe as a piece of plumbing that allows data to flow from one process to another.

```
                                      pipe
  +------+                    +------------------+                    +------+
  |  ls  |  ───────────────►  |                  │  ───────────────►  |  wc  |
  |stdout│                    | byte stream;     │                    │stdin │
  |(fd 1)│                    | unidirectional   │                    │(fd 0)│
  +------+                    +------------------+                    +------+
                                  │         │
                            write end    read end
                            of pipe     of pipe
```

<span id="page-13-0"></span>Figure 44-1: Using a pipe to connect two processes

One point to note in Figure 44-1 is that the two processes are connected to the pipe so that the writing process (ls) has its standard output (file descriptor 1) joined to the write end of the pipe, while the reading process (wc) has its standard input (file descriptor 0) joined to the read end of the pipe. In effect, these two processes are unaware of the existence of the pipe; they just read from and write to the standard file descriptors. The shell must do some work in order to set things up in this way, and we see how this is done in Section 44.4.

In the following paragraphs, we cover a number of important characteristics of pipes.

#### A pipe is a byte stream

When we say that a pipe is a byte stream, we mean that there is no concept of messages or message boundaries when using a pipe. The process reading from a pipe can read blocks of data of any size, regardless of the size of blocks written by the writing process. Furthermore, the data passes through the pipe sequentially—bytes are read from a pipe in exactly the order they were written. It is not possible to randomly access the data in a pipe using *lseek()*.

If we want to implement the notion of discrete messages in a pipe, we must do this within our application. While this is feasible (refer to Section 44.8), it may be preferable to use alternative IPC mechanisms, such as message queues and datagram sockets, which we discuss in later chapters.

## Reading from a pipe

Attempts to read from a pipe that is currently empty block until at least one byte has been written to the pipe. If the write end of a pipe is closed, then a process reading from the pipe will see end-of-file (i.e., *read()* returns 0) once it has read all remaining data in the pipe.

## Pipes are unidirectional

Data can travel only in one direction through a pipe. One end of the pipe is used for writing, and the other end is used for reading.

On some other UNIX implementations—notably those derived from System V Release 4—pipes are bidirectional (so-called *stream pipes*). Bidirectional pipes are not specified by any UNIX standards, so that, even on implementations where they are provided, it is best to avoid reliance on their semantics. As an alternative, we can use UNIX domain stream socket pairs (created using the *socketpair()* system call described in Section 57.5), which provide a standardized bidirectional communication mechanism that is semantically equivalent to stream pipes.

## **Writes of up to PIPE\_BUF bytes are guaranteed to be atomic**

If multiple processes are writing to a single pipe, then it is guaranteed that their data won't be intermingled if they write no more than PIPE\_BUF bytes at a time.

SUSv3 requires that PIPE\_BUF be at least \_POSIX\_PIPE\_BUF (512). An implementation should define PIPE\_BUF (in <limits.h>) and/or allow the call fpathconf(fd, \_PC\_PIPE\_BUF) to return the actual upper limit for atomic writes. PIPE\_BUF varies across UNIX implementations; for example, it is 512 bytes on FreeBSD 6.0, 4096 bytes on Tru64 5.1, and 5120 bytes on Solaris 8. On Linux, PIPE\_BUF has the value 4096.

When writing blocks of data larger than PIPE\_BUF bytes to a pipe, the kernel may transfer the data in multiple smaller pieces, appending further data as the reader removes bytes from the pipe. (The write() call blocks until all of the data has been written to the pipe.) When there is only a single process writing to a pipe (the usual case), this doesn't matter. However, if there are multiple writer processes, then writes of large blocks may be broken into segments of arbitrary size (which may be smaller than PIPE\_BUF bytes) and interleaved with writes by other processes.

The PIPE\_BUF limit affects exactly when data is transferred to the pipe. When writing up to PIPE\_BUF bytes, write() will block if necessary until sufficient space is available in the pipe so that it can complete the operation atomically. When more than PIPE\_BUF bytes are being written, write() transfers as much data as possible to fill the pipe, and then blocks until data has been removed from the pipe by some reading process. If such a blocked write() is interrupted by a signal handler, then the call unblocks and returns a count of the number of bytes successfully transferred, which will be less than was requested (a so-called partial write).

> On Linux 2.2, pipe writes of any size are atomic, unless interrupted by a signal handler. On Linux 2.4 and later, any write greater than PIPE\_BUF bytes may be interleaved with writes by other processes. (The kernel code implementing pipes underwent substantial changes between kernel versions 2.2 and 2.4.)

## **Pipes have a limited capacity**

A pipe is simply a buffer maintained in kernel memory. This buffer has a maximum capacity. Once a pipe is full, further writes to the pipe block until the reader removes some data from the pipe.

SUSv3 makes no requirement about the capacity of a pipe. In Linux kernels before 2.6.11, the pipe capacity is the same as the system page size (e.g., 4096 bytes on x86-32); since Linux 2.6.11, the pipe capacity is 65,536 bytes. Other UNIX implementations have different pipe capacities.

In general, an application never needs to know the exact capacity of a pipe. If we want to prevent the writer process(es) from blocking, the process(es) reading from the pipe should be designed to read data as soon as it is available.

> In theory, there is no reason why a pipe couldn't operate with smaller capacities, even with a single-byte buffer. The reason for employing large buffer sizes is efficiency: each time a writer fills the pipe, the kernel must perform a context switch to allow the reader to be scheduled so that it can empty some data from the pipe. Employing a larger buffer size means that fewer context switches are required.

> Starting with Linux 2.6.35, the capacity of a pipe can be modified. The Linux-specific call fcntl(fd, F\_SETPIPE\_SZ, size) changes the capacity of the pipe referred to by fd to be at least size bytes. An unprivileged process can

change the pipe capacity to any value in the range from the system page size up to the value in /proc/sys/fs/pipe-max-size. The default value for pipe-maxsize is 1,048,576 bytes. A privileged (CAP\_SYS\_RESOURCE) process can override this limit. When allocating space for the pipe, the kernel may round size up to some value convenient for the implementation. The fcntl(fd, F\_GETPIPE\_SZ) call returns the actual size allocated for the pipe.

# **44.2 Creating and Using Pipes**

The pipe() system call creates a new pipe.

```
#include <unistd.h>
int pipe(int filedes[2]);
                                              Returns 0 on success, or –1 on error
```

A successful call to pipe() returns two open file descriptors in the array filedes: one for the read end of the pipe (filedes[0]) and one for the write end ( filedes[1]).

As with any file descriptor, we can use the read() and write() system calls to perform I/O on the pipe. Once written to the write end of a pipe, data is immediately available to be read from the read end. A read() from a pipe obtains the lesser of the number of bytes requested and the number of bytes currently available in the pipe (but blocks if the pipe is empty).

We can also use the stdio functions (printf(), scanf(), and so on) with pipes by first using fdopen() to obtain a file stream corresponding to one of the descriptors in filedes (Section 13.7). However, when doing this, we must be aware of the stdio buffering issues described in Section [44.6.](#page-29-0)

> The call ioctl(fd, FIONREAD, &cnt) returns the number of unread bytes in the pipe or FIFO referred to by the file descriptor fd. This feature is also available on some other implementations, but is not specified in SUSv3.

[Figure 44-2](#page-15-0) shows the situation after a pipe has been created by pipe(), with the calling process having file descriptors referring to each end.

```
                  +----------------------------------+
                  |          calling process         |
   |--------------|                                  |------------|
   |              |   filedes[1]      filedes[0]     |            |
   |              +------------------+---------------+            |
   |                                                              |
   |                                                              |
   |                              pipe                            |
   |    ┌─────────────────────────────────────────────────────┐   |
   |--->│   direction of data flow  ───────────────────────►  │<--|
        └─────────────────────────────────────────────────────┘
```

<span id="page-15-0"></span>**Figure 44-2:** Process file descriptors after creating a pipe

A pipe has few uses within a single process (we consider one in Section 63.5.2). Normally, we use a pipe to allow communication between two processes. To connect two processes using a pipe, we follow the pipe() call with a call to fork(). During a fork(), the child process inherits copies of its parent's file descriptors (Section 24.2.1), bringing about the situation shown on the left side of [Figure 44-3.](#page-16-0)

```
                  +----------------------------------+
                  |         parent process           |
   |--------------|  filedes[1]      filedes[0]      |<----------|
   |              +--------+-------------+-----------+           |
   |                                                             |
   |                                                             |
   |                                                             |
   |                             pipe                            |
   |    ┌───────────────────────────────────────────────────┐    |
   |--->│                                                   │----|
   |    │        ────────────────────────────────►          │    |
   |    └──────────────────┼─────────────┼──────────────────┘    |
   |                       |             ▲                       |
   |                       |             |                       |
   |                       |             |                       |
   |              +--------+-------------+-----------+           | 
   |--------------|  filedes[1]      filedes[0]      |<----------|           
                  |         child process            |            
                  +----------------------------------+
                
                           a) After fork()   
                           
                  +----------------------------------+
                  |         parent process           |
   |--------------|         filedes[1]               |------------|
   |              +----------------+-----------------+            |
   |                               |                              |
   |                               ▼                              |
   |                             pipe                             |
   |    ┌─────────────────────────────────────────────────────┐   |
   |--->│          ────────────────────────────────►          │<--|
        └─────────────────────────────────────────────────────┘   |
                                                                  |
                  +----------------+----------------+             |
                  |         filedes[0]              |<------------|
                  |         child process           |             
                  +---------------------------------+
                       
                  b) After closing unused descriptors
```

<span id="page-16-0"></span>**Figure 44-3:** Setting up a pipe to transfer data from a parent to a child

While it is possible for the parent and child to both read from and write to the pipe, this is not usual. Therefore, immediately after the fork(), one process closes its descriptor for the write end of the pipe, and the other closes its descriptor for the read end. For example, if the parent is to send data to the child, then it would close its read descriptor for the pipe, filedes[0], while the child would close its write descriptor for the pipe, filedes[1], bringing about the situation shown on the right side of [Figure 44-3](#page-16-0). The code to create this setup is shown in Listing 44-1.

**Listing 44-1:** Steps in creating a pipe to transfer data from a parent to a child

```
 int filedes[2];
 if (pipe(filedes) == -1) /* Create the pipe */
 errExit("pipe");
 switch (fork()) { /* Create a child process */
 case -1:
 errExit("fork");
 case 0: /* Child */
 if (close(filedes[1]) == -1) /* Close unused write end */
 errExit("close");
 /* Child now reads from pipe */
 break;
 default: /* Parent */
 if (close(filedes[0]) == -1) /* Close unused read end */
 errExit("close");
 /* Parent now writes to pipe */
 break;
 }
```

One reason that it is not usual to have both the parent and child reading from a single pipe is that if two processes try to simultaneously read from a pipe, we can't be sure which process will be the first to succeed—the two processes race for data. Preventing such races would require the use of some synchronization mechanism. However, if we require bidirectional communication, there is a simpler way: just create two pipes, one for sending data in each direction between the two processes. (If employing this technique, then we need to be wary of deadlocks that may occur if both processes block while trying to read from empty pipes or while trying to write to pipes that are already full.)

While it is possible to have multiple processes writing to a pipe, it is typical to have only a single writer. (We show one example of where it is useful to have multiple writers to a pipe in Section [44.3](#page-20-1).) By contrast, there are situations where it can be useful to have multiple writers on a FIFO, and we see an example of this in Section [44.8.](#page-32-1)

> Starting with kernel 2.6.27, Linux supports a new, nonstandard system call, pipe2(). This system call performs the same task as pipe(), but supports an additional argument, flags, that can be used to modify the behavior of the system call. Two flags are supported. The O\_CLOEXEC flag causes the kernel to enable the close-on-exec flag (FD\_CLOEXEC) for the two new file descriptors. This flag is useful for the same reasons as the open() O\_CLOEXEC flag described in Section 4.3.1. The O\_NONBLOCK flag causes the kernel to mark both underlying open file descriptions as nonblocking, so that future I/O operations will be nonblocking. This saves additional calls to fcntl() to achieve the same result.

### **Pipes allow communication between related processes**

In the discussion so far, we have talked about using pipes for communication between a parent and a child process. However, pipes can be used for communication between any two (or more) related processes, as long as the pipe was created by a common ancestor before the series of fork() calls that led to the existence of the processes. (This is what we meant when we referred to related processes at the beginning of this chapter.) For example, a pipe could be used for communication between a process and its grandchild. The first process creates the pipe, and then forks a child that in turn forks to yield the grandchild. A common scenario is that a pipe is used for communication between two siblings—their parent creates the pipe, and then creates the two children. This is what the shell does when building a pipeline.

> There is an exception to the statement that pipes can be used to communicate only between related processes. Passing a file descriptor over a UNIX domain socket (a technique that we briefly describe in Section 61.13.3) makes it possible to pass a file descriptor for a pipe to an unrelated process.

## **Closing unused pipe file descriptors**

Closing unused pipe file descriptors is more than a matter of ensuring that a process doesn't exhaust its limited set of file descriptors—it is essential to the correct use of pipes. We now consider why the unused file descriptors for both the read and write ends of the pipe must be closed.

The process reading from the pipe closes its write descriptor for the pipe, so that, when the other process completes its output and closes its write descriptor, the reader sees end-of-file (once it has read any outstanding data in the pipe).

If the reading process doesn't close the write end of the pipe, then, after the other process closes its write descriptor, the reader won't see end-of-file, even after it has read all data from the pipe. Instead, a read() would block waiting for data, because the kernel knows that there is still at least one write descriptor open for the pipe. That this descriptor is held open by the reading process itself is irrelevant; in theory, that process could still write to the pipe, even if it is blocked trying to read. For example, the read() might be interrupted by a signal handler that writes data to the pipe. (This is a realistic scenario, as we'll see in Section 63.5.2.)

The writing process closes its read descriptor for the pipe for a different reason. When a process tries to write to a pipe for which no process has an open read descriptor, the kernel sends the SIGPIPE signal to the writing process. By default, this signal kills a process. A process can instead arrange to catch or ignore this signal, in which case the write() on the pipe fails with the error EPIPE (broken pipe). Receiving the SIGPIPE signal or getting the EPIPE error is a useful indication about the status of the pipe, and this is why unused read descriptors for the pipe should be closed.

> Note that the treatment of a write() that is interrupted by a SIGPIPE handler is special. Normally, when a write() (or other "slow" system call) is interrupted by a signal handler, the call is either automatically restarted or fails with the error EINTR, depending on whether the handler was installed with the sigaction() SA\_RESTART flag (Section 21.5). The behavior in the case of SIGPIPE is different because it makes no sense either to automatically restart the write() or to simply indicate that the write() was interrupted by a handler (thus implying that the write() could usefully be manually restarted). In neither case can a subsequent write() attempt succeed, because the pipe will still be broken.

If the writing process doesn't close the read end of the pipe, then, even after the other process closes the read end of the pipe, the writing process will still be able to write to the pipe. Eventually, the writing process will fill the pipe, and a further attempt to write will block indefinitely.

One final reason for closing unused file descriptors is that it is only after all file descriptors in all processes that refer to a pipe are closed that the pipe is destroyed and its resources released for reuse by other processes. At this point, any unread data in the pipe is lost.

## **Example program**

The program in [Listing 44-2](#page-19-0) demonstrates the use of a pipe for communication between parent and child processes. This example demonstrates the byte-stream nature of pipes referred to earlier—the parent writes its data in a single operation, while the child reads data from the pipe in small blocks.

The main program calls pipe() to create a pipe q, and then calls fork() to create a child w. After the fork(), the parent process closes its file descriptor for the read end of the pipe i, and writes the string given as the program's command-line argument to the write end of the pipe o. The parent then closes the read end of the pipe a, and calls wait() to wait for the child to terminate s. After closing its file descriptor for the write end of the pipe e, the child process enters a loop where it reads r blocks of data (of up to BUF\_SIZE bytes) from the pipe and writes y them to standard output. When the child encounters end-of-file on the pipe t, it exits the loop u, writes a trailing newline character, closes its descriptor for the read end of the pipe, and terminates.

Here's an example of what we might see when running the program in Listing 44-2:

```
$ ./simple_pipe 'It was a bright cold day in April, '\
'and the clocks were striking thirteen.'
It was a bright cold day in April, and the clocks were striking thirteen.
```

<span id="page-19-0"></span>**Listing 44-2:** Using a pipe to communicate between a parent and child process

```
–––––––––––––––––––––––––––––––––––––––––––––––––––––– pipes/simple_pipe.c
  #include <sys/wait.h>
  #include "tlpi_hdr.h"
  #define BUF_SIZE 10
  int
  main(int argc, char *argv[])
  {
   int pfd[2]; /* Pipe file descriptors */
   char buf[BUF_SIZE];
   ssize_t numRead;
   if (argc != 2 || strcmp(argv[1], "--help") == 0)
   usageErr("%s string\n", argv[0]);
q if (pipe(pfd) == -1) /* Create the pipe */
   errExit("pipe");
w switch (fork()) {
   case -1:
   errExit("fork");
   case 0: /* Child - reads from pipe */
e if (close(pfd[1]) == -1) /* Write end is unused */
   errExit("close - child");
   for (;;) { /* Read data from pipe, echo on stdout */
r numRead = read(pfd[0], buf, BUF_SIZE);
   if (numRead == -1)
   errExit("read");
t if (numRead == 0)
   break; /* End-of-file */
y if (write(STDOUT_FILENO, buf, numRead) != numRead)
   fatal("child - partial/failed write");
   }
u write(STDOUT_FILENO, "\n", 1);
   if (close(pfd[0]) == -1)
   errExit("close");
   _exit(EXIT_SUCCESS);
   default: /* Parent - writes to pipe */
i if (close(pfd[0]) == -1) /* Read end is unused */
   errExit("close - parent");
```

```
o if (write(pfd[1], argv[1], strlen(argv[1])) != strlen(argv[1]))
   fatal("parent - partial/failed write");
a if (close(pfd[1]) == -1) /* Child will see EOF */
   errExit("close");
s wait(NULL); /* Wait for child to finish */
   exit(EXIT_SUCCESS);
   }
  }
  –––––––––––––––––––––––––––––––––––––––––––––––––––––– pipes/simple_pipe.c
```

# <span id="page-20-1"></span>**44.3 Pipes as a Method of Process Synchronization**

<span id="page-20-0"></span>In Section 24.5, we looked at how signals could be used to synchronize the actions of parent and child processes in order to avoid race conditions. Pipes can be used to achieve a similar result, as shown by the skeleton program in [Listing 44-3.](#page-20-2) This program creates multiple child processes (one for each command-line argument), each of which is intended to accomplish some action, simulated in the example program by sleeping for some time. The parent waits until all children have completed their actions.

To perform the synchronization, the parent builds a pipe q before creating the child processes w. Each child inherits a file descriptor for the write end of the pipe and closes this descriptor once it has completed its action e. After all of the children have closed their file descriptors for the write end of the pipe, the parent's read() t from the pipe will complete, returning end-of-file (0). At this point, the parent is free to carry on to do other work. (Note that closing the unused write end of the pipe in the parent r is essential to the correct operation of this technique; otherwise, the parent would block forever when trying to read from the pipe.)

The following is an example of what we see when we use the program in Listing 44-3 to create three children that sleep for 4, 2, and 6 seconds:

```
$ ./pipe_sync 4 2 6
08:22:16 Parent started
08:22:18 Child 2 (PID=2445) closing pipe
08:22:20 Child 1 (PID=2444) closing pipe
08:22:22 Child 3 (PID=2446) closing pipe
08:22:22 Parent ready to go
```

<span id="page-20-2"></span>**Listing 44-3:** Using a pipe to synchronize multiple processes

```
–––––––––––––––––––––––––––––––––––––––––––––––––––––––– pipes/pipe_sync.c
#include "curr_time.h" /* Declaration of currTime() */
#include "tlpi_hdr.h"
int
main(int argc, char *argv[])
{
 int pfd[2]; /* Process synchronization pipe */
 int j, dummy;
```

```
 if (argc < 2 || strcmp(argv[1], "--help") == 0)
   usageErr("%s sleep-time...\n", argv[0]);
   setbuf(stdout, NULL); /* Make stdout unbuffered, since we
   terminate child with _exit() */
   printf("%s Parent started\n", currTime("%T"));
q if (pipe(pfd) == -1)
   errExit("pipe");
   for (j = 1; j < argc; j++) {
w switch (fork()) {
   case -1:
   errExit("fork %d", j);
   case 0: /* Child */
   if (close(pfd[0]) == -1) /* Read end is unused */
   errExit("close");
   /* Child does some work, and lets parent know it's done */
   sleep(getInt(argv[j], GN_NONNEG, "sleep-time"));
   /* Simulate processing */
   printf("%s Child %d (PID=%ld) closing pipe\n",
   currTime("%T"), j, (long) getpid());
e if (close(pfd[1]) == -1)
   errExit("close");
   /* Child now carries on to do other things... */
   _exit(EXIT_SUCCESS);
   default: /* Parent loops to create next child */
   break;
   }
   }
   /* Parent comes here; close write end of pipe so we can see EOF */
r if (close(pfd[1]) == -1) /* Write end is unused */
   errExit("close");
   /* Parent may do other work, then synchronizes with children */
t if (read(pfd[0], &dummy, 1) != 0)
   fatal("parent didn't get EOF");
   printf("%s Parent ready to go\n", currTime("%T"));
   /* Parent can now carry on to do other things... */
   exit(EXIT_SUCCESS);
  }
  –––––––––––––––––––––––––––––––––––––––––––––––––––––––– pipes/pipe_sync.c
```

Synchronization using pipes has an advantage over the earlier example of synchronization using signals: it can be used to coordinate the actions of one process with multiple other (related) processes. The fact that multiple (standard) signals can't be queued makes signals unsuitable in this case. (Conversely, signals have the advantage that they can be broadcast by one process to all of the members of a process group.)

Other synchronization topologies are possible (e.g., using multiple pipes). Furthermore, this technique could be extended so that, instead of closing the pipe, each child writes a message to the pipe containing its process ID and some status information. Alternatively, each child might write a single byte to the pipe. The parent process could then count and analyze these messages. This approach guards against the possibility of the child accidentally terminating, rather than explicitly closing the pipe.

# <span id="page-22-0"></span>**44.4 Using Pipes to Connect Filters**

When a pipe is created, the file descriptors used for the two ends of the pipe are the next lowest-numbered descriptors available. Since, in normal circumstances, descriptors 0, 1, and 2 are already in use for a process, some higher-numbered descriptors will be allocated for the pipe. So how do we bring about the situation shown in [Figure 44-1,](#page-13-0) where two filters (i.e., programs that read from stdin and write to stdout) are connected using a pipe, such that the standard output of one program is directed into the pipe and the standard input of the other is taken from the pipe? And in particular, how can we do this without modifying the code of the filters themselves?

The answer is to use the techniques described in Section 5.5 for duplicating file descriptors. Traditionally, the following series of calls was used to accomplish the desired result:

```
int pfd[2];
pipe(pfd); /* Allocates (say) file descriptors 3 and 4 for pipe */
/* Other steps here, e.g., fork() */
close(STDOUT_FILENO); /* Free file descriptor 1 */
dup(pfd[1]); /* Duplication uses lowest free file
 descriptor, i.e., fd 1 */
```

The end result of the above steps is that the process's standard output is bound to the write end of the pipe. A corresponding set of calls can be used to bind a process's standard input to the read end of the pipe.

Note that these steps depend on the assumption that file descriptors 0, 1, and 2 for a process are already open. (The shell normally ensures this for each program it executes.) If file descriptor 0 was already closed prior to the above steps, then we would erroneously bind the process's standard input to the write end of the pipe. To avoid this possibility, we can replace the calls to close() and dup() with the following dup2() call, which allows us to explicitly specify the descriptor to be bound to the pipe end:

```
dup2(pfd[1], STDOUT_FILENO); /* Close descriptor 1, and reopen bound
 to write end of pipe */
```

After duplicating pfd[1], we now have two file descriptors referring to the write end of the pipe: descriptor 1 and pfd[1]. Since unused pipe file descriptors should be closed, after the dup2() call, we close the superfluous descriptor:

```
close(pfd[1]);
```

The code we have shown so far relies on standard output having been previously open. Suppose that, prior to the pipe() call, standard input and standard output had both been closed. In this case, pipe() would have allocated these two descriptors to the pipe, perhaps with pfd[0] having the value 0 and pfd[1] having the value 1. Consequently, the preceding dup2() and close() calls would be equivalent to the following:

```
dup2(1, 1); /* Does nothing */
close(1); /* Closes sole descriptor for write end of pipe */
```

Therefore, it is good defensive programming practice to bracket these calls with an if statement of the following form:

```
if (pfd[1] != STDOUT_FILENO) {
 dup2(pfd[1], STDOUT_FILENO);
 close(pfd[1]);
}
```

### **Example program**

The program in [Listing 44-4](#page-23-0) uses the techniques described in this section to bring about the setup shown in [Figure 44-1](#page-13-0). After building a pipe, this program creates two child processes. The first child binds its standard output to the write end of the pipe and then execs ls. The second child binds its standard input to the read end of the pipe and then execs wc.

<span id="page-23-0"></span>**Listing 44-4:** Using a pipe to connect ls and wc

```
––––––––––––––––––––––––––––––––––––––––––––––––––––––– pipes/pipe_ls_wc.c
#include <sys/wait.h>
#include "tlpi_hdr.h"
int
main(int argc, char *argv[])
{
 int pfd[2]; /* Pipe file descriptors */
 if (pipe(pfd) == -1) /* Create pipe */
 errExit("pipe");
 switch (fork()) {
 case -1:
 errExit("fork");
 case 0: /* First child: exec 'ls' to write to pipe */
 if (close(pfd[0]) == -1) /* Read end is unused */
 errExit("close 1");
```

```
 /* Duplicate stdout on write end of pipe; close duplicated descriptor */
 if (pfd[1] != STDOUT_FILENO) { /* Defensive check */
 if (dup2(pfd[1], STDOUT_FILENO) == -1)
 errExit("dup2 1");
 if (close(pfd[1]) == -1)
 errExit("close 2");
 }
 execlp("ls", "ls", (char *) NULL); /* Writes to pipe */
 errExit("execlp ls");
 default: /* Parent falls through to create next child */
 break;
 }
 switch (fork()) {
 case -1:
 errExit("fork");
 case 0: /* Second child: exec 'wc' to read from pipe */
 if (close(pfd[1]) == -1) /* Write end is unused */
 errExit("close 3");
 /* Duplicate stdin on read end of pipe; close duplicated descriptor */
 if (pfd[0] != STDIN_FILENO) { /* Defensive check */
 if (dup2(pfd[0], STDIN_FILENO) == -1)
 errExit("dup2 2");
 if (close(pfd[0]) == -1)
 errExit("close 4");
 }
 execlp("wc", "wc", "-l", (char *) NULL); /* Reads from pipe */
 errExit("execlp wc");
 default: /* Parent falls through */
 break;
 }
 /* Parent closes unused file descriptors for pipe, and waits for children */
 if (close(pfd[0]) == -1)
 errExit("close 5");
 if (close(pfd[1]) == -1)
 errExit("close 6");
 if (wait(NULL) == -1)
 errExit("wait 1");
 if (wait(NULL) == -1)
 errExit("wait 2");
 exit(EXIT_SUCCESS);
}
––––––––––––––––––––––––––––––––––––––––––––––––––––––– pipes/pipe_ls_wc.c
```

When we run the program in Listing 44-4, we see the following:

# 44.5 Talking to a Shell Command via a Pipe: popen()

A common use for pipes is to execute a shell command and either read its output or send it some input. The *popen()* and *pclose()* functions are provided to simplify this task.

```
#include <stdio.h>
FILE *popen(const char *command, const char *mode);
```

The *popen()* function creates a pipe, and then forks a child process that execs a shell, which in turn creates a child process to execute the string given in *command*. The *mode* argument is a string that determines whether the calling process will read from the pipe (*mode* is *r*) or write to it (*mode* is *w*). (Since pipes are unidirectional, two-way communication with the executed *command* is not possible.) The value of *mode* determines whether the standard output of the executed command is connected to the write end of the pipe or its standard input is connected to the read end of the pipe, as shown in Figure 44-4.

```
   a) mode is r                                    b) mode is w

              +-------------+                                   +-------------+
        |---->|   /bin/sh   |--|                           |--->|   /bin/sh   |-----|
 fork(),|     +------+------+  |                    fork(),|    +------+------+     |
 exec() |                      |fork(), exec()      exec() |                        |fork(), exec()
        |                      |                           |                        |
   +----------+             +--v-------+              +----|-----+             +----v-----+
   |calling   |             | command  |              |calling   |             | command  |
   |process   |     pipe    |          |              |process   |    pipe     |          |
   |        fp|<------------| stdout   |              |        fp|------+----->|stdin     |
   +----------+             +----------+              +----------+             +----------+
```

<span id="page-25-0"></span>**Figure 44-4:** Overview of process relationships and pipe usage for *popen()* 

On success, popen() returns a file stream pointer that can be used with the *stdio* library functions. If an error occurs (e.g., mode is not r or w, pipe creation fails, or the fork() to create the child fails), then popen() returns NULL and sets errno to indicate the cause of the error.

After the *popen()* call, the calling process uses the pipe to read the output of *command* or to send input to it. Just as with pipes created using *pipe()*, when reading from the pipe, the calling process encounters end-of-file once *command* has closed

the write end of the pipe; when writing to the pipe, it is sent a SIGPIPE signal, and gets the EPIPE error, if command has closed the read end of the pipe.

Once I/O is complete, the pclose() function is used to close the pipe and wait for the child shell to terminate. (The fclose() function should not be used, since it doesn't wait for the child.) On success, pclose() yields the termination status (Section 26.1.3) of the child shell (which is the termination status of the last command that the shell executed, unless the shell was killed by a signal). As with system() (Section 27.6), if a shell could not be execed, then pclose() returns a value as though the child shell had terminated with the call \_exit(127). If some other error occurs, pclose() returns –1. One possible error is that the termination status could not be obtained. We explain how this may occur shortly.

When performing a wait to obtain the status of the child shell, SUSv3 requires that pclose(), like system(), should automatically restart the internal call that it makes to waitpid() if that call is interrupted by a signal handler.

In general, we can make the same statements for popen() as were made in Section 27.6 for system(). Using popen() offers convenience. It builds the pipe, performs descriptor duplication, closes unused descriptors, and handles all of the details of fork() and exec() on our behalf. In addition, shell processing is performed on the command. This convenience comes at the cost of efficiency. At least two extra processes must be created: one for the shell and one or more for the command(s) executed by the shell. As with system(), popen() should never be used from privileged programs.

While there are several similarities between system() and popen() plus pclose(), there are also significant differences. These stem from the fact that, with system(), the execution of the shell command is encapsulated within a single function call, whereas with popen(), the calling process runs in parallel with the shell command and then calls pclose(). The differences are as follows:

-  Since the calling process and the executed command are operating in parallel, SUSv3 requires that popen() should not ignore SIGINT and SIGQUIT. If generated from the keyboard, these signals are sent to both the calling process and the executed command. This occurs because both processes reside in the same process group, and terminal-generated signals are sent to all of the members of the (foreground) process group, as described in Section 34.5.
-  Since the calling process may create other child processes between the execution of popen() and pclose(), SUSv3 requires that popen() should not block SIGCHLD. This means that if the calling process performs a wait operation before the pclose() call, it may retrieve the status of the child created by popen(). In this case, when pclose() is later called, it will return –1, with errno set to ECHILD, indicating that pclose() could not retrieve the status of the child.

## **Example program**

[Listing 44-5](#page-27-0) demonstrates the use of popen() and pclose(). This program repeatedly reads a filename wildcard pattern w, and then uses popen() to obtain the results from passing this pattern to the ls command t. (Techniques similar to this were used on older UNIX implementations to perform filename generation, also known as globbing, prior to the existence of the glob() library function.)

```
––––––––––––––––––––––––––––––––––––––––––––––––––––––– pipes/popen_glob.c
  #include <ctype.h>
  #include <limits.h>
  #include "print_wait_status.h" /* For printWaitStatus() */
  #include "tlpi_hdr.h"
q #define POPEN_FMT "/bin/ls -d %s 2> /dev/null"
  #define PAT_SIZE 50
  #define PCMD_BUF_SIZE (sizeof(POPEN_FMT) + PAT_SIZE)
  int
  main(int argc, char *argv[])
  {
   char pat[PAT_SIZE]; /* Pattern for globbing */
   char popenCmd[PCMD_BUF_SIZE];
   FILE *fp; /* File stream returned by popen() */
   Boolean badPattern; /* Invalid characters in 'pat'? */
   int len, status, fileCnt, j;
   char pathname[PATH_MAX];
   for (;;) { /* Read pattern, display results of globbing */
   printf("pattern: ");
   fflush(stdout);
w if (fgets(pat, PAT_SIZE, stdin) == NULL)
   break; /* EOF */
   len = strlen(pat);
   if (len <= 1) /* Empty line */
   continue;
   if (pat[len - 1] == '\n') /* Strip trailing newline */
   pat[len - 1] = '\0';
   /* Ensure that the pattern contains only valid characters,
   i.e., letters, digits, underscore, dot, and the shell
   globbing characters. (Our definition of valid is more
   restrictive than the shell, which permits other characters
   to be included in a filename if they are quoted.) */
e for (j = 0, badPattern = FALSE; j < len && !badPattern; j++)
   if (!isalnum((unsigned char) pat[j]) &&
   strchr("_*?[^-].", pat[j]) == NULL)
   badPattern = TRUE;
   if (badPattern) {
   printf("Bad pattern character: %c\n", pat[j - 1]);
   continue;
   }
   /* Build and execute command to glob 'pat' */
r snprintf(popenCmd, PCMD_BUF_SIZE, POPEN_FMT, pat);
   popenCmd[PCMD_BUF_SIZE - 1] = '\0'; /* Ensure string is
   null-terminated */
```

```
t fp = popen(popenCmd, "r");
   if (fp == NULL) {
   printf("popen() failed\n");
   continue;
   }
   /* Read resulting list of pathnames until EOF */
   fileCnt = 0;
   while (fgets(pathname, PATH_MAX, fp) != NULL) {
   printf("%s", pathname);
   fileCnt++;
   }
   /* Close pipe, fetch and display termination status */
   status = pclose(fp);
   printf(" %d matching file%s\n", fileCnt, (fileCnt != 1) ? "s" : "");
   printf(" pclose() status == %#x\n", (unsigned int) status);
   if (status != -1)
   printWaitStatus("\t", status);
   }
   exit(EXIT_SUCCESS);
  }
  ––––––––––––––––––––––––––––––––––––––––––––––––––––––– pipes/popen_glob.c
```

The following shell session demonstrates the use of the program in [Listing 44-5.](#page-27-0) In this example, we first provide a pattern that matches two filenames, and then a pattern that matches no filename:

```
$ ./popen_glob
pattern: popen_glob* Matches two filenames
popen_glob
popen_glob.c
 2 matching files
 pclose() status = 0
 child exited, status=0
pattern: x* Matches no filename
 0 matching files
 pclose() status = 0x100 ls(1) exits with status 1
 child exited, status=1
pattern: ^D$ Type Control-D to terminate
```

The construction of the command qr for globbing in [Listing 44-5](#page-27-0) requires some explanation. Actual globbing of a pattern is performed by the shell. The ls command is merely being used to list the matching filenames, one per line. We could have tried using the echo command instead, but this would have had the undesirable result that if a pattern matched no filenames, then the shell would leave the pattern unchanged, and echo would simply display the pattern. By contrast, if ls is given the name of a file that doesn't exist, it prints an error message on stderr (which we dispose of by redirecting stderr to /dev/null), prints nothing on stdout, and exits with a status of 1.

Note also the input checking performed in [Listing 44-5](#page-27-0) e. This is done to prevent invalid input causing popen() to execute an unexpected shell command. Suppose that these checks were omitted, and the user entered the following input:

```
pattern: ; rm *
```

The program would then pass the following command to popen(), with disastrous results:

```
/bin/ls -d ; rm * 2> /dev/null
```

Such checking of input is always required in programs that use popen() (or system()) to execute a shell command built from user input. (An alternative would be for the application to quote any characters other than those being checked for, so that those characters don't undergo special processing by the shell.)

# <span id="page-29-0"></span>**44.6 Pipes and stdio Buffering**

Since the file stream pointer returned by a call to popen() doesn't refer to a terminal, the stdio library applies block buffering to the file stream (Section 13.2). This means that when we call popen() with a mode of w, then, by default, output is sent to the child process at the other end of the pipe only when the stdio buffer is filled or we close the pipe with pclose(). In many cases, this presents no problem. If, however, we need to ensure that the child process receives data on the pipe immediately, then we can either use periodic calls to fflush() or disable stdio buffering using the call setbuf(fp, NULL). This technique can also be used if we create a pipe using the pipe() system call and then use fdopen() to obtain a stdio stream corresponding to the write end of the pipe.

If the process calling popen() is reading from the pipe (i.e., mode is r), things may not be so straightforward. In this case, if the child process is using the stdio library, then—unless it includes explicit calls to fflush() or setbuf()—its output will be available to the calling process only when the child either fills the stdio buffer or calls fclose(). (The same statement applies if we are reading from a pipe created using pipe() and the process writing on the other end is using the stdio library.) If this is a problem, there is little we can do unless we can modify the source code of the program running in the child process to include calls to setbuf() of fflush().

If modifying the source code is not an option, then instead of using a pipe, we could use a pseudoterminal. A pseudoterminal is an IPC channel that appears to the process on one end as though it is a terminal. Consequently, the stdio library line buffers output. We describe pseudoterminals in Chapter 64.

# **44.7 FIFOs**

Semantically, a FIFO is similar to a pipe. The principal difference is that a FIFO has a name within the file system and is opened in the same way as a regular file. This allows a FIFO to be used for communication between unrelated processes (e.g., a client and server).

Once a FIFO has been opened, we use the same I/O system calls as are used with pipes and other files (i.e., read(), write(), and close()). Just as with pipes, a FIFO has a write end and a read end, and data is read from the pipe in the same order as it is written. This fact gives FIFOs their name: first in, first out. FIFOs are also sometimes known as named pipes.

As with pipes, when all descriptors referring to a FIFO have been closed, any outstanding data is discarded.

We can create a FIFO from the shell using the mkfifo command:

```
$ mkfifo [ -m mode ] pathname
```

The pathname is the name of the FIFO to be created, and the –m option is used to specify a permission mode in the same way as for the chmod command.

When applied to a FIFO (or pipe), fstat() and stat() return a file type of S\_IFIFO in the st\_mode field of the stat structure (Section 15.1). When listed with ls –l, a FIFO is shown with the type p in the first column, and ls –F appends an the pipe symbol (|) to the FIFO pathname.

The mkfifo() function creates a new FIFO with the given pathname.

```
#include <sys/stat.h>
int mkfifo(const char *pathname, mode_t mode);
                                            Returns 0 on success, or –1 on error
```

The mode argument specifies the permissions for the new FIFO. These permissions are specified by ORing the desired combination of constants from Table 15-4, on page 295. As usual, these permissions are masked against the process umask value (Section 15.4.6).

> Historically, FIFOs were created using the system call mknod(pathname, S\_IFIFO, 0). POSIX.1-1990 specified mkfifo() as a simpler API avoiding the generality of mknod(), which allows creation of various types of files, including device files. (SUSv3 specifies mknod(), but weakly, defining only its use for creating FIFOs.) Most UNIX implementations provide mkfifo() as a library function layered on top of mknod().

Once a FIFO has been created, any process can open it, subject to the usual file permission checks (Section 15.4.3).

Opening a FIFO has somewhat unusual semantics. Generally, the only sensible use of a FIFO is to have a reading process and a writing process on each end. Therefore, by default, opening a FIFO for reading (the open() O\_RDONLY flag) blocks until another process opens the FIFO for writing (the open() O\_WRONLY flag). Conversely, opening the FIFO for writing blocks until another process opens the FIFO for reading. In other words, opening a FIFO synchronizes the reading and writing processes. If the opposite end of a FIFO is already open (perhaps because a pair of processes have already opened each end of the FIFO), then open() succeeds immediately.

Under most UNIX implementations (including Linux), it is possible to circumvent the blocking behavior when opening FIFOs by specifying the O\_RDWR flag when opening a FIFO. In this case, open() returns immediately with a file descriptor that can be used for reading and writing on the FIFO. Doing this rather subverts the I/O model for FIFOs, and SUSv3 explicitly notes that opening a FIFO with the O\_RDWR flag is unspecified; therefore, for portability reasons, this technique should be avoided. In circumstances where we need to prevent blocking when opening a FIFO, the open() O\_NONBLOCK flag provides a standardized method for doing so (refer to Section [44.9\)](#page-38-0).

> Avoiding the use of the O\_RDWR flag when opening a FIFO can be desirable for a another reason. After such an open(), the calling process will never see end-offile when reading from the resulting file descriptor, because there will always be at least one descriptor open for writing to the FIFO—the same descriptor from which the process is reading.

## **Using FIFOs and tee(1) to create a dual pipeline**

One of the characteristics of shell pipelines is that they are linear; each process in the pipeline reads data produced by its predecessor and sends data to its successor. Using FIFOs, it is possible to create a fork in a pipeline, so that a duplicate copy of the output of a process is sent to another process in addition to its successor in the pipeline. In order to do this, we need to use the tee command, which writes two copies of what it reads from its standard input: one to standard output and the other to the file named in its command-line argument.

Making the file argument to tee a FIFO allows us to have two processes simultaneously reading the duplicate output produced by tee. We demonstrate this in the following shell session, which creates a FIFO named myfifo, starts a background wc command that opens the FIFO for reading (this will block until the FIFO is opened for writing), and then executes a pipeline that sends the output of ls to tee, which both passes the output further down the pipeline to sort and sends it to the myfifo FIFO. (The –k5n option to sort causes the output of ls to be sorted in increasing numerical order on the fifth space-delimited field.)

```
$ mkfifo myfifo
$ wc -l < myfifo &
$ ls -l | tee myfifo | sort -k5n
(Resulting output not shown)
```

Diagrammatically, the above commands create the situation shown in [Figure 44-5.](#page-31-0)

The tee program is so named because of its shape. We can consider tee as functioning similarly to a pipe, but with an additional branch that sends duplicate output. Diagrammatically, this has the shape of a capital letter T (see [Figure 44-5\)](#page-31-0). In addition to the purpose described here, tee is also useful for debugging pipelines and for saving the results produced at some intervening point in a complex pipeline.

```
       +-----+       .------.       +-----+       .------.       +------+
       | ls  | -----►( pipe )-----► | tee | -----►( pipe )-----► | sort |
       +-----+       `------'       +-----+       `------'       +------+
                                        |
                                        │
                                        ▼
                                     .-------.
                                    /  FIFO   \
                                    \         /
                                     `-------'
                                        │
                                        ▼
                                      +----+
                                      | wc |
                                      +----+
```

<span id="page-31-0"></span>**Figure 44-5:** Using a FIFO and tee(1) to create a dual pipeline

# <span id="page-32-1"></span>**44.8 A Client-Server Application Using FIFOs**

<span id="page-32-0"></span>In this section, we present a simple client-server application that employs FIFOs for IPC. The server provides the (trivial) service of assigning unique sequential numbers to each client that requests them. In the course of discussing this application, we introduce a few concepts and techniques in server design.

### **Application overview**

In the example application, all clients send their requests to the server using a single server FIFO. The header file ([Listing 44-6\)](#page-34-0) defines the well-known name (/tmp/seqnum\_sv) that the server uses for its FIFO. This name is fixed, so that all clients know how to contact the server. (In this example application, we create the FIFOs in the /tmp directory, since this allows us to conveniently run the programs without change on most systems. However, as noted in Section 38.7, creating files in publicly writable directories such as /tmp can lead to various security vulnerabilities and should be avoided in real-world applications.)

> In client-server applications, we'll repeatedly encounter the concept of a wellknown address or name used by a server to make its service visible to clients. Using a well-known address is one solution to the problem of how clients can know where to contact a server. Another possible solution is to provide some kind of name server with which servers can register the names of their services. Each client then contacts the name server to obtain the location of the service it desires. This solution allows the location of servers to be flexible, at the cost of some extra programming effort. Of course, clients and servers then need to know where to contact the name server; typically, it resides at a well-known address.

It is not, however, possible to use a single FIFO to send responses to all clients, since multiple clients would race to read from the FIFO, and possibly read each other's response messages rather than their own. Therefore, each client creates a unique FIFO that the server uses for delivering the response for that client, and the server needs to know how to find each client's FIFO. One possible way to do this is for the client to generate its FIFO pathname, and then pass the pathname as part of its request message. Alternatively, the client and server can agree on a convention for constructing a client FIFO pathname, and, as part of its request, the client can pass the server the information required to construct the pathname specific to this client. This latter solution is used in our example. Each client's FIFO name is built from a template (CLIENT\_FIFO\_TEMPLATE) consisting of a pathname containing the client's process ID. The inclusion of the process ID provides an easy way of generating a name unique to this client.

[Figure 44-6](#page-33-0) shows how this application uses FIFOs for communication between the client and server processes of our application.

The header file [\(Listing 44-6\)](#page-34-0) defines the formats for the request messages sent from clients to the server, and for the response messages sent from the server to clients.

```
        +--------------------+                         +----------------------+
        |    Client A        |<------------------------|    Client A FIFO     |
        |    (PID = 6514)    |                         | /tmp/seqnum_cl.6514  |
        +---------+----------+                         +----------+-----------+
                  |                                              ^
                  | Request (PID + length)                       |
                  v                                              | Response (seq. #)
            +-----+-------------------------------+            +-----+------+                           
            |             Server FIFO             |----------->|   Server   |                
            |           /tmp/seqnum_sv            |            +-----+------+                
            +-----+-------------------------------+              |
                  ^                                              | Response (seq. #)
                  | Request (PID + length)                       |
                  |                                              v
        +---------+----------+                         +----------+-----------+
        |    Client B        |<------------------------|    Client B FIFO     |
        |    (PID = 6523)    |                         | /tmp/seqnum_cl.6523  |
        +--------------------+                         +----------------------+

```

<span id="page-33-0"></span>Figure 44-6: Using FIFOs in a single-server, multiple-client application

Recall that the data in pipes and FIFOs is a byte stream; boundaries between multiple messages are not preserved. This means that when multiple messages are being delivered to a single process, such as the server in our example, then the sender and receiver must agree on some convention for separating the messages. Various approaches are possible:

- Terminate each message with a *delimiter character*, such as a newline character. (For an example of this technique, see the *readLine()* function in Listing 59-1, on page 1201.) In this case, either the delimiter character must be one that never appears as part of the message, or we must adopt a convention for escaping the delimiter if it does occur within the message. For example, if we use a newline delimiter, then the characters \ plus newline could be used to represent a real newline character within the message, while \\ could represent a real \. One drawback of this approach is that the process reading messages must scan data from the FIFO a byte at a time until the delimiter character is found.
- Include a *fixed-size header with a length field* in each message specifying the number of bytes in the remaining variable-length component of the message. In this case, the reading process first reads the header from the FIFO, and then uses the header's length field to determine the number of bytes to read for the remainder of the message. This approach has the advantage of efficiently allowing messages of arbitrary size, but could lead to problems if a malformed message (e.g., bad *length* field) is written to the pipe.
- Use *fixed-length messages*, and have the server always read messages of this fixed size. This has the advantage of being simple to program. However, it places an upper limit on our message size and means that some channel capacity is wasted (since short messages must be padded to the fixed length). Furthermore, if one of the clients accidentally or deliberately sends a message that is not of the right length, then all subsequent messages will be out of step; in this situation, the server can't easily recover.

These three techniques are illustrated in Figure 44-7. Be aware that for each of these techniques, the total length of each message must be smaller than PIPE\_BUF bytes in order to avoid the possibility of messages being broken up by the kernel and interleaved with messages from other writers.

In the three techniques described in the main text, a single channel (FIFO) is used for all messages from all clients. An alternative is to use a *single connection for each message*. The sender opens the communication channel, sends its message, and then closes the channel. The reading process knows that the message is complete when it encounters end-of-file. If multiple writers hold a FIFO open, then this approach is not feasible, because the reader won't see end-of-file when one of the writers closes the FIFO. This approach is, however, feasible when using stream sockets, where a server process creates a unique communication channel for each incoming client connection.

```
1) delimiter character

   [data| ][data| ][data| ]
         ^       ^       ^
         |       |       |
       delimiter characters 


2) header with length field

   [ len ][ data         ][ len ][ data         ][ len ][ data       ]
          <--len bytes -->


3) fixed-length messages

   <---- n bytes --->  <--- n bytes ----> <--- n bytes ---->
   [      data       ][      data       ][      data       ]
```

<span id="page-34-1"></span>Figure 44-7: Separating messages in a byte stream

In our example application, we use the third of the techniques described above, with each client sending messages of a fixed size to the server. This message is defined by the *request* structure defined in Listing 44-6. Each request to the server includes the client's process ID, which enables the server to construct the name of the FIFO used by the client to receive a response. The request also contains a field (*seqLen*) specifying how many sequence numbers should be allocated to this client. The response message sent from server to client consists of a single field, *seqNum*, which is the starting value of the range of sequence numbers allocated to this client.

<span id="page-34-0"></span>**Listing 44-6:** Header file for fifo segnum server.c and fifo segnum client.c

```
pipes/fifo_seqnum.h
#include <sys/types.h>
#include <sys/stat.h>
#include <fcntl.h>
#include "tlpi hdr.h"
#define SERVER FIFO "/tmp/segnum sv"
                                /* Well-known name for server's FIFO */
#define CLIENT_FIFO TEMPLATE "/tmp/seqnum cl.%ld"
                                /* Template for building client FIFO name */
#define CLIENT FIFO NAME LEN (sizeof(CLIENT FIFO TEMPLATE) + 20)
                                /* Space required for client FIFO pathname
                                   (+20 as a generous allowance for the PID) */
struct request {
                                /* Request (client --> server) */
                                /* PID of client */
   pid t pid;
   int seqLen;
                                /* Length of desired sequence */
};
```

```
struct response { /* Response (server --> client) */
 int seqNum; /* Start of sequence */
};
–––––––––––––––––––––––––––––––––––––––––––––––––––––– pipes/fifo_seqnum.h
```

### **Server program**

Listing 44-7 is the code for the server. The server performs the following steps:

-  Create the server's well-known FIFO q and open the FIFO for reading w. The server must be run before any clients, so that the server FIFO exists by the time a client attempts to open it. The server's open() blocks until the first client opens the other end of the server FIFO for writing.
-  Open the server's FIFO once more e, this time for writing. This will never block, since the FIFO has already been opened for reading. This second open is a convenience to ensure that the server doesn't see end-of-file if all clients close the write end of the FIFO.
-  Ignore the SIGPIPE signal r, so that if the server attempts to write to a client FIFO that doesn't have a reader, then, rather than being sent a SIGPIPE signal (which kills a process by default), it receives an EPIPE error from the write() system call.
-  Enter a loop that reads and responds to each incoming client request t. To send the response, the server constructs the name of the client FIFO y and then opens that FIFO u.
-  If the server encounters an error in opening the client FIFO, it abandons that client's request i.

This is an example of an iterative server, in which the server reads and handles each client request before going on to handle the next client. An iterative server design is suitable when each client request can be quickly processed and responded to, so that other client requests are not delayed. An alternative design is a concurrent server, in which the main server process employs a separate child process (or thread) to handle each client request. We discuss server design further in Chapter 60.

<span id="page-35-0"></span>**Listing 44-7:** An iterative server using FIFOs

```
–––––––––––––––––––––––––––––––––––––––––––––––– pipes/fifo_seqnum_server.c
#include <signal.h>
#include "fifo_seqnum.h"
int
main(int argc, char *argv[])
{
 int serverFd, dummyFd, clientFd;
 char clientFifo[CLIENT_FIFO_NAME_LEN];
 struct request req;
 struct response resp;
 int seqNum = 0; /* This is our "service" */
```

```
 /* Create well-known FIFO, and open it for reading */
   umask(0); /* So we get the permissions we want */
q if (mkfifo(SERVER_FIFO, S_IRUSR | S_IWUSR | S_IWGRP) == -1
   && errno != EEXIST)
   errExit("mkfifo %s", SERVER_FIFO);
w serverFd = open(SERVER_FIFO, O_RDONLY);
   if (serverFd == -1)
   errExit("open %s", SERVER_FIFO);
   /* Open an extra write descriptor, so that we never see EOF */
e dummyFd = open(SERVER_FIFO, O_WRONLY);
   if (dummyFd == -1)
   errExit("open %s", SERVER_FIFO);
r if (signal(SIGPIPE, SIG_IGN) == SIG_ERR)
   errExit("signal");
t for (;;) { /* Read requests and send responses */
   if (read(serverFd, &req, sizeof(struct request))
   != sizeof(struct request)) {
   fprintf(stderr, "Error reading request; discarding\n");
   continue; /* Either partial read or error */
   }
   /* Open client FIFO (previously created by client) */
y snprintf(clientFifo, CLIENT_FIFO_NAME_LEN, CLIENT_FIFO_TEMPLATE,
   (long) req.pid);
u clientFd = open(clientFifo, O_WRONLY);
   if (clientFd == -1) { /* Open failed, give up on client */
   errMsg("open %s", clientFifo);
i continue;
   }
   /* Send response and close FIFO */
   resp.seqNum = seqNum;
   if (write(clientFd, &resp, sizeof(struct response))
   != sizeof(struct response))
   fprintf(stderr, "Error writing to FIFO %s\n", clientFifo);
   if (close(clientFd) == -1)
   errMsg("close");
   seqNum += req.seqLen; /* Update our sequence number */
   }
  }
  –––––––––––––––––––––––––––––––––––––––––––––––– pipes/fifo_seqnum_server.c
```

### **Client program**

[Listing 44-8](#page-37-0) is the code for the client. The client performs the following steps:

-  Create a FIFO to be used for receiving a response from the server w. This is done before sending the request, in order to ensure that the FIFO exists by the time the server attempts to open it and send a response message.
-  Construct a message for the server containing the client's process ID and a number (taken from an optional command-line argument) specifying the length of the sequence that the client wishes the server to assign to it r. (If no command-line argument is supplied, the default sequence length is 1.)
-  Open the server FIFO t and send the message to the server y.
-  Open the client FIFO u, and read and print the server's response i.

The only other detail of note is the exit handler q, established with atexit() e, which ensures that the client's FIFO is deleted when the process exits. Alternatively, we could have simply placed an unlink() call immediately after the open() of the client FIFO. This would work because, at that point, after they have both performed blocking open() calls, the server and the client would each hold open file descriptors for the FIFO, and removing the FIFO name from the file system doesn't affect these descriptors or the open file descriptions to which they refer.

Here is an example of what we see when we run the client and server programs:

```
$ ./fifo_seqnum_server &
[1] 5066
$ ./fifo_seqnum_client 3 Request a sequence of three numbers
0 Assigned sequence begins at 0
$ ./fifo_seqnum_client 2 Request a sequence of two numbers
3 Assigned sequence begins at 3
$ ./fifo_seqnum_client Request a single number
5
```

<span id="page-37-0"></span>**Listing 44-8:** Client for the sequence-number server

```
–––––––––––––––––––––––––––––––––––––––––––––––– pipes/fifo_seqnum_client.c
  #include "fifo_seqnum.h"
  static char clientFifo[CLIENT_FIFO_NAME_LEN];
  static void /* Invoked on exit to delete client FIFO */
q removeFifo(void)
  {
   unlink(clientFifo);
  }
  int
  main(int argc, char *argv[])
  {
   int serverFd, clientFd;
   struct request req;
   struct response resp;
```

```
 if (argc > 1 && strcmp(argv[1], "--help") == 0)
   usageErr("%s [seq-len...]\n", argv[0]);
   /* Create our FIFO (before sending request, to avoid a race) */
   umask(0); /* So we get the permissions we want */
w snprintf(clientFifo, CLIENT_FIFO_NAME_LEN, CLIENT_FIFO_TEMPLATE,
   (long) getpid());
   if (mkfifo(clientFifo, S_IRUSR | S_IWUSR | S_IWGRP) == -1
   && errno != EEXIST)
   errExit("mkfifo %s", clientFifo);
e if (atexit(removeFifo) != 0)
   errExit("atexit");
   /* Construct request message, open server FIFO, and send request */
r req.pid = getpid();
   req.seqLen = (argc > 1) ? getInt(argv[1], GN_GT_0, "seq-len") : 1;
t serverFd = open(SERVER_FIFO, O_WRONLY);
   if (serverFd == -1)
   errExit("open %s", SERVER_FIFO);
y if (write(serverFd, &req, sizeof(struct request)) !=
   sizeof(struct request))
   fatal("Can't write to server");
   /* Open our FIFO, read and display response */
u clientFd = open(clientFifo, O_RDONLY);
   if (clientFd == -1)
   errExit("open %s", clientFifo);
i if (read(clientFd, &resp, sizeof(struct response))
   != sizeof(struct response))
   fatal("Can't read response from server");
   printf("%d\n", resp.seqNum);
   exit(EXIT_SUCCESS);
  }
  –––––––––––––––––––––––––––––––––––––––––––––––– pipes/fifo_seqnum_client.c
```

# <span id="page-38-0"></span>**44.9 Nonblocking I/O**

As noted earlier, when a process opens one end of a FIFO, it blocks if the other end of the FIFO has not yet been opened. Sometimes, it is desirable not to block, and for this purpose, the O\_NONBLOCK flag can be specified when calling open():

```
fd = open("fifopath", O_RDONLY | O_NONBLOCK);
if (fd == -1)
 errExit("open");
```

If the other end of the FIFO is already open, then the O\_NONBLOCK flag has no effect on the open() call—it successfully opens the FIFO immediately, as usual. The O\_NONBLOCK flag changes things only if the other end of the FIFO is not yet open, and the effect depends on whether we are opening the FIFO for reading or writing:

-  If the FIFO is being opened for reading, and no process currently has the write end of the FIFO open, then the open() call succeeds immediately ( just as though the other end of the FIFO was already open).
-  If the FIFO is being opened FIFO for writing, and the other end of the FIFO is not already open for reading, then open() fails, setting errno to ENXIO.

The asymmetry of the O\_NONBLOCK flag depending on whether the FIFO is being opened for reading or for writing can be explained as follows. It is okay to open a FIFO for reading when there is no writer at the other end of the FIFO, since any attempt to read from the FIFO simply returns no data. However, attempting to write to a FIFO for which there is no reader would result in the generation of the SIGPIPE signal and an EPIPE error from write().

Table 44-1 summarizes the semantics of opening a FIFO, including the effects of O\_NONBLOCK described above.

|          | Type of open()   |                        | Result of open()         |
|----------|------------------|------------------------|--------------------------|
| open for | additional flags | other end of FIFO open | other end of FIFO closed |
|          | none (blocking)  | succeeds immediately   | blocks                   |
| reading  | O_NONBLOCK       | succeeds immediately   | succeeds immediately     |
|          | none (blocking)  | succeeds immediately   | blocks                   |
| writing  | O_NONBLOCK       | succeeds immediately   | fails (ENXIO)            |

**Table 44-1:** Semantics of open() for a FIFO

Using the O\_NONBLOCK flag when opening a FIFO serves two main purposes:

-  It allows a single process to open both ends of a FIFO. The process first opens the FIFO for reading specifying O\_NONBLOCK, and then opens the FIFO for writing.
-  It prevents deadlocks between processes opening two FIFOs.

A deadlock is a situation where two or more process are blocked because each is waiting on the other process(es) to complete some action. The two processes shown in [Figure 44-8](#page-40-0) are deadlocked. Each process is blocked waiting to open a FIFO for reading. This blocking would not happen if each process could perform its second step (opening the other FIFO for writing). This particular deadlock problem could be solved by reversing the order of steps 1 and 2 in process Y, while leaving the order in process X unchanged, or vice versa. However, such an arrangement of steps may not be easy to achieve in some applications. Instead, we can resolve the problem by having either process, or both, specify the O\_NONBLOCK flag when opening the FIFOs for reading.

| Process X                            | Process Y                            |
|--------------------------------------|--------------------------------------|
| 1. Open FIFO A for reading<br>blocks | 1. Open FIFO B for reading<br>blocks |
| 2. Open FIFO B for writing           | 2. Open FIFO A for writing           |

<span id="page-40-0"></span>**Figure 44-8:** Deadlock between processes opening two FIFOs

## **Nonblocking read() and write()**

The O\_NONBLOCK flag affects not only the semantics of open() but also—because the flag then remains set for the open file description—the semantics of subsequent read() and write() calls. We describe these effects in the next section.

Sometimes, we need to change the state of the O\_NONBLOCK flag for a FIFO (or another type of file) that is already open. Scenarios where this need may arise include the following:

-  We opened a FIFO using O\_NONBLOCK, but we want subsequent read() and write() calls to operate in blocking mode.
-  We want to enable nonblocking mode for a file descriptor that was returned by pipe(). More generally, we might want to change the nonblocking status of any file descriptor that was obtained other than from a call to open()—for example, one of the three standard descriptors that are automatically opened for each new program run by the shell or a file descriptor returned by socket().
-  For some application-specific purpose, we need to switch the setting of the O\_NONBLOCK setting of a file descriptor on and off.

For these purposes, we can use fcntl() to enable or disable the O\_NONBLOCK open file status flag. To enable the flag, we write the following (omitting error checking):

```
int flags;
   flags = fcntl(fd, F_GETFL); /* Fetch open files status flags */
   flags |= O_NONBLOCK; /* Enable O_NONBLOCK bit */
   fcntl(fd, F_SETFL, flags); /* Update open files status flags */
And to disable it, we write the following:
   flags = fcntl(fd, F_GETFL);
   flags &= ~O_NONBLOCK; /* Disable O_NONBLOCK bit */
   fcntl(fd, F_SETFL, flags);
```

# **44.10 Semantics of read() and write() on Pipes and FIFOs**

Table 44-2 summarizes the operation of read() for pipes and FIFOs, and includes the effect of the O\_NONBLOCK flag.

The only difference between blocking and nonblocking reads occurs when no data is present and the write end is open. In this case, a normal read() blocks, while a nonblocking read() fails with the error EAGAIN.

**Table 44-2:** Semantics of reading n bytes from a pipe or FIFO containing p bytes

| O_NONBLOCK | Data bytes available in pipe or FIFO (p) |                         |              |              |
|------------|------------------------------------------|-------------------------|--------------|--------------|
| enabled?   | p = 0, write end open                    | p = 0, write end closed | p < n        | p >= n       |
| No         | block                                    | return 0 (EOF)          | read p bytes | read n bytes |
| Yes        | fail (EAGAIN)                            | return 0 (EOF)          | read p bytes | read n bytes |

The impact of the O\_NONBLOCK flag when writing to a pipe or FIFO is made complex by interactions with the PIPE\_BUF limit. The write() behavior is summarized in Table 44-3.

**Table 44-3:** Semantics of writing n bytes to a pipe or FIFO

| O_NONBLOCK | Read end open                                                                                                                             |                                                                                                                                                                                                                  | Read end              |
|------------|-------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------|
| enabled?   | n <= PIPE_BUF                                                                                                                             | n > PIPE_BUF                                                                                                                                                                                                     | closed                |
| No         | Atomically write n bytes;<br>may block until sufficient<br>data is read for write() to<br>be performed                                    | Write n bytes; may block until<br>sufficient data read for write() to<br>complete; data may be interleaved<br>with writes by other processes                                                                     |                       |
| Yes        | If sufficient space is<br>available to immediately<br>write n bytes, then write()<br>succeeds atomically;<br>otherwise, it fails (EAGAIN) | If there is sufficient space to<br>immediately write some bytes,<br>then write between 1 and n bytes<br>(which may be interleaved with<br>data written by other processes);<br>otherwise, write() fails (EAGAIN) | SIGPIPE<br>+<br>EPIPE |

The O\_NONBLOCK flag causes a write() on a pipe or FIFO to fail (with the error EAGAIN) in any case where data can't be transferred immediately. This means that if we are writing up to PIPE\_BUF bytes, then the write() will fail if there is not sufficient space in the pipe or FIFO, because the kernel can't complete the operation immediately and can't perform a partial write, since that would break the requirement that writes of up to PIPE\_BUF bytes are atomic.

When writing more than PIPE\_BUF bytes at a time, a write is not required to be atomic. For this reason, write() transfers as many bytes as possible (a partial write) to fill up the pipe or FIFO. In this case, the return value from write() is the number of bytes actually transferred, and the caller must retry later in order to write the remaining bytes. However, if the pipe or FIFO is full, so that not even one byte can be transferred, then write() fails with the error EAGAIN.

## **44.11 Summary**

Pipes were the first method of IPC under the UNIX system, and they are used frequently by the shell, as well as in other applications. A pipe is a unidirectional, limitedcapacity byte stream that can be used for communication between related processes. Although blocks of data of any size can be written to a pipe, only writes that do not exceed PIPE\_BUF bytes are guaranteed to be atomic. As well as being used as a method of IPC, pipes can also be used for process synchronization.

When using pipes, we must be careful to close unused descriptors in order to ensure that reading processes detect end-of-file and writing processes receive the SIGPIPE signal or the EPIPE error. (Usually, it is easiest to have the application writing to a pipe ignore SIGPIPE and detect a "broken" pipe via the EPIPE error.)

The popen() and pclose() functions allow a program to transfer data to or from a standard shell command, without needing to handle the details of creating a pipe, execing a shell, and closing unused file descriptors.

FIFOs operate in exactly the same way as pipes, except that they are created using mkfifo(), have a name in the file system, and can be opened by any process with appropriate permissions. By default, opening a FIFO for reading blocks until another process opens the FIFO for writing, and vice versa.

In the course of this chapter, we looked at a number of related topics. First, we saw how to duplicate file descriptors in such a manner that the standard input or output of a filter can be bound to a pipe. While presenting a client-server example using FIFOs, we touched on a number of topics in client-server design, including the use of a well-known address for a server and iterative versus concurrent server design. In developing the example FIFO application, we noted that, although data transmitted through a pipe is a byte stream, it is sometimes useful for communicating processes to package the data into messages, and we looked at various ways in which this could be accomplished.

Finally, we noted the effect of the O\_NONBLOCK (nonblocking I/O) flag when opening and performing I/O on a FIFO. The O\_NONBLOCK flag is useful if we don't want to block while opening a FIFO. It is also useful if we don't want reads to block if no data is available, or writes to block if there is insufficient space within a pipe or FIFO.

## **Further information**

The implementation of pipes is discussed in [Bach, 1986] and [Bovet & Cesati, 2005]. Useful details about pipes and FIFOs can also be found in [Vahalia, 1996].

# **44.12 Exercises**

- **44-1.** Write a program that uses two pipes to enable bidirectional communication between a parent and child process. The parent process should loop reading a block of text from standard input and use one of the pipes to send the text to the child, which converts it to uppercase and sends it back to the parent via the other pipe. The parent reads the data coming back from the child and echoes it on standard output before continuing around the loop once more.
- **44-2.** Implement popen() and pclose(). Although these functions are simplified by not requiring the signal handling employed in the implementation of system() (Section 27.7), you will need to be careful to correctly bind the pipe ends to file streams in each process, and to ensure that all unused descriptors referring to the pipe ends are closed. Since children created by multiple calls to popen() may be running at one time, you will need to maintain a data structure that associates the file stream pointers allocated by popen() with the corresponding child process IDs. (If using an array for this purpose, the value returned by the fileno() function, which obtains the file descriptor corresponding to a file stream, can be used to index the

- array.) Obtaining the correct process ID from this structure will allow pclose() to select the child upon which to wait. This structure will also assist with the SUSv3 requirement that any still-open file streams created by earlier calls to popen() must be closed in the new child process.
- **44-3.** The server in Listing 44-7 (fifo\_seqnum\_server.c) always starts assigning sequence numbers from 0 each time it is started. Modify the program to use a backup file that is updated each time a sequence number is assigned. (The open() O\_SYNC flag, described in Section 4.3.1, may be useful.) At startup, the program should check for the existence of this file, and if it is present, use the value it contains to initialize the sequence number. If the backup file can't be found on startup, the program should create a new file and start assigning sequence numbers beginning at 0. (An alternative to this technique would be to use memory-mapped files, described in Chapter [49.](#page-140-0))
- **44-4.** Add code to the server in Listing 44-7 (fifo\_seqnum\_server.c) so that if the program receives the SIGINT or SIGTERM signals, it removes the server FIFO and terminates.
- **44-5.** The server in Listing 44-7 (fifo\_seqnum\_server.c) performs a second O\_WRONLY open of the FIFO so that it never sees end-of-file when reading from the reading descriptor (serverFd) of the FIFO. Instead of doing this, an alternative approach could be tried: whenever the server sees end-of-file on the reading descriptor, it closes the descriptor, and then once more opens the FIFO for reading. (This open would block until the next client opened the FIFO for writing.) What is wrong with this approach?
- **44-6.** The server in Listing 44-7 (fifo\_seqnum\_server.c) assumes that the client process is well behaved. If a misbehaving client created a client FIFO and sent a request to the server, but did not open its FIFO, then the server's attempt to open the client FIFO would block, and other client's requests would be indefinitely delayed. (If done maliciously, this would constitute a denial-of-service attack.) Devise a scheme to deal with this problem. Extend the server (and possibly the client in [Listing 44-8](#page-37-0)) accordingly.
- **44-7.** Write programs to verify the operation of nonblocking opens and nonblocking I/O on FIFOs (see Section [44.9\)](#page-38-0).

# **INTRODUCTION TO SYSTEM V IPC**

System V IPC is the label used to refer to three different mechanisms for interprocess communication:

-  Message queues can be used to pass messages between processes. Message queues are somewhat like pipes, but differ in two important respects. First, message boundaries are preserved, so that readers and writers communicate in units of messages, rather than via an undelimited byte stream. Second, each message includes an integer type field, and it is possible to select messages by type, rather than reading them in the order in which they were written.
-  Semaphores permit multiple processes to synchronize their actions. A semaphore is a kernel-maintained integer value that is visible to all processes that have the necessary permissions. A process indicates to its peers that it is performing some action by making an appropriate modification to the value of the semaphore.
-  Shared memory enables multiple processes to share the same region (called a segment) of memory (i.e., the same page frames are mapped into the virtual memory of multiple processes). Since access to user-space memory is a fast operation, shared memory is one of the quickest methods of IPC: once one process has updated the shared memory, the change is immediately visible to other processes sharing the same segment.

Although these three IPC mechanisms are quite diverse in function, there are good reasons for discussing them together. One reason is that they were developed together, first appearing in the late 1970s in Columbus UNIX. This was a Bell-internal UNIX implementation used for database and transaction-processing systems for telephone company record keeping and administration. Around 1983, these IPC mechanisms made their way into mainstream UNIX by appearing in System V hence the appellation System V IPC.

A more significant reason for discussing the System V IPC mechanisms together is that their programming interfaces share a number of common characteristics, so that many of the same concepts apply to all of these mechanisms.

> Because System V IPC is required by SUSv3 for XSI conformance, it is sometimes alternatively labeled XSI IPC.

This chapter provides an overview of the System V IPC mechanisms and details those features that are common to all three mechanisms. The three mechanisms are then discussed individually in the following chapters.

System V IPC is a kernel option that is configured via the CONFIG\_SYSVIPC option.

## **45.1 API Overview**

<span id="page-45-0"></span>Table 45-1 summarizes the header files and system calls used for working with System V IPC objects.

Some implementations require the inclusion of <sys/types.h> before including the header files shown in Table 45-1. Some older UNIX implementations may also require the inclusion of <sys/ipc.h>. (No versions of the Single UNIX Specification required these header files.)

> On most hardware architectures on which Linux is implemented, a single system call (ipc(2)) acts as the entry point to the kernel for all System V IPC operations, and all of the calls listed in Table 45-1 are actually implemented as library functions layered on top of this system call. (Two exceptions to this arrangement are Alpha and IA-64, where the functions listed in the table really are implemented as individual system calls.) This somewhat unusual approach is an artifact of the initial implementation of System V IPC as a loadable kernel module. Although they are actually library functions on most Linux architectures, throughout this chapter, we'll refer to the functions in Table 45-1 as system calls. Only implementers of C libraries need to use ipc(2); any other use in applications is not portable.

**Table 45-1:** Summary of programming interfaces for System V IPC objects

| Interface                 | Message queues                                  | Semaphores                       | Shared memory                     |
|---------------------------|-------------------------------------------------|----------------------------------|-----------------------------------|
| Header file               | <sys msg.h=""></sys>                            | <sys sem.h=""></sys>             | <sys shm.h=""></sys>              |
| Associated data structure | msqid_ds                                        | semid_ds                         | shmid_ds                          |
| Create/open object        | msgget()                                        | semget()                         | shmget() + shmat()                |
| Close object              | (none)                                          | (none)                           | shmdt()                           |
| Control operations        | msgctl()                                        | semctl()                         | shmctl()                          |
| Performing IPC            | msgsnd()—write message<br>msgrcv()—read message | semop()—test/adjust<br>semaphore | access memory in<br>shared region |

## **Creating and opening a System V IPC object**

Each System V IPC mechanism has an associated get system call (msgget(), semget(), or shmget()), which is analogous to the open() system call used for files. Given an integer key (analogous to a filename), the get call either:

-  creates a new IPC object with the given key and returns a unique identifier for that object; or
-  returns the identifier of an existing IPC object with the given key.

We'll (loosely) term the second use opening an existing IPC object. In this case, all that the get call is doing is converting one number (the key) into another number (the identifier).

> In the context of System V IPC, the object doesn't carry any of the connotations associated with object-oriented programming. The term merely serves to distinguish the System V IPC mechanisms from files. Although there are several analogies between files and System V IPC objects, the use of IPC objects differs in several important respects from the standard UNIX file I/O model, and this is a source of some complications when using the System V IPC mechanisms.

An IPC identifier is analogous to a file descriptor in that it is used in all subsequent system calls to refer to the IPC object. There is, however, an important semantic difference. Whereas a file descriptor is a process attribute, an IPC identifier is a property of the object itself and is visible system-wide. All processes accessing the same object use the same identifier. This means that if we know an IPC object already exists, we can skip the get call, provided we have some other means of knowing the identifier of the object. For example, the process that created the object might write the identifier to a file that can then be read by other processes.

The following example shows how to create a System V message queue:

```
id = msgget(key, IPC_CREAT | S_IRUSR | S_IWUSR);
if (id == -1)
 errExit("msgget");
```

As with all of the get calls, the key is the first argument, and the identifier is returned as the function result. We specify the permissions to be placed on the new object as part of the final (flags) argument to the get call, using the same bit-mask constants as are used for files (Table 15-4, on page 295). In the above example, permission is granted to just the owner of the object to read and write messages on the queue.

The process umask (Section 15.4.6) is not applied to the permissions placed on a newly created IPC object.

> Several UNIX implementations define the following bit-mask constants for IPC permissions: MSG\_R, MSG\_W, SEM\_R, SEM\_A, SHM\_R, and SHM\_W. These correspond to owner (user) read and write permissions for each IPC mechanism. To get the corresponding group and other permission bit masks, these constants can be rightshifted 3 and 6 bits. These constants are not specified by SUSv3, which employs the same bit masks as are used for files, and are not defined in glibc headers.

Each process that wants to access the same IPC object performs a get call specifying the same key in order to obtain the same identifier for that object. We consider how to choose a key for an application in Section [45.2.](#page-48-0)

If no IPC object corresponding to the given key currently exists, and IPC\_CREAT (analogous to the open() O\_CREAT flag) was specified as part of the flags argument, then the get call creates a new IPC object. If no corresponding IPC object currently exists, and IPC\_CREAT was not specified (and the key was not specified as IPC\_PRIVATE, described in Section [45.2\)](#page-48-0), then the get call fails with the error ENOENT.

A process can guarantee that it is the one creating an IPC object by specifying the IPC\_EXCL flag (analogous to the open() O\_EXCL flag). If IPC\_EXCL is specified and the IPC object corresponding to the given key already exists, then the get call fails with the error EEXIST.

## **IPC object deletion and object persistence**

The ctl system call (msgctl(), semctl(), shmctl()) for each System V IPC mechanism performs a range of control operations for the object. Many of these operations are specific to the IPC mechanism, but a few are generic to all IPC mechanisms. An example of a generic control operation is IPC\_RMID, which is used to delete an object. For example, we can use the following call to delete a shared memory object:

```
if (shmctl(id, IPC_RMID, NULL) == -1)
 errExit("shmctl");
```

For message queues and semaphores, deletion of the IPC object is immediate, and any information contained within the object is destroyed, regardless of whether any other process is still using the object. (This is one of a number of points where the operation of System IPC objects is not analogous to files. In Section 18.3, we saw that if we remove the last link to a file, then the file is actually removed only after all open file descriptors referring to it have been closed.)

Deletion of shared memory objects occurs differently. Following the shmctl(id, IPC\_RMID, NULL) call, the shared memory segment is removed only after all processes using the segment detach it (using shmdt()). (This is much closer to the situation with file deletion.)

System V IPC objects have kernel persistence. Once created, an object continues to exist until it is explicitly deleted or the system is shut down. This property of System V IPC objects can be advantageous. It is possible for a process to create an object, modify its state, and then exit, leaving the object to be accessed by some process that is started at a later time. It can also be disadvantageous for the following reasons:

-  There are system-imposed limits on the number of IPC objects of each type. If we fail to remove unused objects, we may eventually encounter application errors as a result of reaching these limits.
-  When deleting a message queue or semaphore object, a multiprocess application may not be able to easily determine which will be the last process requiring access to the object, and thus when the object can be safely deleted. The problem is that these objects are connectionless—the kernel doesn't keep a record of which processes have the object open. (This disadvantage doesn't apply for shared memory segments, because of their different deletion semantics, described above.)

## <span id="page-48-0"></span>**45.2 IPC Keys**

<span id="page-48-1"></span>System V IPC keys are integer values represented using the data type key\_t. The IPC get calls translate a key into the corresponding integer IPC identifier. These calls guarantee that if we create a new IPC object, then that object will have a unique identifier, and that if we specify the key of an existing object, then we'll always obtain the (same) identifier for that object. (Internally, the kernel maintains data structures mapping keys to identifiers for each IPC mechanism, as described in Section [45.5](#page-54-0).)

So, how do we provide a unique key—one that guarantees that we won't accidentally obtain the identifier of an existing IPC object used by some other application? There are three possibilities:

-  Randomly choose some integer key value, which is typically placed in a header file included by all programs using the IPC object. The difficulty with this approach is that we may accidentally choose a value used by another application.
-  Specify the IPC\_PRIVATE constant as the key value to the get call when creating the IPC object, which always results in the creation of a new IPC object that is guaranteed to have a unique key.
-  Employ the ftok() function to generate a (likely unique) key.

Using either IPC\_PRIVATE or ftok() is the usual technique.

## **Generating a unique key with IPC\_PRIVATE**

When creating a new IPC object, the key may be specified as IPC\_PRIVATE, as follows:

```
id = msgget(IPC_PRIVATE, S_IRUSR | S_IWUSR);
```

In this case, it is not necessary to specify the IPC\_CREAT or IPC\_EXCL flags.

This technique is especially useful in multiprocess applications where the parent process creates the IPC object prior to performing a fork(), with the result that the child inherits the identifier of the IPC object. We can also use this technique in clientserver applications (i.e., those involving unrelated processes), but the clients must have a means of obtaining the identifiers of the IPC objects created by the server (and vice versa). For example, after creating an IPC object, the server could then write its identifier to a file that can be read by the clients.

## **Generating a unique key with ftok()**

The ftok() (file to key) function returns a key value suitable for use in a subsequent call to one of the System V IPC get system calls.

```
#include <sys/ipc.h>
key_t ftok(char *pathname, int proj);
                                  Returns integer key on success, or –1 on error
```

This key value is generated from the supplied pathname and proj value using an implementation-defined algorithm. SUSv3 makes the following requirements:

-  Only the least significant 8 bits of proj are employed by the algorithm.
-  The application must ensure that the pathname refers to an existing file to which stat() can be applied (otherwise, ftok() returns –1).
-  If different pathnames (links) referring to the same file (i.e., i-node) are supplied to ftok() with the same proj value, the same key value must be returned.

To put things another way, ftok() uses the i-node number rather than the name of the file to generate the key value. (Because the ftok() algorithm depends on the i-node number, the file should not be removed and re-created during the life of the application, since it is likely that the file will be re-created with a different i-node number.) The purpose of the proj value is simply to allow us to generate multiple keys from the same file, which is useful when an application needs to create multiple IPC objects of the same type. Historically, the proj argument was of type char, and it is often specified as such in calls to ftok().

> SUSv3 leaves the behavior of ftok() unspecified if proj is 0. Under AIX 5.1, ftok() returns –1 if proj is specified as 0. On Linux, this value has no special meaning. Nevertheless, portable applications should avoid specifying proj as 0; this still leaves a choice of 255 other values.

Normally, the pathname given to ftok() refers to one of the files or directories that forms part of, or is created by, the application, and cooperating processes pass the same pathname to ftok().

On Linux, the key returned by ftok() is a 32-bit value, created by taking the least significant 8 bits from the proj argument, the least significant 8 bits of the device number (i.e., the minor device number) of the device containing the file system in which the file resides, and the least significant 16 bits of the i-node number of the file referred to by pathname. (The last two pieces of information are obtained by calling stat() on pathname.)

The glibc ftok() algorithm is similar to that employed on other UNIX implementations, and suffers a similar limitation: there is a (very small) possibility that two different files could yield the same key value. This can occur because there is a chance that the least significant bits of an i-node number could be the same for two files on different file systems, coupled with the possibility that two different disk devices (on a system with multiple disk controllers) could have the same minor device number. However, in practice, the possibility of colliding key values for different applications is small enough that the use of ftok() for key generation is a viable technique.

A typical usage of ftok() is the following:

```
key_t key;
int id;
key = ftok("/mydir/myfile", 'x');
if (key == -1)
 errExit("ftok");
```

```
id = msgget(key, IPC_CREAT | S_IRUSR | S_IWUSR);
if (id == -1)
 errExit("msgget");
```

# **45.3 Associated Data Structure and Object Permissions**

<span id="page-50-0"></span>The kernel maintains an associated data structure for each instance of a System V IPC object. The form of this data structure varies according to the IPC mechanism (message queue, semaphore, or shared memory) and is defined in the corresponding header file for the IPC mechanism (see Table 45-1). We discuss mechanismspecific details of each of these data structures in the following chapters.

The associated data structure for an IPC object is initialized when the object is created via the appropriate get system call. Once the object has been created, a program can obtain a copy of this data structure using the appropriate ctl system call, by specifying an operation type of IPC\_STAT. Conversely, some parts of the data structure can be modified using the IPC\_SET operation.

As well as data specific to the type of IPC object, the associated data structure for all three IPC mechanisms includes a substructure, ipc\_perm, that holds information used to determine permissions granted on the object:

```
struct ipc_perm {
 key_t __key; /* Key, as supplied to 'get' call */
 uid_t uid; /* Owner's user ID */
 gid_t gid; /* Owner's group ID */
 uid_t cuid; /* Creator's user ID */
 gid_t cgid; /* Creator's group ID */
 unsigned short mode; /* Permissions */
 unsigned short __seq; /* Sequence number */
};
```

SUSv3 mandates all of the ipc\_perm fields shown here, except \_\_key and \_\_seq. However, most UNIX implementations provide some version of these fields.

The uid and gid fields specify the ownership of the IPC object. The cuid and cgid fields hold the user and group IDs of the process that created the object. Initially, the corresponding user and creator ID fields have the same values, which are taken from the effective IDs of the calling processes. The creator IDs are immutable, but the owner IDs can be changed via the IPC\_SET operation. The following code demonstrates how to change the uid field for a shared memory segment (the associated data structure is of type shmid\_ds):

```
struct shmid_ds shmds;
if (shmctl(id, IPC_STAT, &shmds) == -1) /* Fetch from kernel */
 errExit("shmctl");
shmds.shm_perm.uid = newuid; /* Change owner UID */
if (shmctl(id, IPC_SET, &shmds) == -1) /* Update kernel copy */
 errExit("shmctl");
```

The mode field of the ipc\_perm substructure holds the permissions mask for the IPC object. These permissions are initialized using the lower 9 bits of the flags specified in the get system call used to create the object, but can be changed subsequently using the IPC\_SET operation.

As with files, permissions are broken into three categories—owner (also known as user), group, and other—and it is possible to specify different permissions for each category. There are, however, some notable differences from the scheme used for files:

-  Only read and write permissions are meaningful for IPC objects. (For semaphores, write permission is commonly referred to as alter permission.) Execute permission is meaningless, and is ignored when performing most access checks.
-  Permission checks are made according to a process's effective user ID, effective group IDs, and supplementary group IDs. (This contrasts with file-system permission checks on Linux, which are performed using the process's file-system IDs, as described in Section 9.5.)

The precise rules governing the permissions a process is granted on an IPC object are as follows:

- 1. If the process is privileged (CAP\_IPC\_OWNER), then all permissions are granted on the IPC object.
- 2. If the effective user ID of the process matches either the owner or the creator user ID of the IPC object, then the process is granted the permissions defined for the owner (user) of the object.
- 3. If the effective group ID or any of the supplementary group IDs of the process match either the owner group ID or the creator group ID of the IPC object, then the process is granted the group permissions defined for the object.
- 4. Otherwise, the process is granted the permissions defined for other.

In the kernel code, the above tests are constructed so that the test to see whether a process is privileged is performed only if the process is not granted the permissions it needs via one of the other tests. This is done to avoid unnecessarily setting the ASU process accounting flag, which indicates that the process made use of superuser privileges (Section 28.1).

Note that neither the use of the IPC\_PRIVATE key value nor the presence of IPC\_EXCL flag has any bearing on which processes may access an IPC object; such access is determined solely by the ownership and permissions of the object.

How read and write permissions are interpreted for an object, and whether they are required, depend on the type of object and on the operation being performed.

When a get call is performed to obtain the identifier of an existing IPC object, an initial permission check is made to ascertain whether the permissions specified in the flags argument are compatible with those on the existing object. If not, then the get call fails with the error EACCES. (Except as otherwise noted, this error code is also returned when permissions are denied in each of the cases listed below.) To illustrate, consider the example of two different users in the same group, with one user creating a message queue using the following call:

```
msgget(key, IPC_CREAT | S_IRUSR | S_IWUSR | S_IRGRP);
 /* rw-r----- */
```

An attempt by the second user to obtain an identifier for this message queue using the following call would fail, since the user is not permitted write access to the message queue:

```
msgget(key, S_IRUSR | S_IWUSR);
```

The second user could bypass this check by specifying 0 for the second argument of the msgget() call, in which case an error would occur only when the program attempted an operation requiring write permission on the IPC object (e.g., writing a message with msgsnd()).

> The get call represents the one case where execute permission is not ignored. Even though it has no meaning for IPC objects, if execute permission is requested in a get call for an existing object, then a check is made to see if that permission is granted.

The permissions required for other common operations are as follows:

-  To retrieve information from the object (e.g., to read a message from a message queue, obtain the value of a semaphore, or attach a shared memory segment for read access) requires read permission.
-  To update information within the object (e.g., to write a message to a message queue, change the value of a semaphore, or attach a shared memory segment for write access) requires write permission.
-  To obtain a copy of the associated data structure for an IPC object (the IPC\_STAT ctl operation) requires read permission.
-  To remove an IPC object (the IPC\_RMID ctl operation) or change its associated data structure (the IPC\_SET ctl operation) requires neither read nor write permission. Rather, the calling process must either be privileged (CAP\_SYS\_ADMIN) or have an effective user ID matching either the owner user ID or the creator user ID of the object (otherwise, the error EPERM results).

It is possible to set the permissions on an IPC object so that the owner or creator can no longer use IPC\_STAT to obtain the associated data structure containing the object permissions (which means that the object won't be displayed by the ipcs(1) command described in Section [45.6](#page-57-0)), although IPC\_SET can still be used to change them.

Various other mechanism-specific operations require read or write permission, or the CAP\_IPC\_OWNER capability. We note the required permissions in the following chapters as the operations are described.

## **45.4 IPC Identifiers and Client-Server Applications**

In client-server applications, the server typically creates the System V IPC objects, while the client simply accesses them. In other words, the server performs an IPC get call specifying the flag IPC\_CREAT, while the client omits this flag in its get call.

Suppose a client engages in an extended dialogue with a server, with multiple IPC operations being performed by each process (e.g., multiple messages exchanged, a sequence of semaphore operations, or multiple updates to shared memory). What happens if the server process crashes or is deliberately halted and then restarted? At this point, it would make no sense to blindly reuse the existing IPC object created by the previous server process, since the new server process has no knowledge of the historical information associated with the current state of the IPC object. (For example, there may be a secondary request within a message queue that was sent by a client in response to an earlier message from the old server process.)

In such a scenario, the only option for the server may be to abandon all existing clients, delete the IPC objects created by the previous server process, and create new instances of the IPC objects. A newly started server handles the possibility that a previous instance of the server terminated prematurely by first trying to create an IPC object by specifying both the IPC\_CREAT and the IPC\_EXCL flags within the get call. If the get call fails because an object with the specified key already exists, then the server assumes the object was created by an old server process; it therefore uses the IPC\_RMID ctl operation to delete the object, and once more performs a get call to create the object. (This may be combined with other steps to ensure that another server process is not currently running, such as those described in Section 55.6.) For a message queue, these steps might appear as shown in [Listing 45-1.](#page-53-0)

<span id="page-53-0"></span>**Listing 45-1:** Cleanup of IPC objects within a server

```
––––––––––––––––––––––––––––––––––––––––––––––––– svipc/svmsg_demo_server.c
#include <sys/types.h>
#include <sys/ipc.h>
#include <sys/msg.h>
#include <sys/stat.h>
#include "tlpi_hdr.h"
#define KEY_FILE "/some-path/some-file"
 /* Should be an existing file or one
 that this program creates */
int
main(int argc, char *argv[])
{
 int msqid;
 key_t key;
 const int MQ_PERMS = S_IRUSR | S_IWUSR | S_IWGRP; /* rw--w---- */
 /* Optional code here to check if another server process is
 already running */
 /* Generate the key for the message queue */
 key = ftok(KEY_FILE, 1);
 if (key == -1)
 errExit("ftok");
```

```
 /* While msgget() fails, try creating the queue exclusively */
 while ((msqid = msgget(key, IPC_CREAT | IPC_EXCL | MQ_PERMS)) == -1) {
 if (errno == EEXIST) { /* MQ with the same key already
 exists - remove it and try again */
 msqid = msgget(key, 0);
 if (msqid == -1)
 errExit("msgget() failed to retrieve old queue ID");
 if (msgctl(msqid, IPC_RMID, NULL) == -1)
 errExit("msgget() failed to delete old queue");
 printf("Removed old message queue (id=%d)\n", msqid);
 } else { /* Some other error --> give up */
 errExit("msgget() failed");
 }
 }
 /* Upon loop exit, we've successfully created the message queue,
 and we can then carry on to do other work... */
 exit(EXIT_SUCCESS);
}
––––––––––––––––––––––––––––––––––––––––––––––––– svipc/svmsg_demo_server.c
```

Even if a restarted server re-created the IPC objects, there still would be a potential problem if supplying the same key to the get call always generated the same identifier whenever a new IPC object was created. Consider the solution just outlined from the point of view of the client. If the IPC objects re-created by the server use the same identifiers, then the client would have no way of becoming aware that the server has been restarted and that the IPC objects don't contain the expected historical information.

To solve this problem, the kernel employs an algorithm (described in the next section) that normally ensures that when a new IPC object is created, the object's identifier will be different, even when the same key is supplied. Consequently, any clients of the old server process that attempt to use the old identifier will receive an error from the relevant IPC system call.

> Solutions such as that shown in [Listing 45-1](#page-53-0) don't completely solve the problem of identifying a server restart when using System V shared memory, since a shared memory object is deleted only when all processes have detached it from their virtual address space. However, shared memory objects are typically used in conjunction with System V semaphores, which are immediately deleted in response to an IPC\_RMID operation. This means that a client process will become aware of a server restart when it tries to access the deleted semaphore object.

# <span id="page-54-0"></span>**45.5 Algorithm Employed by System V IPC get Calls**

[Figure 45-1](#page-55-0) shows some of the structures used internally by the kernel to represent information about System V IPC objects (in this case semaphores, but the details are similar for other IPC mechanisms), including the fields used to calculate IPC keys. For each IPC mechanism (shared memory, message queue, or semaphore), the kernel maintains an associated ipc\_ids structure that records various global information about all instances of that IPC mechanism. This information includes a dynamically sized array of pointers, entries, to the associated data structure for each object instance (semid\_ds structures in the case of semaphores). The current size of the entries array is recorded in the size field, with the max\_id field holding the index of the highest currently in-use element.

```
ipc_ids structure (sem_ids)
+----------------------------------+                 +----------------------------------+              
| size   = 128                     |       |-------->| sem_perm.__key = 0x4d0731db      |                                              
+----------------------------------+       |         +----------------------------------+       
| in_use = 2                       |       |         |                                  |
+----------------------------------+       |         +----------------------------------+
| max_id = 3                       |       |         | sem_perm.__seq = 9               |  
+----------------------------------+       |         +----------------------------------+<--------------|
| seq    = 10                      |       |         |                                  |               |
+----------------------------------+       |         +----------------------------------+               |
|              entries             |       |                                                            |
+-----------+----------------------+       |                                                         associated data structures (semid_ds)
| entries   |          0           |-------|                                                            |
+           |+---------------------+                +-----------+----------------------+                |
|           |          1           |       |------->|sem_perm.__key = 0x4b079002       |                |
+           +----------------------+       |        +----------------------------------+                |
|           |          2           |-------|        |                                  |<---------------|
+           +----------------------+                +----------------------------------+                  
|           |          3           |                | sem_perm.__seq = 5               |                 
+-----------+----------------------+                +----------------------------------+                      
|           |                      |                |                                  |                   
+-----------+----------------------+                +----------------------------------+                 
                                                       
```

<span id="page-55-1"></span><span id="page-55-0"></span>**Figure 45-1:** Kernel data structures used to represent System V IPC (semaphore) objects

When an IPC get call is made, the algorithm used on Linux (other systems use similar algorithms) is approximately as follows:

- 1. The list of associated data structures (pointed to by elements of the entries array) is searched for one whose key field matches that specified in the get call.
  - a) If no match is found, and IPC\_CREAT was not specified, then the error ENOENT is returned.
  - b) If a match is found, but both IPC\_CREAT and IPC\_EXCL were specified, then the error EEXIST is returned.
  - c) Otherwise, if a match is found, then the following step is skipped.
- 2. If no match was found, and IPC\_CREAT was specified, then a new mechanism-specific associated data structure (semid\_ds in [Figure 45-1\)](#page-55-0) is allocated and initialized. This also involves updating various fields of the ipc\_ids structure, and may involve resizing the entries array. A pointer to the new structure is placed in the first free element of entries. Two substeps are included as part of this initialization:
  - a) The key value supplied in the get call is copied into the xxx\_perm.\_\_key field of the newly allocated structure.
  - b) The current value of the seq field of the ipc\_ids structure is copied into the xxx\_perm.\_\_seq field of the associated data structure, and the seq field is incremented by one.

3. The identifier for the IPC object is calculated using the following formula:

```
identifier = index + xxx_perm.__seq * SEQ_MULTIPLIER
```

In the formula used to calculate the IPC identifier, index is the index of this object instance within the entries array, and SEQ\_MULTIPLIER is a constant defined with the value 32,768 (IPCMNI in the kernel source file include/linux/ipc.h). For example, in [Figure 45-1,](#page-55-0) the identifier generated for the semaphore with the key value 0x4b079002 would be (2 + 5 \* 32,768) = 163,842.

Note the following points about the algorithm employed by the get calls:

 Even if a new IPC object is created with the same key, it will almost certainly have a different identifier, since the identifier is calculated based on the seq value saved in the associated data structure, and this value is incremented by one during the creation of each object of this type.

> The algorithm employed within the kernel wraps the seq value back to 0 when it reaches the value (INT\_MAX / IPCMNI)—that is, 2,147,483,647 / 32,768 = 65,535. Thus, a new IPC object could have the same identifier as a previous object if 65,535 objects are created in the interim and the new object reuses the same element in the entries array as the previous object (i.e., this element must also have been freed in the interim). However, the chances of this occurring are small.

-  The algorithm generates a distinct set of identifier values for each index of the entries array.
-  Since the constant IPCMNI defines an upper limit on the number of System V objects of each type, the algorithm guarantees that each existing IPC object has a unique identifier.
-  Given an identifier value, the corresponding index into the entries array can be quickly calculated using this equation:

```
index = identifier % SEQ_MULTIPLIER
```

Being able to rapidly perform this calculation is necessary for the efficient operation of those IPC system calls that are supplied with the identifier of an IPC object (i.e., those calls in Table 45-1 other than the get calls).

In passing, it is worth noting that two different errors can result if a process makes an IPC system call (e.g., msgctl(), semop(), or shmat()) that specifies an identifier that doesn't correspond to an existing object. If the corresponding index of entries is empty, the error EINVAL results. If the index points to an associated data structure, but the sequence number stored in that structure doesn't yield the same identifier value, then it is assumed that an old object pointed to by this array index has been deleted and the index reused. This scenario is diagnosed with the error EIDRM.

## <span id="page-57-0"></span>**45.6 The ipcs and ipcrm Commands**

The ipcs and ipcrm commands are the System V IPC analogs of the ls and rm file commands. Using ipcs, we can obtain information about IPC objects on the system. By default, ipcs displays all objects, as in the following example:

#### \$ **ipcs**

```
------ Shared Memory Segments --------
key shmid owner perms bytes nattch status
0x6d0731db 262147 mtk 600 8192 2
------ Semaphore Arrays --------
key semid owner perms nsems
0x6107c0b8 0 cecilia 660 6
0x6107c0b6 32769 britta 660 1
------ Message Queues --------
key msqid owner perms used-bytes messages
0x71075958 229376 cecilia 620 12 2
```

On Linux, ipcs(1) displays information only about IPC objects for which we have read permission, regardless of whether we own the objects. On some UNIX implementations, ipcs shows the same behavior as on Linux. However, on other implementations, ipcs displays all objects regardless of whether read permission is granted to the user.

By default, for each object, ipcs displays the key, the identifier, the owner, and the permissions (expressed as an octal number), followed by information specific to the object:

-  For shared memory, ipcs displays the size of the shared memory region, the number of processes that currently have the shared memory region attached to their virtual address space, and status flags. The status flags indicate whether the region has been locked into RAM to prevent swapping (Section [48.7](#page-134-0)) and whether the region has been marked to be destroyed when all processes have detached it.
-  For semaphores, ipcs displays the size of the semaphore set.
-  For message queues, ipcs displays the total number of bytes of data and the number of messages in the queue.

The ipcs(1) manual page documents various options for displaying other information about IPC objects.

The ipcrm command deletes an IPC object. The general form of this command is one of the following:

```
$ ipcrm -X key
$ ipcrm -x id
```

In the above, we either specify key as an IPC object key or id as an IPC object identifier, and the letter x is replaced by an uppercase or lowercase q (for message queues), s (for semaphores), or m (for shared memory). Thus, we could use the following command to delete the semaphore set with the identifier 65538:

```
$ ipcrm -s 65538
```

# **45.7 Obtaining a List of All IPC Objects**

<span id="page-58-0"></span>Linux provides two nonstandard methods of obtaining a list of all IPC objects on the system:

-  files within the /proc/sysvipc directory that list all IPC objects; and
-  the use of Linux-specific ctl calls.

We describe the files in /proc/sysvipc directory here, and defer discussion of the ctl calls until Section [46.6](#page-74-0), where we provide an example program that lists all System V message queues on the system.

> Some other UNIX implementations have their own nonstandard methods of obtaining a list of all IPC identifiers; for example, Solaris provides the msgids(), semids(), and shmids() system calls for this purpose.

Three read-only files in the /proc/sysvipc directory provide the same information as can be obtained via ipcs:

-  /proc/sysvipc/msg lists all messages queues and their attributes.
-  /proc/sysvipc/sem lists all semaphore sets and their attributes.
-  /proc/sysvipc/shm lists all shared memory segments and their attributes.

Unlike the ipcs command, these files always show all objects of the corresponding type, regardless of whether read permission is available on the objects.

An example of the contents of /proc/sysvipc/sem is the following (with some white space removed to fit this example on the page):

```
$ cat /proc/sysvipc/sem
key semid perms nsems uid gid cuid cgid otime ctime
 0 16646144 600 4 1000 100 1000 100 0 1010166460
```

The three /proc/sysvipc files provide a (nonportable) method for programs and scripts to walk through a list of all of the existing IPC objects of a given type.

> The best that we can achieve by way of a portable approach to obtaining a list of all IPC objects of a given type is to parse the output of ipcs(1).

## **45.8 IPC Limits**

Since System V IPC objects consume system resources, the kernel places various limits on each class of IPC object in order to prevent resources from being exhausted. The methods for placing limits on System V IPC objects are not specified by SUSv3, but most UNIX implementations (including Linux) follow a similar framework for the types of limits that may be placed. As we cover each System V IPC mechanism in the following chapters, we discuss the associated limits and note differences from other UNIX implementations.

Although the types of limits that can be placed on each class of IPC object are generally similar across various UNIX implementations, the methods of viewing and changing these limits are not. The methods described in the following chapters are Linux-specific (they generally involve the use of files in the /proc/sys/kernel directory); things are done differently on other implementations.

On Linux, the ipcs –l command can be used to list the limits on each of the IPC mechanisms. Programs can employ the Linux-specific IPC\_INFO ctl operation to retrieve the same information.

## **45.9 Summary**

System V IPC is the name given to three IPC mechanisms that first appeared widely in System V, and have subsequently been ported to most UNIX implementations and incorporated into various standards. The three IPC mechanisms are message queues, which allow processes to exchange messages; semaphores, which allow processes to synchronize access to shared resources; and shared memory, which allows two or more processes to share the same pages of memory.

The three IPC mechanisms have many similarities in their APIs and semantics. For each IPC mechanism, a get system call creates or opens an object. Given an integer key, the get calls return an integer identifier used to refer to the object in subsequent system calls. Each IPC mechanism also has a corresponding a ctl call that is used to delete an object and to retrieve and modify various attributes (e.g., ownership and permissions) in an object's associated data structure.

The algorithm used to generate identifiers for new IPC objects is designed to minimize the possibility of the same identifier being (immediately) reused if an object is deleted, even if the same key is used to create a new object. This enables client-server applications to function correctly—a restarted server process is able to detect and remove IPC objects created by its predecessor, and this action invalidates the identifiers held by any clients of the previous server process.

The ipcs command lists the System V IPC objects that currently exist on the system. The ipcrm command is used to remove System IPC objects.

On Linux, files in the /proc/sysvipc directory can be used to obtain information about all of the System V IPC objects on the system.

Each IPC mechanism has an associated set of limits that can be used to avoid exhaustion of system resources by preventing the creation of an arbitrary number of IPC objects. Various files under the /proc/sys/kernel directory can be used to view and modify these limits.

## **Further information**

Information about the implementation of System V IPC on Linux can be found in [Maxwell, 1999] and [Bovet & Cesati, 2005]. [Goodheart & Cox, 1994] describes the implementation of System V IPC for System V Release 4.

# **45.10 Exercises**

- **45-1.** Write a program to verify that the algorithm employed by ftok() uses the file's i-node number, minor device number, and proj value, as described in Section [45.2](#page-48-0). (It is sufficient to print all of these values, as well as the return value from ftok(), in hexadecimal, and inspect the results for a few examples.)
- **45-2.** Implement ftok().
- **45-3.** Verify (by experiment) the statements made in Section [45.5](#page-54-0) about the algorithm used to generate System V IPC identifiers.

# **SYSTEM V MESSAGE QUEUES**

This chapter describes System V message queues. Message queues allow processes to exchange data in the form of messages. Although message queues are similar to pipes and FIFOs in some respects, they also differ in important ways:

-  The handle used to refer to a message queue is the identifier returned by a call to msgget(). These identifiers are not the same as the file descriptors used for most other forms of I/O on UNIX systems.
-  Communication via message queues is message-oriented; that is, the reader receives whole messages, as written by the writer. It is not possible to read part of a message, leaving the remainder in the queue, or to read multiple messages at a time. This contrasts with pipes, which provide an undifferentiated stream of bytes (i.e., with pipes, the reader can read an arbitrary number of bytes at a time, irrespective of the size of data blocks written by the writer).
-  In addition to containing data, each message has an integer type. Messages can be retrieved from a queue in first-in, first-out order or retrieved by type.

At the end of this chapter (Section [46.9\)](#page-84-0), we summarize a number of limitations of System V message queues. These limitations lead us to the conclusion that, where possible, new applications should avoid the use of System V message queues in favor of other IPC mechanisms such as FIFOs, POSIX message queues, and sockets. However, when message queues were initially devised, these alternative mechanisms were unavailable or were not widespread across UNIX implementations. Consequently, there are various existing applications that employ message queues, and this fact forms one of the primary motivations for describing them.

## **46.1 Creating or Opening a Message Queue**

The msgget() system call creates a new message queue or obtains the identifier of an existing queue.

```
#include <sys/types.h> /* For portability */
#include <sys/msg.h>
int msgget(key_t key, int msgflg);
                   Returns message queue identifier on success, or –1 on error
```

The key argument is a key generated using one of the methods described in Section [45.2](#page-48-1) (i.e., usually the value IPC\_PRIVATE or a key returned by ftok()). The msgflg argument is a bit mask that specifies the permissions (Table 15-4, on page 295) to be placed on a new message queue or checked against an existing queue. In addition, zero or more of the following flags can be ORed (|) in msgflg to control the operation of msgget():

IPC\_CREAT

If no message queue with the specified key exists, create a new queue.

IPC\_EXCL

If IPC\_CREAT was also specified, and a queue with the specified key already exists, fail with the error EEXIST.

These flags are described in more detail in Section [45.1.](#page-45-0)

The msgget() system call begins by searching the set of all existing message queues for one with the specified key. If a matching queue is found, the identifier of that queue is returned (unless both IPC\_CREAT and IPC\_EXCL were specified in msgflg, in which case an error is returned). If no matching queue was found and IPC\_CREAT was specified in msgflg, a new queue is created and its identifier is returned.

The program in [Listing 46-1](#page-61-0) provides a command-line interface to the msgget() system call. The program permits the use of command-line options and arguments to specify all possibilities for the key and msgflg arguments to msgget(). Details of the command format accepted by this program are shown in the usageError() function. Upon successful queue creation, the program prints the queue identifier. We demonstrate the use of this program in Section [46.2.2](#page-66-0).

```
Listing 46-1: Using msgget()
–––––––––––––––––––––––––––––––––––––––––––––––––––––– svmsg/svmsg_create.c
#include <sys/types.h>
#include <sys/ipc.h>
#include <sys/msg.h>
#include <sys/stat.h>
#include "tlpi_hdr.h"
```

```
static void /* Print usage info, then exit */
usageError(const char *progName, const char *msg)
{
 if (msg != NULL)
 fprintf(stderr, "%s", msg);
 fprintf(stderr, "Usage: %s [-cx] {-f pathname | -k key | -p} "
 "[octal-perms]\n", progName);
 fprintf(stderr, " -c Use IPC_CREAT flag\n");
 fprintf(stderr, " -x Use IPC_EXCL flag\n");
 fprintf(stderr, " -f pathname Generate key using ftok()\n");
 fprintf(stderr, " -k key Use 'key' as key\n");
 fprintf(stderr, " -p Use IPC_PRIVATE key\n");
 exit(EXIT_FAILURE);
}
int
main(int argc, char *argv[])
{
 int numKeyFlags; /* Counts -f, -k, and -p options */
 int flags, msqid, opt;
 unsigned int perms;
 long lkey;
 key_t key;
 /* Parse command-line options and arguments */
 numKeyFlags = 0;
 flags = 0;
 while ((opt = getopt(argc, argv, "cf:k:px")) != -1) {
 switch (opt) {
 case 'c':
 flags |= IPC_CREAT;
 break;
 case 'f': /* -f pathname */
 key = ftok(optarg, 1);
 if (key == -1)
 errExit("ftok");
 numKeyFlags++;
 break;
 case 'k': /* -k key (octal, decimal or hexadecimal) */
 if (sscanf(optarg, "%li", &lkey) != 1)
 cmdLineErr("-k option requires a numeric argument\n");
 key = lkey;
 numKeyFlags++;
 break;
 case 'p':
 key = IPC_PRIVATE;
 numKeyFlags++;
 break;
```

```
 case 'x':
 flags |= IPC_EXCL;
 break;
 default:
 usageError(argv[0], "Bad option\n");
 }
 }
 if (numKeyFlags != 1)
 usageError(argv[0], "Exactly one of the options -f, -k, "
 "or -p must be supplied\n");
 perms = (optind == argc) ? (S_IRUSR | S_IWUSR) :
 getInt(argv[optind], GN_BASE_8, "octal-perms");
 msqid = msgget(key, flags | perms);
 if (msqid == -1)
 errExit("msgget");
 printf("%d\n", msqid);
 exit(EXIT_SUCCESS);
}
–––––––––––––––––––––––––––––––––––––––––––––––––––––– svmsg/svmsg_create.c
```

# **46.2 Exchanging Messages**

The msgsnd() and msgrcv() system calls perform I/O on message queues. The first argument to both system calls (msqid) is a message queue identifier. The second argument, msgp, is a pointer to a programmer-defined structure used to hold the message being sent or received. This structure has the following general form:

```
struct mymsg {
 long mtype; /* Message type */
 char mtext[]; /* Message body */
}
```

This definition is really just shorthand for saying that the first part of a message contains the message type, specified as a long integer, while the remainder of the message is a programmer-defined structure of arbitrary length and content; it need not be an array of characters. Thus, the mgsp argument is typed as void \* to allow it to be a pointer to any type of structure.

A zero-length mtext field is permitted, and is sometimes useful if the information to be conveyed can be encoded solely in the message type or if the existence of a message is in itself sufficient information for the receiving process.

## **46.2.1 Sending Messages**

The msgsnd() system call writes a message to a message queue.

```
#include <sys/types.h> /* For portability */
#include <sys/msg.h>
int msgsnd(int msqid, const void *msgp, size_t msgsz, int msgflg);
                                           Returns 0 on success, or –1 on error
```

To send a message with msgsnd(), we must set the mtype field of the message structure to a value greater than 0 (we see how this value is used when we discuss msgrcv() in the next section) and copy the desired information into the programmer-defined mtext field. The msgsz argument specifies the number of bytes contained in the mtext field.

> When sending messages with msgsnd(), there is no concept of a partial write as with write(). This is why a successful msgsnd() needs only to return 0, rather than the number of bytes sent.

The final argument, msgflg, is a bit mask of flags controlling the operation of msgsnd(). Only one such flag is defined:

#### IPC\_NOWAIT

Perform a nonblocking send. Normally, if a message queue is full, msgsnd() blocks until enough space has become available to allow the message to be placed on the queue. However, if this flag is specified, then msgsnd() returns immediately with the error EAGAIN.

A msgsnd() call that is blocked because the queue is full may be interrupted by a signal handler. In this case, msgsnd() always fails with the error EINTR. (As noted in Section 21.5, msgsnd() is among those system calls that are never automatically restarted, regardless of the setting of the SA\_RESTART flag when the signal handler is established.)

Writing a message to a message queue requires write permission on the queue.

The program in [Listing 46-2](#page-64-0) provides a command-line interface to the msgsnd() system call. The command-line format accepted by this program is shown in the usageError() function. Note that this program doesn't use the msgget() system call. (We noted that a process doesn't need to use a get call in order to access an IPC object in Section [45.1.](#page-45-0)) Instead, we specify the message queue by providing its identifier as a command-line argument. We demonstrate the use of this program in Section [46.2.2.](#page-66-0)

<span id="page-64-0"></span>**Listing 46-2:** Using msgsnd() to send a message

––––––––––––––––––––––––––––––––––––––––––––––––––––––– **svmsg/svmsg\_send.c** #include <sys/types.h> #include <sys/msg.h> #include "tlpi\_hdr.h" #define MAX\_MTEXT 1024 struct mbuf { long mtype; /\* Message type \*/ char mtext[MAX\_MTEXT]; /\* Message body \*/ };

```
static void /* Print (optional) message, then usage description */
usageError(const char *progName, const char *msg)
{
 if (msg != NULL)
 fprintf(stderr, "%s", msg);
 fprintf(stderr, "Usage: %s [-n] msqid msg-type [msg-text]\n", progName);
 fprintf(stderr, " -n Use IPC_NOWAIT flag\n");
 exit(EXIT_FAILURE);
}
int
main(int argc, char *argv[])
{
 int msqid, flags, msgLen;
 struct mbuf msg; /* Message buffer for msgsnd() */
 int opt; /* Option character from getopt() */
 /* Parse command-line options and arguments */
 flags = 0;
 while ((opt = getopt(argc, argv, "n")) != -1) {
 if (opt == 'n')
 flags |= IPC_NOWAIT;
 else
 usageError(argv[0], NULL);
 }
 if (argc < optind + 2 || argc > optind + 3)
 usageError(argv[0], "Wrong number of arguments\n");
 msqid = getInt(argv[optind], 0, "msqid");
 msg.mtype = getInt(argv[optind + 1], 0, "msg-type");
 if (argc > optind + 2) { /* 'msg-text' was supplied */
 msgLen = strlen(argv[optind + 2]) + 1;
 if (msgLen > MAX_MTEXT)
 cmdLineErr("msg-text too long (max: %d characters)\n", MAX_MTEXT);
 memcpy(msg.mtext, argv[optind + 2], msgLen);
 } else { /* No 'msg-text' ==> zero-length msg */
 msgLen = 0;
 }
 /* Send message */
 if (msgsnd(msqid, &msg, msgLen, flags) == -1)
 errExit("msgsnd");
 exit(EXIT_SUCCESS);
}
––––––––––––––––––––––––––––––––––––––––––––––––––––––– svmsg/svmsg_send.c
```

## <span id="page-66-0"></span>**46.2.2 Receiving Messages**

The msgrcv() system call reads (and removes) a message from a message queue, and copies its contents into the buffer pointed to by msgp.

```
#include <sys/types.h> /* For portability */
#include <sys/msg.h>
ssize_t msgrcv(int msqid, void *msgp, size_t maxmsgsz, long msgtyp, int msgflg);
                Returns number of bytes copied into mtext field, or –1 on error
```

The maximum space available in the mtext field of the msgp buffer is specified by the argument maxmsgsz. If the body of the message to be removed from the queue exceeds maxmsgsz bytes, then no message is removed from the queue, and msgrcv() fails with the error E2BIG. (This default behavior can be changed using the MSG\_NOERROR flag described shortly.)

Messages need not be read in the order in which they were sent. Instead, we can select messages according to the value in the mtype field. This selection is controlled by the msgtyp argument, as follows:

-  If msgtyp equals 0, the first message from the queue is removed and returned to the calling process.
-  If msgtyp is greater than 0, the first message in the queue whose mtype equals msgtyp is removed and returned to the calling process. By specifying different values for msgtyp, multiple processes can read from a message queue without racing to read the same messages. One useful technique is to have each process select messages matching its process ID.
-  If msgtyp is less than 0, treat the waiting messages as a priority queue. The first message of the lowest mtype less than or equal to the absolute value of msgtyp is removed and returned to the calling process.

An example helps clarify the behavior when msgtyp is less than 0. Suppose that we have a message queue containing the sequence of messages shown in Figure 46-1 and we performed a series of msgrcv() calls of the following form:

```
msgrcv(id, &msg, maxmsgsz, -300, 0);
```

These msgrcv() calls would retrieve messages in the order 2 (type 100), 5 (type 100), 3 (type 200), and 1 (type 300). A further call would block, since the type of the remaining message (400) exceeds 300.

The msgflg argument is a bit mask formed by ORing together zero or more of the following flags:

#### IPC\_NOWAIT

Perform a nonblocking receive. Normally, if no message matching msgtyp is in the queue, msgrcv() blocks until such a message becomes available. Specifying the IPC\_NOWAIT flag causes msgrcv() to instead return immediately with the error ENOMSG. (The error EAGAIN would be more consistent, as occurs on a nonblocking msgsnd() or a nonblocking read from a FIFO. However, failing with ENOMSG is historical behavior, and required by SUSv3.)

#### MSG\_EXCEPT

This flag has an effect only if msgtyp is greater than 0, in which case it forces the complement of the usual operation; that is, the first message from the queue whose mtype is not equal to msgtyp is removed from the queue and returned to the caller. This flag is Linux-specific, and is made available from <sys/msg.h> only if \_GNU\_SOURCE is defined. Performing a series of calls of the form msgrcv(id, &msg, maxmsgsz, 100, MSG\_EXCEPT) on the message queue shown in Figure 46-1 would retrieve messages in the order 1, 3, 4, and then block.

#### MSG\_NOERROR

By default, if the size of the mtext field of the message exceeds the space available (as defined by the maxmsgsz argument), msgrcv() fails. If the MSG\_NOERROR flag is specified, then msgrcv() instead removes the message from the queue, truncates its mtext field to maxmsgsz bytes, and returns it to the caller. The truncated data is lost.

Upon successful completion, msgrcv() returns the size of the mtext field of the received message; on error, –1 is returned.

| queue<br>position | Message type<br>(mtype) | Message body<br>(mtext) |
|-------------------|-------------------------|-------------------------|
| 1                 | 300                     |                         |
| 2                 | 100                     |                         |
| 3                 | 200                     |                         |
| 4                 | 400                     |                         |
| 5                 | 100                     |                         |

**Figure 46-1:** Example of a message queue containing messages of different types

As with msgsnd(), if a blocked msgrcv() call is interrupted by a signal handler, then the call fails with the error EINTR, regardless of the setting of the SA\_RESTART flag when the signal handler was established.

Reading a message from a message queue requires read permission on the queue.

### **Example program**

The program in [Listing 46-3](#page-68-0) provides a command-line interface to the msgrcv() system call. The command-line format accepted by this program is shown in the usageError() function. Like the program in [Listing 46-2,](#page-64-0) which demonstrated the use of msgsnd(), this program doesn't use the msgget() system call, but instead expects a message queue identifier as its command-line argument.

The following shell session demonstrates the use of the programs in [Listing 46-1](#page-86-0), [Listing 46-2](#page-64-0), and [Listing 46-3.](#page-68-0) We begin by creating a message queue using the IPC\_PRIVATE key, and then write three messages with different types to the queue:

```
$ ./svmsg_create -p
32769 ID of message queue
$ ./svmsg_send 32769 20 "I hear and I forget."
$ ./svmsg_send 32769 10 "I see and I remember."
$ ./svmsg_send 32769 30 "I do and I understand."
```

We then use the program in [Listing 46-3](#page-68-0) to read messages with a type less than or equal to 20 from the queue:

```
$ ./svmsg_receive -t -20 32769
Received: type=10; length=22; body=I see and I remember.
$ ./svmsg_receive -t -20 32769
Received: type=20; length=21; body=I hear and I forget.
$ ./svmsg_receive -t -20 32769
```

The last of the above commands blocked, because there was no message in the queue whose type was less than or equal to 20. So, we continue by typing Control-C to terminate the command, and then execute a command that reads a message of any type from the queue:

```
Type Control-C to terminate program
$ ./svmsg_receive 32769
Received: type=30; length=23; body=I do and I understand.
```

<span id="page-68-0"></span>**Listing 46-3:** Using msgrcv() to read a message

```
––––––––––––––––––––––––––––––––––––––––––––––––––––– svmsg/svmsg_receive.c
#define _GNU_SOURCE /* Get definition of MSG_EXCEPT */
#include <sys/types.h>
#include <sys/msg.h>
#include "tlpi_hdr.h"
#define MAX_MTEXT 1024
struct mbuf {
 long mtype; /* Message type */
 char mtext[MAX_MTEXT]; /* Message body */
};
static void
usageError(const char *progName, const char *msg)
{
 if (msg != NULL)
 fprintf(stderr, "%s", msg);
 fprintf(stderr, "Usage: %s [options] msqid [max-bytes]\n", progName);
 fprintf(stderr, "Permitted options are:\n");
 fprintf(stderr, " -e Use MSG_NOERROR flag\n");
 fprintf(stderr, " -t type Select message of given type\n");
 fprintf(stderr, " -n Use IPC_NOWAIT flag\n");
```

```
#ifdef MSG_EXCEPT
 fprintf(stderr, " -x Use MSG_EXCEPT flag\n");
#endif
 exit(EXIT_FAILURE);
}
int
main(int argc, char *argv[])
{
 int msqid, flags, type;
 ssize_t msgLen;
 size_t maxBytes;
 struct mbuf msg; /* Message buffer for msgrcv() */
 int opt; /* Option character from getopt() */
 /* Parse command-line options and arguments */
 flags = 0;
 type = 0;
 while ((opt = getopt(argc, argv, "ent:x")) != -1) {
 switch (opt) {
 case 'e': flags |= MSG_NOERROR; break;
 case 'n': flags |= IPC_NOWAIT; break;
 case 't': type = atoi(optarg); break;
#ifdef MSG_EXCEPT
 case 'x': flags |= MSG_EXCEPT; break;
#endif
 default: usageError(argv[0], NULL);
 }
 }
 if (argc < optind + 1 || argc > optind + 2)
 usageError(argv[0], "Wrong number of arguments\n");
 msqid = getInt(argv[optind], 0, "msqid");
 maxBytes = (argc > optind + 1) ?
 getInt(argv[optind + 1], 0, "max-bytes") : MAX_MTEXT;
 /* Get message and display on stdout */
 msgLen = msgrcv(msqid, &msg, maxBytes, type, flags);
 if (msgLen == -1)
 errExit("msgrcv");
 printf("Received: type=%ld; length=%ld", msg.mtype, (long) msgLen);
 if (msgLen > 0)
 printf("; body=%s", msg.mtext);
 printf("\n");
 exit(EXIT_SUCCESS);
}
––––––––––––––––––––––––––––––––––––––––––––––––––––– svmsg/svmsg_receive.c
```

# **46.3 Message Queue Control Operations**

The msgctl() system call performs control operations on the message queue identified by msqid.

```
#include <sys/types.h> /* For portability */
#include <sys/msg.h>
int msgctl(int msqid, int cmd, struct msqid_ds *buf);
                                           Returns 0 on success, or –1 on error
```

The cmd argument specifies the operation to be performed on the queue. It can be one of the following:

#### IPC\_RMID

Immediately remove the message queue object and its associated msqid\_ds data structure. All messages remaining in the queue are lost, and any blocked reader or writer processes are immediately awakened, with msgsnd() or msgrcv() failing with the error EIDRM. The third argument to msgctl() is ignored for this operation.

#### IPC\_STAT

Place a copy of the msqid\_ds data structure associated with this message queue in the buffer pointed to by buf. We describe the msqid\_ds structure in Section [46.4.](#page-71-0)

#### IPC\_SET

Update selected fields of the msqid\_ds data structure associated with this message queue using values provided in the buffer pointed to by buf.

Further details about these operations, including the privileges and permissions required by the calling process, are described in Section [45.3](#page-50-0). We describe some other values for cmd in Section [46.6](#page-74-1).

The program in [Listing 46-4](#page-70-0) demonstrates the use of msgctl() to delete a message queue.

<span id="page-70-0"></span>**Listing 46-4:** Deleting System V message queues

```
––––––––––––––––––––––––––––––––––––––––––––––––––––––––– svmsg/svmsg_rm.c
#include <sys/types.h>
#include <sys/msg.h>
#include "tlpi_hdr.h"
int
main(int argc, char *argv[])
{
 int j;
```

```
 if (argc > 1 && strcmp(argv[1], "--help") == 0)
 usageErr("%s [msqid...]\n", argv[0]);
 for (j = 1; j < argc; j++)
 if (msgctl(getInt(argv[j], 0, "msqid"), IPC_RMID, NULL) == -1)
 errExit("msgctl %s", argv[j]);
 exit(EXIT_SUCCESS);
}
––––––––––––––––––––––––––––––––––––––––––––––––––––––––– svmsg/svmsg_rm.c
```

# <span id="page-71-0"></span>**46.4 Message Queue Associated Data Structure**

Each message queue has an associated msqid\_ds data structure of the following form:

```
struct msqid_ds {
 struct ipc_perm msg_perm; /* Ownership and permissions */
 time_t msg_stime; /* Time of last msgsnd() */
 time_t msg_rtime; /* Time of last msgrcv() */
 time_t msg_ctime; /* Time of last change */
 unsigned long __msg_cbytes; /* Number of bytes in queue */
 msgqnum_t msg_qnum; /* Number of messages in queue */
 msglen_t msg_qbytes; /* Maximum bytes in queue */
 pid_t msg_lspid; /* PID of last msgsnd() */
 pid_t msg_lrpid; /* PID of last msgrcv() */
};
```

The purpose of the abbreviated spelling msq in the name msqid\_ds is to confuse the programmer. This is the only message queue interface employing this spelling.

The msgqnum\_t and msglen\_t data types—used to type the msg\_qnum and msg\_qbytes fields—are unsigned integer types specified in SUSv3.

The fields of the msqid\_ds structure are implicitly updated by the various message queue system calls, and certain fields can be explicitly updated using the msgctl() IPC\_SET operation. The details are as follows:

```
msg_perm
```

When the message queue is created, the fields of this substructure are initialized as described in Section [45.3.](#page-50-0) The uid, gid, and mode subfields can be updated via IPC\_SET.

msg\_stime

When the queue is created, this field is set to 0; each later successful msgsnd() sets this field to the current time. This field and the other timestamp fields in the msqid\_ds structure are typed as time\_t; they store time in seconds since the Epoch.

msg\_rtime

This field is set to 0 when the message queue is created, and then set to the current time on each successful msgrcv().

#### msg\_ctime

This field is set to the current time when the message queue is created and whenever an IPC\_SET operation is successfully performed.

#### \_\_msg\_cbytes

This field is set to 0 when the message queue is created, and then adjusted during each successful msgsnd() and msgrcv() to reflect the total number of bytes contained in the mtext fields of all messages in the queue.

#### msg\_qnum

When the message queue is created, this field is set to 0. It is then incremented by each successful msgsnd() and decremented by each successful msgrcv() to reflect the total number of messages in the queue.

#### msg\_qbytes

The value in this field defines an upper limit on the number of bytes in the mtext fields of all messages in the message queue. This field is initialized to the value of the MSGMNB limit when the queue is created. A privileged (CAP\_SYS\_RESOURCE) process can use the IPC\_SET operation to adjust msg\_qbytes to any value in the range 0 to INT\_MAX (2,147,483,647 on 32-bit platforms) bytes. An unprivileged process can adjust msg\_qbytes to any value in the range 0 to MSGMNB. A privileged user can modify the value contained in the Linux-specific /proc/sys/kernel/msgmnb file in order to change the initial msg\_qbytes setting for all subsequently created message queues, as well as the upper limit for subsequent changes to msg\_qbytes by unprivileged processes. We say more about message queue limits in Section [46.5](#page-73-0).

#### msg\_lspid

This field is set to 0 when the queue is created, and then set to the process ID of the calling process on each successful msgsnd().

#### msg\_lrpid

This field is set to 0 when the message queue is created, and then set to the process ID of the calling process on each successful msgrcv().

All of the above fields are specified by SUSv3, with the exception of \_\_msg\_cbytes. Nevertheless, most UNIX implementations provide an equivalent of the \_\_msg\_cbytes field.

The program in [Listing 46-5](#page-72-0) demonstrates the use of the IPC\_STAT and IPC\_SET operations to modify the msg\_qbytes setting of a message queue.

<span id="page-72-0"></span>**Listing 46-5:** Changing the msg\_qbytes setting of a System V message queue

–––––––––––––––––––––––––––––––––––––––––––––––––––– **svmsg/svmsg\_chqbytes.c** #include <sys/types.h> #include <sys/msg.h> #include "tlpi\_hdr.h" int main(int argc, char \*argv[]) { struct msqid\_ds ds; int msqid;

```
 if (argc != 3 || strcmp(argv[1], "--help") == 0)
 usageErr("%s msqid max-bytes\n", argv[0]);
 /* Retrieve copy of associated data structure from kernel */
 msqid = getInt(argv[1], 0, "msqid");
 if (msgctl(msqid, IPC_STAT, &ds) == -1)
 errExit("msgctl");
 ds.msg_qbytes = getInt(argv[2], 0, "max-bytes");
 /* Update associated data structure in kernel */
 if (msgctl(msqid, IPC_SET, &ds) == -1)
 errExit("msgctl");
 exit(EXIT_SUCCESS);
}
–––––––––––––––––––––––––––––––––––––––––––––––––––– svmsg/svmsg_chqbytes.c
```

# <span id="page-73-0"></span>**46.5 Message Queue Limits**

Most UNIX implementations impose various limits on the operation of System V message queues. Here, we describe the limits under Linux and note a few differences from other UNIX implementations.

The following limits are enforced on Linux. The system call affected by the limit and the error that results if the limit is reached are noted in parentheses.

MSGMNI

This is a system-wide limit on the number of message queue identifiers (in other words, message queues) that can be created. (msgget(), ENOSPC)

MSGMAX

This is a system-wide limit specifying the maximum number of (mtext) bytes that can be written in a single message. (msgsnd(), EINVAL)

MSGMNB

This is the maximum number of (mtext) bytes that can be held in a message queue at one time. This limit is a system-wide parameter that is used to initialize the msg\_qbytes field of the msqid\_ds data structure associated with this message queue. Subsequently, the msg\_qbytes value can be modified on a per-queue basis, as described in Section [46.4.](#page-71-0) If a queue's msg\_qbytes limit is reached, then msgsnd() blocks, or fails with the error EAGAIN if IPC\_NOWAIT was set.

Some UNIX implementations also define the following further limits:

MSGTQL

This is a system-wide limit on the number of messages that can be placed on all message queues on the system.

MSGPOOL

This is a system-wide limit on the size of the buffer pool that is used to hold data in all message queues on the system.

Although Linux doesn't impose either of the above limits, it does limit the number of messages on an individual queue to the value specified by the queue's msg\_qbytes setting. This limitation is relevant only if we are writing zero-length messages to a queue. It has the effect that the limit on the number of zero-length messages is the same as the limit on the number of 1-byte messages that can be written to the queue. This is necessary to prevent an infinite number of zero-length messages being written to the queue. Although they contain no data, each zero-length message consumes a small amount of memory for system bookkeeping overhead.

At system startup, the message queue limits are set to default values. These defaults have varied somewhat across kernel versions. (Some distributors' kernels set different defaults from those provided by vanilla kernels.) On Linux, the limits can be viewed or changed via files in the /proc file system. [Table 46-1](#page-74-2) shows the /proc file corresponding to each limit. As an example, here are the default limits that we see for Linux 2.6.31 on one x86-32 system:

```
$ cd /proc/sys/kernel
$ cat msgmni
748
$ cat msgmax
8192
$ cat msgmnb
16384
```

<span id="page-74-2"></span>**Table 46-1:** System V message queue limits

| Limit  | Ceiling value (x86-32)      | Corresponding file<br>in /proc/sys/kernel |
|--------|-----------------------------|-------------------------------------------|
| MSGMNI | 32768 (IPCMNI)              | msgmni                                    |
| MSGMAX | Depends on available memory | msgmax                                    |
| MSGMNB | 2147483647 (INT_MAX)        | msgmnb                                    |

The ceiling value column of [Table 46-1](#page-74-2) shows the maximum value to which each limit can be raised on the x86-32 architecture. Note that although the MSGMNB limit can be raised to the value INT\_MAX, some other limit (e.g., lack of memory) will be reached before a message queue can be loaded with so much data.

The Linux-specific msgctl() IPC\_INFO operation retrieves a structure of type msginfo, which contains the values of the various message queue limits:

```
struct msginfo buf;
msgctl(0, IPC_INFO, (struct msqid_ds *) &buf);
```

<span id="page-74-0"></span>Details about IPC\_INFO and the msginfo structure can be found in the msgctl(2) manual page.

# <span id="page-74-1"></span>**46.6 Displaying All Message Queues on the System**

In Section [45.7](#page-58-0), we looked at one way to obtain a list of all of the IPC objects on the system: via a set of files in the /proc file system. We now look at a second method of obtaining the same information: via a set of Linux-specific IPC ctl (msgctl(), semctl(), and shmctl()) operations. (The ipcs program employs these operations.) These operations are as follows:

 MSG\_INFO, SEM\_INFO, and SHM\_INFO: The MSG\_INFO operation serves two purposes. First, it returns a structure detailing resources consumed by all message queues on the system. Second, as the function result of the ctl call, it returns the index of the maximum item in the entries array pointing to data structures for the message queue objects (see [Figure 45-1,](#page-55-1) on page [932\)](#page-55-1). The SEM\_INFO and SHM\_INFO operations perform an analogous task for semaphore sets and shared memory segments, respectively. We must define the \_GNU\_SOURCE feature test macro to obtain the definitions of these three constants from the corresponding System V IPC header files.

> An example showing the use of MSG\_INFO to retrieve a msginfo structure containing information about resources used by all message queue objects is provided in the file svmsg/svmsg\_info.c in the source code distribution for this book.

 MSG\_STAT, SEM\_STAT, and SHM\_STAT: Like the IPC\_STAT operation, these operations retrieve the associated data structure for an IPC object. However, they differ in two respects. First, instead of expecting an IPC identifier as the first argument of the ctl call, these operations expect an index into the entries array. Second, if the operation is successful, then, as its function result, the ctl call returns the identifier of the IPC object corresponding to that index. We must define the \_GNU\_SOURCE feature test macro to obtain the definitions of these three constants from the corresponding System V IPC header files.

To list all message queues on the system, we can do the following:

- 1. Use a MSG\_INFO operation to find out the maximum index (maxind) of the entries array for message queues.
- 2. Perform a loop for all values from 0 up to and including maxind, employing a MSG\_STAT operation for each value. During this loop, we ignore the errors that may occur if an item of the entries array is empty (EINVAL) or if we don't have permissions on the object to which it refers (EACCES).

[Listing 46-6](#page-76-0) provides an implementation of the above steps for message queues. The following shell session log demonstrates the use of this program:

## \$ **./svmsg\_ls** maxind: 4 index ID key messages 2 98306 0x00000000 0 4 163844 0x000004d2 2 \$ **ipcs -q** Check above against output of ipcs ------ Message Queues ------- key msqid owner perms used-bytes messages 0x00000000 98306 mtk 600 0 0 0x000004d2 163844 mtk 600 12 2

```
––––––––––––––––––––––––––––––––––––––––––––––––––––––––– svmsg/svmsg_ls.c
#define _GNU_SOURCE
#include <sys/types.h>
#include <sys/msg.h>
#include "tlpi_hdr.h"
int
main(int argc, char *argv[])
{
 int maxind, ind, msqid;
 struct msqid_ds ds;
 struct msginfo msginfo;
 /* Obtain size of kernel 'entries' array */
 maxind = msgctl(0, MSG_INFO, (struct msqid_ds *) &msginfo);
 if (maxind == -1)
 errExit("msgctl-MSG_INFO");
 printf("maxind: %d\n\n", maxind);
 printf("index id key messages\n");
 /* Retrieve and display information from each element of 'entries' array */
 for (ind = 0; ind <= maxind; ind++) {
 msqid = msgctl(ind, MSG_STAT, &ds);
 if (msqid == -1) {
 if (errno != EINVAL && errno != EACCES)
 errMsg("msgctl-MSG_STAT"); /* Unexpected error */
 continue; /* Ignore this item */
 }
 printf("%4d %8d 0x%08lx %7ld\n", ind, msqid,
 (unsigned long) ds.msg_perm.__key, (long) ds.msg_qnum);
 }
 exit(EXIT_SUCCESS);
}
––––––––––––––––––––––––––––––––––––––––––––––––––––––––– svmsg/svmsg_ls.c
```

## **46.7 Client-Server Programming with Message Queues**

In this section, we consider two of various possible designs for client-server applications using System V message queues:

-  The use of a single message queue for exchanging messages in both directions between server and client.
-  The use of separate message queues for the server and for each client. The server's queue is used to receive incoming client requests, and responses are sent to clients via the individual client queues.

Which approach we choose depends on the requirements of our application. We next consider some of the factors that may influence our choice.

## **Using a single message queue for server and clients**

Using a single message queue may be suitable when the messages exchanged between servers and clients are small. However, note the following points:

-  Since multiple processes may attempt to read messages at the same time, we must use the message type (mtype) field to allow each process to select only those messages intended for it. One way to accomplish this is to use the client's process ID as the message type for messages sent from the server to the client. The client can send its process ID as part of its message(s) to the server. Furthermore, messages to the server must also be distinguished by a unique message type. For this purpose, we can use the number 1, which, being the process ID of the permanently running init process, can never be the process ID of a client process. (An alternative would be to use the server's process ID as the message type; however, it is difficult for the clients to obtain this information.) This numbering scheme is shown in Figure 46-2.
-  Message queues have a limited capacity. This has the potential to cause a couple of problems. One of these is that multiple simultaneous clients could fill the message queue, resulting in a deadlock situation, where no new client requests can be submitted and the server is blocked from writing any responses. The other problem is that a poorly behaved or intentionally malicious client may fail to read responses from the server. This can lead to the queue becoming clogged with unread messages, preventing any communication between clients and server. (Using two queues—one for messages from clients to the server, and the other for messages from the server to the clients—would solve the first of these problems, but not the second.)

```
                                            +---------+
                                    |-------| Server  |<--------|
          Server sends response     |       +----+----+         |     Server reads request
          mtype = PID of client (3) |                           | (2) select msgtyp = 1
                                    |    +-----------------+    |
                                    |--->|  message queue  |----|
                                    |--->|                 |----|
        Client sends request        |    +-----------------+    |      Client reads response
        mtype = 1,              (1) |                           | (4)  select msgtyp = own PID
        mtext includes client PID   |       +---------+         |
                                    |-------| Client  |<--------|
                                            +----+----+

```

**Figure 46-2:** Using a single message queue for client-server IPC

### **Using one message queue per client**

Using one message queue per client (as well as one for the server) is preferable where large messages need to be exchanged, or where there is potential for the problems listed above when using a single message queue. Note the following points regarding this approach:

- Each client must create its own message queue (typically using the IPC\_PRIVATE key) and inform the server of the queue's identifier, usually by transmitting the identifier as part of the client's message(s) to the server.
- There is a system-wide limit (MSGMNI) on the number of message queues, and the default value for this limit is quite low on some systems. If we expect to have a large number of simultaneous clients, we may need to raise this limit.
- The server should allow for the possibility that the client's message queue no longer exists (perhaps because the client prematurely deleted it).

We say more about using one message queue per client in the next section.

## <span id="page-78-1"></span>46.8 A File-Server Application Using Message Queues

In this section, we describe a client-server application that uses one message queue per client. The application is a simple file server. The client sends a request message to the server's message queue asking for the contents of a named file. The server responds by returning the file contents as a series of messages to the client's private message queue. Figure 46-3 provides an overview of the application.

Because the server performs no authentication of the client, any user that can run the client can obtain any of the files accessible to the server. A more sophisticated server would require some type of authentication from the client before serving the requested file.

```
                                           (4) Server creates child to handle request (fork)
                                             +-------+     fork()     +------------+
                                             |Server |--------------->|Server child|
                                             +-------+                +------------+
                                                  ^                     |
                               (3) read request   |                     | (5) Server child sends response(s) to Client MQ
                                                  |                     |
                                  +-----------+   |                     |   +-----------+            
                             |--->| Server MQ |---|                     |-->| Client MQ |----|
                             |    +-----------+                             +-----------+    |
                             |                   (msgget(IPC_PRIVATE,...))      ^            |
                             |                            ______________________|            |
                             |                            |(1) Client creates private queue  |
                             |                        +---------+                            |
                             |------------------------| Client  |<---------------------------|
              (2) Client sends request to Server MQ   +---------+   (6) Client reads response(s) from Client MQ
                  (mtext includes ID of client queue)                
                                  
```

<span id="page-78-0"></span>Figure 46-3: Client-server IPC using one message queue per client

#### Common header file

Listing 46-7 is the header file included by both the server and the client. This header defines the well-known key to be used for the server's message queue

(SERVER\_KEY), and defines the formats of the messages to be passed between the client and the server.

The requestMsg structure defines the format of the request sent from the client to the server. In this structure, the mtext component consists of two fields: the identifier of the client's message queue and the pathname of the file requested by the client. The constant REQ\_MSG\_SIZE equates to the combined size of these two fields and is used as the msgsz argument in calls to msgsnd() using this structure.

The responseMsg structure defines the format of the response messages sent from the server back to the client. The mtype field is used in response messages to supply information about the message content, as defined by the RESP\_MT\_\* constants.

<span id="page-79-0"></span>**Listing 46-7:** Header file for svmsg\_file\_server.c and svmsg\_file\_client.c

```
––––––––––––––––––––––––––––––––––––––––––––––––––––––– svmsg/svmsg_file.h
#include <sys/types.h>
#include <sys/msg.h>
#include <sys/stat.h>
#include <stddef.h> /* For definition of offsetof() */
#include <limits.h>
#include <fcntl.h>
#include <signal.h>
#include <sys/wait.h>
#include "tlpi_hdr.h"
#define SERVER_KEY 0x1aaaaaa1 /* Key for server's message queue */
struct requestMsg { /* Requests (client to server) */
 long mtype; /* Unused */
 int clientId; /* ID of client's message queue */
 char pathname[PATH_MAX]; /* File to be returned */
};
/* REQ_MSG_SIZE computes size of 'mtext' part of 'requestMsg' structure.
 We use offsetof() to handle the possibility that there are padding
 bytes between the 'clientId' and 'pathname' fields. */
#define REQ_MSG_SIZE (offsetof(struct requestMsg, pathname) - \
 offsetof(struct requestMsg, clientId) + PATH_MAX)
#define RESP_MSG_SIZE 8192
struct responseMsg { /* Responses (server to client) */
 long mtype; /* One of RESP_MT_* values below */
 char data[RESP_MSG_SIZE]; /* File content / response message */
};
/* Types for response messages sent from server to client */
#define RESP_MT_FAILURE 1 /* File couldn't be opened */
#define RESP_MT_DATA 2 /* Message contains file data */
#define RESP_MT_END 3 /* File data complete */
––––––––––––––––––––––––––––––––––––––––––––––––––––––– svmsg/svmsg_file.h
```

### **Server program**

[Listing 46-8](#page-80-0) is the server program for the application. Note the following points about the server:

-  The server is designed to handle requests concurrently. A concurrent server design is preferable to the iterative design employed in [Listing 44-7](#page-35-0) (page [912](#page-35-0)), since we want to avoid the possibility that a client request for a large file would cause all other client requests to wait.
-  Each client request is handled by creating a child process that serves the requested file i. In the meantime, the main server process waits upon further client requests. Note the following points about the server child:
  - Since the child produced via fork() inherits a copy of the parent's stack, it thus obtains a copy of the request message read by the main server process.
  - The server child terminates after handling its associated client request o.
-  In order to avoid the creation of zombie processes (Section 26.2), the server establishes a handler for SIGCHLD y and calls waitpid() within this handler q.
-  The msgrcv() call in the parent server process may block, and consequently be interrupted by the SIGCHLD handler. To handle this possibility, a loop is used to restart the call if it fails with the EINTR error u.
-  The server child executes the serveRequest() function w, which sends three message types back to the client. A request with an mtype of RESP\_MT\_FAILURE indicates that the server could not open the requested file e; RESP\_MT\_DATA is used for a series of messages containing file data r; and RESP\_MT\_END (with a zero-length data field) is used to indicate that transmission of file data is complete t.

We consider a number of ways to improve and extend the server program in [Exercise 46-4](#page-86-1).

<span id="page-80-0"></span>**Listing 46-8:** A file server using System V message queues

```
––––––––––––––––––––––––––––––––––––––––––––––––– svmsg/svmsg_file_server.c
  #include "svmsg_file.h"
  static void /* SIGCHLD handler */
  grimReaper(int sig)
  {
   int savedErrno;
   savedErrno = errno; /* waitpid() might change 'errno' */
q while (waitpid(-1, NULL, WNOHANG) > 0)
   continue;
   errno = savedErrno;
  }
```

```
static void /* Executed in child process: serve a single client */
w serveRequest(const struct requestMsg *req)
  {
   int fd;
   ssize_t numRead;
   struct responseMsg resp;
   fd = open(req->pathname, O_RDONLY);
   if (fd == -1) { /* Open failed: send error text */
e resp.mtype = RESP_MT_FAILURE;
   snprintf(resp.data, sizeof(resp.data), "%s", "Couldn't open");
   msgsnd(req->clientId, &resp, strlen(resp.data) + 1, 0);
   exit(EXIT_FAILURE); /* and terminate */
   }
   /* Transmit file contents in messages with type RESP_MT_DATA. We don't
   diagnose read() and msgsnd() errors since we can't notify client. */
r resp.mtype = RESP_MT_DATA;
   while ((numRead = read(fd, resp.data, RESP_MSG_SIZE)) > 0)
   if (msgsnd(req->clientId, &resp, numRead, 0) == -1)
   break;
   /* Send a message of type RESP_MT_END to signify end-of-file */
t resp.mtype = RESP_MT_END;
   msgsnd(req->clientId, &resp, 0, 0); /* Zero-length mtext */
  }
  int
  main(int argc, char *argv[])
  {
   struct requestMsg req;
   pid_t pid;
   ssize_t msgLen;
   int serverId;
   struct sigaction sa;
   /* Create server message queue */
   serverId = msgget(SERVER_KEY, IPC_CREAT | IPC_EXCL |
   S_IRUSR | S_IWUSR | S_IWGRP);
   if (serverId == -1)
   errExit("msgget");
   /* Establish SIGCHLD handler to reap terminated children */
   sigemptyset(&sa.sa_mask);
   sa.sa_flags = SA_RESTART;
   sa.sa_handler = grimReaper;
y if (sigaction(SIGCHLD, &sa, NULL) == -1)
   errExit("sigaction");
```

```
 /* Read requests, handle each in a separate child process */
   for (;;) {
   msgLen = msgrcv(serverId, &req, REQ_MSG_SIZE, 0, 0);
   if (msgLen == -1) {
u if (errno == EINTR) /* Interrupted by SIGCHLD handler? */
   continue; /* ... then restart msgrcv() */
   errMsg("msgrcv"); /* Some other error */
   break; /* ... so terminate loop */
   }
i pid = fork(); /* Create child process */
   if (pid == -1) {
   errMsg("fork");
   break;
   }
   if (pid == 0) { /* Child handles request */
   serveRequest(&req);
o _exit(EXIT_SUCCESS);
   }
   /* Parent loops to receive next client request */
   }
   /* If msgrcv() or fork() fails, remove server MQ and exit */
   if (msgctl(serverId, IPC_RMID, NULL) == -1)
   errExit("msgctl");
   exit(EXIT_SUCCESS);
  }
  ––––––––––––––––––––––––––––––––––––––––––––––––– svmsg/svmsg_file_server.c
```

## **Client program**

[Listing 46-9](#page-83-0) is the client program for the application. Note the following:

-  The client creates a message queue with the IPC\_PRIVATE key w and uses atexit() e to establish an exit handler q to ensure that the queue is deleted when the client exits.
-  The client passes the identifier for its queue, as well as the pathname of the file to be served, in a request to the server r.
-  The client handles the possibility that the first response message sent by the server may be a failure notification (mtype equals RESP\_MT\_FAILURE) by printing the text of the error message returned by the server and exiting t.
-  If the file is successfully opened, then the client loops y, receiving a series of messages containing the file contents (mtype equals RESP\_MT\_DATA). The loop is terminated by receipt of an end-of-file message (mtype equals RESP\_MT\_END).

This simple client doesn't handle various possibilities resulting from failures in the server. We consider some improvements in Exercise [46-5.](#page-87-0)

```
––––––––––––––––––––––––––––––––––––––––––––––––– svmsg/svmsg_file_client.c
  #include "svmsg_file.h"
  static int clientId;
  static void
  removeQueue(void)
  {
   if (msgctl(clientId, IPC_RMID, NULL) == -1)
q errExit("msgctl");
  }
  int
  main(int argc, char *argv[])
  {
   struct requestMsg req;
   struct responseMsg resp;
   int serverId, numMsgs;
   ssize_t msgLen, totBytes;
   if (argc != 2 || strcmp(argv[1], "--help") == 0)
   usageErr("%s pathname\n", argv[0]);
   if (strlen(argv[1]) > sizeof(req.pathname) - 1)
   cmdLineErr("pathname too long (max: %ld bytes)\n",
   (long) sizeof(req.pathname) - 1);
   /* Get server's queue identifier; create queue for response */
   serverId = msgget(SERVER_KEY, S_IWUSR);
   if (serverId == -1)
   errExit("msgget - server message queue");
w clientId = msgget(IPC_PRIVATE, S_IRUSR | S_IWUSR | S_IWGRP);
   if (clientId == -1)
   errExit("msgget - client message queue");
e if (atexit(removeQueue) != 0)
   errExit("atexit");
   /* Send message asking for file named in argv[1] */
   req.mtype = 1; /* Any type will do */
   req.clientId = clientId;
   strncpy(req.pathname, argv[1], sizeof(req.pathname) - 1);
   req.pathname[sizeof(req.pathname) - 1] = '\0';
   /* Ensure string is terminated */
r if (msgsnd(serverId, &req, REQ_MSG_SIZE, 0) == -1)
   errExit("msgsnd");
```

```
 /* Get first response, which may be failure notification */
   msgLen = msgrcv(clientId, &resp, RESP_MSG_SIZE, 0, 0);
   if (msgLen == -1)
   errExit("msgrcv");
t if (resp.mtype == RESP_MT_FAILURE) {
   printf("%s\n", resp.data); /* Display msg from server */
   if (msgctl(clientId, IPC_RMID, NULL) == -1)
   errExit("msgctl");
   exit(EXIT_FAILURE);
   }
   /* File was opened successfully by server; process messages
   (including the one already received) containing file data */
   totBytes = msgLen; /* Count first message */
y for (numMsgs = 1; resp.mtype == RESP_MT_DATA; numMsgs++) {
   msgLen = msgrcv(clientId, &resp, RESP_MSG_SIZE, 0, 0);
   if (msgLen == -1)
   errExit("msgrcv");
   totBytes += msgLen;
   }
   printf("Received %ld bytes (%d messages)\n", (long) totBytes, numMsgs);
   exit(EXIT_SUCCESS);
  }
  ––––––––––––––––––––––––––––––––––––––––––––––––– svmsg/svmsg_file_client.c
```

The following shell session demonstrates the use of the programs in [Listing 46-8](#page-80-0) and [Listing 46-9:](#page-83-0)

```
$ ./svmsg_file_server & Run server in background
[1] 9149
$ wc -c /etc/services Show size of file that client will request
764360 /etc/services
$ ./svmsg_file_client /etc/services 
Received 764360 bytes (95 messages) Bytes received matches size above
$ kill %1 Terminate server
[1]+ Terminated ./svmsg_file_server
```

# <span id="page-84-0"></span>**46.9 Disadvantages of System V Message Queues**

<span id="page-84-1"></span>UNIX systems provide a number of mechanisms for transmitting data from one process to another on the same system, either in the form of an undelimited byte stream (pipes, FIFOs, and UNIX domain stream sockets) or as delimited messages (System V message queues, POSIX message queues, and UNIX domain datagram sockets).

A distinctive feature of System V message queues is the ability to attach a numeric type to each message. This provides for two possibilities that may be useful to applications: reading processes may select messages by type, or they may employ a priority-queue strategy so that higher-priority messages (i.e., those with lower message type values) are read first.

However, System V message queues have a number of disadvantages:

-  Message queues are referred to by identifiers, rather than the file descriptors used by most other UNIX I/O mechanisms. This means that a variety of file descriptor–based I/O techniques described in Chapter 63 (e.g., select(), poll(), and epoll) can't be applied to message queues. Furthermore, writing programs that simultaneously handle inputs from both message queues and file descriptor– based I/O mechanisms requires code that is more complex than code that deals with file descriptors alone. (We look at one way of combining the two I/O models in Exercise 63-3.)
-  The use of keys, rather than filenames, to identify message queues results in additional programming complexity and also requires the use of ipcs and ipcrm instead of ls and rm. The ftok() function usually generates a unique key, but it is not guaranteed to do so. Employing the IPC\_PRIVATE key guarantees a unique queue identifier, but leaves us with the task of making that identifier visible to other processes that require it.
-  Message queues are connectionless, and the kernel doesn't maintain a count of the number of processes referring to the queue as is done with pipes, FIFOs, and sockets. Consequently, it can be difficult to answer the following questions:
  - When is it safe for an application to delete a message queue? (Premature deletion of the queue results in immediate loss of data, regardless of whether any process might later be interested in reading from the queue.)
  - How can an application ensure that an unused queue is deleted?
-  There are limits on the total number of message queues, the size of messages, and the capacity of individual queues. These limits are configurable, but if an application operates outside the range of the default limits, this requires extra work when installing the application.

In summary, System V message queues are often best avoided. In situations where we require the facility to select messages by type, we should consider alternatives. POSIX message queues (Chapter 52) are one such alternative. As a further alternative, solutions involving multiple file descriptor–based communication channels may provide functionality similar to selecting messages by type, while at the same time allowing the use of the alternative I/O models described in Chapter 63. For example, if we need to transmit "normal" and "priority" messages, we could use a pair of FIFOs or UNIX domain sockets for the two message types, and then employ select() or poll() to monitor file descriptors for both channels.

# **46.10 Summary**

System V message queues allow processes to communicate by exchanging messages consisting of a numeric type plus a body containing arbitrary data. The distinguishing features of message queues are that message boundaries are preserved and that the receiver(s) can select messages by type, rather than reading messages in first-in, first-out order.

Various factors led us to conclude that other IPC mechanisms are usually preferable to System V message queues. One major difficulty is that message queues are not referred to using file descriptors. This means that we can't employ various alternative I/O models with message queues; in particular, it is complex to simultaneously monitor both message queues and file descriptors to see if I/O is possible. Furthermore, the fact that message queues are connectionless (i.e., not reference counted) makes it difficult for an application to know when a queue may be deleted safely.

## **46.11 Exercises**

- <span id="page-86-0"></span>**46-1.** Experiment with the programs in [Listing 46-1](#page-61-0) (svmsg\_create.c), [Listing 46-2](#page-64-0) (svmsg\_send.c), and [Listing 46-3](#page-68-0) (svmsg\_receive.c) to confirm your understanding of the msgget(), msgsnd(), and msgrcv() system calls.
- **46-2.** Recode the sequence-number client-server application of Section [44.8](#page-32-0) to use System V message queues. Use a single message queue to transmit messages from both client to server and server to client. Employ the conventions for message types described in Section [46.8.](#page-78-1)
- **46-3.** In the client-server application of Section [46.8,](#page-78-1) why does the client pass the identifier of its message queue in the body of the message (in the clientId field), rather than in the message type (mtype)?
- <span id="page-86-1"></span>**46-4.** Make the following changes to the client-server application of Section [46.8:](#page-78-1)
  - a) Replace the use of a hard-coded message queue key with code in the server that uses IPC\_PRIVATE to generate a unique identifier, and then writes this identifier to a well-known file. The client must read the identifier from this file. The server should remove this file if it terminates.
  - b) In the serveRequest() function of the server program, system call errors are not diagnosed. Add code that logs errors using syslog() (Section 37.5).
  - c) Add code to the server so that it becomes a daemon on startup (Section 37.2).
  - d) In the server, add a handler for SIGTERM and SIGINT that performs a tidy exit. The handler should remove the message queue and (if the earlier part of this exercise was implemented) the file created to hold the server's message queue identifier. Include code in the handler to terminate the server by disestablishing the handler, and then once more raising the same signal that invoked the handler (see Section 26.1.4 for the rationale and steps required for this task).
  - e) The server child doesn't handle the possibility that the client may terminate prematurely, in which case the server child would fill the client's message queue, and then block indefinitely. Modify the server to handle this possibility by establishing a timeout when calling msgsnd(), as described in Section 23.3. If the server child deems that the client has disappeared, it should attempt to delete the client's message queue, and then exit (after perhaps logging a message via syslog()).

- <span id="page-87-0"></span>**46-5.** The client shown in [Listing 46-9](#page-83-0) (svmsg\_file\_client.c) doesn't handle various possibilities for failure in the server. In particular, if the server message queue fills up (perhaps because the server terminated and the queue was filled by other clients), then the msgsnd() call will block indefinitely. Similarly, if the server fails to send a response to the client, then the msgrcv() call will block indefinitely. Add code to the client that sets timeouts (Section 23.3) on these calls. If either call times out, then the program should report an error to the user and terminate.
- **46-6.** Write a simple chat application (similar to talk(1), but without the curses interface) using System V messages queues. Use a single message queue for each client.

# <span id="page-88-0"></span>**SYSTEM V SEMAPHORES**

This chapter describes System V semaphores. Unlike the IPC mechanisms described in previous chapters, System V semaphores are not used to transfer data between processes. Instead, they allow processes to synchronize their actions. One common use of a semaphore is to synchronize access to a block of shared memory, in order to prevent one process from accessing the shared memory at the same time as another process is updating it.

A semaphore is a kernel-maintained integer whose value is restricted to being greater than or equal to 0. Various operations (i.e., system calls) can be performed on a semaphore, including the following:

-  setting the semaphore to an absolute value;
-  adding a number to the current value of the semaphore;
-  subtracting a number from the current value of the semaphore; and
-  waiting for the semaphore value to be equal to 0.

The last two of these operations may cause the calling process to block. When lowering a semaphore value, the kernel blocks any attempt to decrease the value below 0. Similarly, waiting for a semaphore to equal 0 blocks the calling process if the semaphore value is not currently 0. In both cases, the calling process remains blocked until some other process alters the semaphore to a value that allows the operation to proceed, at which point the kernel wakes the blocked process. [Figure 47-1](#page-89-0) shows the use of a semaphore to synchronize the actions of two processes that alternately move the semaphore value between 0 and 1.

```
    Process A                                     Process B
    ---------                                     ---------

   Create semaphore
        |
        v
   Initialize semaphore to 0
        | 
        |                                   Subtract 1 from semaphore
        |                                               |
        v                                               | blocks
   Add 1 to semaphore                                   |
        |                                               |
        |---------------------------------------------> |  resumes             |
        |                                               |                      |
        |                                               |                      | Time
        |                                               |                      |
        v                                               |                      v
   Subtract 1 from semaphore                            |
        | blocks                                        |
        |                                               v
        | <-------------------------------------- Add 1 to semaphore
        | resumes                                       |
        v                                               v
     
```

<span id="page-89-0"></span>**Figure 47-1:** Using a semaphore to synchronize two processes

In terms of controlling the actions of a process, a semaphore has no meaning in and of itself. Its meaning is determined only by the associations given to it by the processes using the semaphore. Typically, processes agree on a convention that associates a semaphore with a shared resource, such as a region of shared memory. Other uses of semaphores are also possible, such as synchronization between parent and child processes after fork(). (In Section 24.5, we looked at the use of signals to accomplish the same task.)

## **47.1 Overview**

The general steps for using a System V semaphore are the following:

-  Create or open a semaphore set using semget().
-  Initialize the semaphores in the set using the semctl() SETVAL or SETALL operation. (Only one process should do this.)
-  Perform operations on semaphore values using semop(). The processes using the semaphore typically use these operations to indicate acquisition and release of a shared resource.
-  When all processes have finished using the semaphore set, remove the set using the semctl() IPC\_RMID operation. (Only one process should do this.)

Most operating systems provide some type of semaphore primitive for use in application programs. However, System V semaphores are rendered unusually complex by the fact that they are allocated in groups called semaphore sets. The number of semaphores in a set is specified when the set is created using the semget() system call. While it is common to operate on a single semaphore at a time, the semop() system call allows us to atomically perform a group of operations on multiple semaphores in the same set.

Because System V semaphores are created and initialized in separate steps, race conditions can result if two processes try to perform these steps at the same time. Describing this race condition and how to avoid it requires that we describe semctl() before describing semop(), which means that there is quite a lot of material to cover before we have all of the details required to fully understand semaphores.

In the meantime, we provide [Listing 47-1](#page-91-0) as a simple example of the use of the various semaphore system calls. This program operates in two modes:

-  Given a single integer command-line argument, the program creates a new semaphore set containing a single semaphore, and initializes the semaphore to the value supplied in the command-line argument. The program displays the identifier of the new semaphore set.
-  Given two command-line arguments, the program interprets them as (in order) the identifier of an existing semaphore set and a value to be added to the first semaphore (numbered 0) in that set. The program carries out the specified operation on that semaphore. To enable us to monitor the semaphore operation, the program prints messages before and after the operation. Each of these messages begins with the process ID, so that we can distinguish the output of multiple instances of the program.

The following shell session log demonstrates the use of the program in [Listing 47-1](#page-91-0). We begin by creating a semaphore that is initialized to 0:

```
$ ./svsem_demo 0
Semaphore ID = 98307 ID of new semaphore set
```

We then execute a background command that tries to decrease the semaphore value by 2:

```
$ ./svsem_demo 98307 -2 &
23338: about to semop at 10:19:42
[1] 23338
```

This command blocked, because the value of the semaphore can't be decreased below 0. Now, we execute a command that adds 3 to the semaphore value:

```
$ ./svsem_demo 98307 +3
23339: about to semop at 10:19:55
23339: semop completed at 10:19:55
23338: semop completed at 10:19:55
[1]+ Done ./svsem_demo 98307 -2
```

The semaphore increment operation succeeded immediately, and caused the semaphore decrement operation in the background command to proceed, since that operation could now be performed without leaving the semaphore's value below 0.

<span id="page-91-0"></span>**Listing 47-1:** Creating and operating on System V semaphores

```
––––––––––––––––––––––––––––––––––––––––––––––––––––––– svsem/svsem_demo.c
#include <sys/types.h>
#include <sys/sem.h>
#include <sys/stat.h>
#include "curr_time.h" /* Declaration of currTime() */
#include "semun.h" /* Definition of semun union */
#include "tlpi_hdr.h"
int
main(int argc, char *argv[])
{
 int semid;
 if (argc < 2 || argc > 3 || strcmp(argv[1], "--help") == 0)
 usageErr("%s init-value\n"
 " or: %s semid operation\n", argv[0], argv[0]);
 if (argc == 2) { /* Create and initialize semaphore */
 union semun arg;
 semid = semget(IPC_PRIVATE, 1, S_IRUSR | S_IWUSR);
 if (semid == -1)
 errExit("semid");
 arg.val = getInt(argv[1], 0, "init-value");
 if (semctl(semid, /* semnum= */ 0, SETVAL, arg) == -1)
 errExit("semctl");
 printf("Semaphore ID = %d\n", semid);
 } else { /* Perform an operation on first semaphore */
 struct sembuf sop; /* Structure defining operation */
 semid = getInt(argv[1], 0, "semid");
 sop.sem_num = 0; /* Specifies first semaphore in set */
 sop.sem_op = getInt(argv[2], 0, "operation");
 /* Add, subtract, or wait for 0 */
 sop.sem_flg = 0; /* No special options for operation */
 printf("%ld: about to semop at %s\n", (long) getpid(), currTime("%T"));
 if (semop(semid, &sop, 1) == -1)
 errExit("semop");
 printf("%ld: semop completed at %s\n", (long) getpid(), currTime("%T"));
 }
 exit(EXIT_SUCCESS);
}
––––––––––––––––––––––––––––––––––––––––––––––––––––––– svsem/svsem_demo.c
```

## **47.2 Creating or Opening a Semaphore Set**

The semget() system call creates a new semaphore set or obtains the identifier of an existing set.

```
#include <sys/types.h> /* For portability */
#include <sys/sem.h>
int semget(key_t key, int nsems, int semflg);
                    Returns semaphore set identifier on success, or –1 on error
```

The key argument is a key generated using one of the methods described in Section [45.2](#page-48-1) (i.e., usually the value IPC\_PRIVATE or a key returned by ftok()).

If we are using semget() to create a new semaphore set, then nsems specifies the number of semaphores in that set, and must be greater than 0. If we are using semget() to obtain the identifier of an existing set, then nsems must be less than or equal to the size of the set (or the error EINVAL results). It is not possible to change the number of semaphores in an existing set.

The semflg argument is a bit mask specifying the permissions to be placed on a new semaphore set or checked against an existing set. These permissions are specified in the same manner as for files (Table 15-4, on page 295). In addition, zero or more of the following flags can be ORed (|) in semflg to control the operation of semget():

IPC\_CREAT

If no semaphore set with the specified key exists, create a new set.

IPC\_EXCL

If IPC\_CREAT was also specified, and a semaphore set with the specified key already exists, fail with the error EEXIST.

These flags are described in more detail in Section [45.1.](#page-45-0)

On success, semget() returns the identifier for the new or existing semaphore set. Subsequent system calls referring to individual semaphores must specify both the semaphore set identifier and the number of the semaphore within that set. The semaphores within a set are numbered starting at 0.

## <span id="page-92-0"></span>**47.3 Semaphore Control Operations**

The semctl() system call performs a variety of control operations on a semaphore set or on an individual semaphore within a set.

```
#include <sys/types.h> /* For portability */
#include <sys/sem.h>
int semctl(int semid, int semnum, int cmd, ... /* union semun arg */);
         Returns nonnegative integer on success (see text); returns –1 on error
```

The semid argument is the identifier of the semaphore set on which the operation is to be performed. For those operations performed on a single semaphore, the semnum argument identifies a particular semaphore within the set. For other operations, this argument is ignored, and we can specify it as 0. The cmd argument specifies the operation to be performed.

Certain operations require a fourth argument to semctl(), which we refer to by the name arg in the remainder of this section. This argument is a union defined as shown in Listing 47-2. We must explicitly define this union in our programs. We do this in our example programs by including the header file in Listing 47-2.

> Although placing the definition of the semun union in a standard header file would be sensible, SUSv3 requires the programmer to explicitly define it instead. Nevertheless, some UNIX implementations do provide this definition in <sys/sem.h>. Older versions of glibc (up to and including version 2.0) also provided this definition. In conformance with SUSv3, more recent versions of glibc do not, and the macro \_SEM\_SEMUN\_UNDEFINED is defined with the value 1 in <sys/sem.h> to indicate this fact (i.e., an application compiled against glibc can test this macro to determine if the program must itself define the semun union).

**Listing 47-2:** Definition of the semun union

```
––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––svsem/semun.h
#ifndef SEMUN_H
#define SEMUN_H /* Prevent accidental double inclusion */
#include <sys/types.h> /* For portability */
#include <sys/sem.h>
union semun { /* Used in calls to semctl() */
 int val;
 struct semid_ds * buf;
 unsigned short * array;
#if defined(__linux__)
 struct seminfo * __buf;
#endif
};
#endif
––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––svsem/semun.h
```

SUSv2 and SUSv3 specify that the final argument to semctl() is optional. However, a few (mainly older) UNIX implementations (and older versions of glibc) prototyped semctl() as follows:

```
int semctl(int semid, int semnum, int cmd, union semun arg);
```

This meant that the fourth argument was required even in the cases where it is not actually used (e.g., the IPC\_RMID and GETVAL operations described below). For full portability, we specify a dummy final argument to semctl() in those calls where it is not required.

In the remainder of this section, we consider the various control operations that can be specified for cmd.

### **Generic control operations**

The following operations are the same ones that can be applied to other types of System V IPC objects. In each case, the semnum argument is ignored. Further details about these operations, including the privileges and permissions required by the calling process, are provided in Section [45.3](#page-50-0).

IPC\_RMID

Immediately remove the semaphore set and its associated semid\_ds data structure. Any processes blocked in semop() calls waiting on semaphores in this set are immediately awakened, with semop() reporting the error EIDRM. The arg argument is not required.

IPC\_STAT

Place a copy of the semid\_ds data structure associated with this semaphore set in the buffer pointed to by arg.buf. We describe the semid\_ds structure in Section [47.4.](#page-95-0)

IPC\_SET

Update selected fields of the semid\_ds data structure associated with this semaphore set using values in the buffer pointed to by arg.buf.

### **Retrieving and initializing semaphore values**

The following operations retrieve or initialize the value(s) of an individual semaphore or of all semaphores in a set. Retrieving a semaphore value requires read permission on the semaphore, while initializing the value requires alter (write) permission.

GETVAL

As its function result, semctl() returns the value of the semnum-th semaphore in the semaphore set specified by semid. The arg argument is not required.

SETVAL

The value of the semnum-th semaphore in the set referred to by semid is initialized to the value specified in arg.val.

GETALL

Retrieve the values of all of the semaphores in the set referred to by semid, placing them in the array pointed to by arg.array. The programmer must ensure that this array is of sufficient size. (The number of semaphores in a set can be obtained from the sem\_nsems field of the semid\_ds data structure retrieved by an IPC\_STAT operation.) The semnum argument is ignored. An example of the use of the GETALL operation is provided in [Listing 47-3](#page-96-0).

SETALL

Initialize all semaphores in the set referred to by semid, using the values supplied in the array pointed to by arg.array. The semnum argument is ignored. [Listing 47-4](#page-97-0) demonstrates the use of the SETALL operation.

If another process is waiting to perform an operation on the semaphore(s) modified by the SETVAL or SETALL operations, and the change(s) made would permit that operation to proceed, then the kernel wakes up that process.

Changing the value of a semaphore with SETVAL or SETALL clears the undo entries for that semaphore in all processes. We describe semaphore undo entries in Section [47.8](#page-109-1).

Note that the information returned by GETVAL and GETALL may already be out of date by the time the calling process comes to use it. Any program that depends on the information returned by these operations being unchanged may be subject to time-of-check, time-of-use race conditions (Section 38.6).

## **Retrieving per-semaphore information**

The following operations return (via the function result value) information about the semnum-th semaphore of the set referred to by semid. For all of these operations, read permission is required on the semaphore set, and the arg argument is not required.

GETPID

Return the process ID of the last process to perform a semop() on this semaphore; this is referred to as the sempid value. If no process has yet performed a semop() on this semaphore, 0 is returned.

GETNCNT

Return the number of processes currently waiting for the value of this semaphore to increase; this is referred to as the semncnt value.

GETZCNT

Return the number of processes currently waiting for the value of this semaphore to become 0; this is referred to as the semzcnt value.

As with the GETVAL and GETALL operations described above, the information returned by the GETPID, GETNCNT, and GETZCNT operations may already be out of date by the time the calling process comes to use it.

[Listing 47-3](#page-96-0) demonstrates the use of these three operations.

# <span id="page-95-0"></span>**47.4 Semaphore Associated Data Structure**

Each semaphore set has an associated semid\_ds data structure of the following form:

```
struct semid_ds {
 struct ipc_perm sem_perm; /* Ownership and permissions */
 time_t sem_otime; /* Time of last semop() */
 time_t sem_ctime; /* Time of last change */
 unsigned long sem_nsems; /* Number of semaphores in set */
};
```

SUSv3 requires all of the fields that we show in the semid\_ds structure. Some other UNIX implementations include additional nonstandard fields. On Linux 2.4 and later, the sem\_nsems field is typed as unsigned long. SUSv3 specifies the type of this field as unsigned short, and it is so defined in Linux 2.2 and on most other UNIX implementations.

The fields of the semid\_ds structure are implicitly updated by various semaphore system calls, and certain subfields of the sem\_perm field can be explicitly updated using the semctl() IPC\_SET operation. The details are as follows:

#### sem\_perm

When the semaphore set is created, the fields of this substructure are initialized as described in Section [45.3.](#page-50-0) The uid, gid, and mode subfields can be updated via IPC\_SET.

sem\_otime

This field is set to 0 when the semaphore set is created, and then set to the current time on each successful semop(), or when the semaphore value is modified as a consequence of a SEM\_UNDO operation (Section [47.8](#page-109-1)). This field and sem\_ctime are typed as time\_t, and store time in seconds since the Epoch.

sem\_ctime

This field is set to the current time when the semaphore set is created and on each successful IPC\_SET, SETALL, or SETVAL operation. (On some UNIX implementations, the SETALL and SETVAL operations don't modify sem\_ctime.)

sem\_nsems

When the set is created, this field is initialized to the number of semaphores in the set.

In the remainder of this section, we show two example programs that make use of the semid\_ds data structure and some of the semctl() operations described in Section [47.3](#page-92-0). We demonstrate the use of both of these programs in Section [47.6](#page-101-0).

## **Monitoring a semaphore set**

The program in [Listing 47-3](#page-96-0) makes use of various semctl() operations to display information about the existing semaphore set whose identifier is provided as its command-line argument. The program first displays the time fields from the semid\_ds data structure. Then, for each semaphore in the set, the program displays the semaphore's current value, as well as its sempid, semncnt, and semzcnt values.

<span id="page-96-1"></span><span id="page-96-0"></span>**Listing 47-3:** A semaphore monitoring program

```
–––––––––––––––––––––––––––––––––––––––––––––––––––––––– svsem/svsem_mon.c
#include <sys/types.h>
#include <sys/sem.h>
#include <time.h>
#include "semun.h" /* Definition of semun union */
#include "tlpi_hdr.h"
int
main(int argc, char *argv[])
{
 struct semid_ds ds;
 union semun arg, dummy; /* Fourth argument for semctl() */
 int semid, j;
```

```
 if (argc != 2 || strcmp(argv[1], "--help") == 0)
 usageErr("%s semid\n", argv[0]);
 semid = getInt(argv[1], 0, "semid");
 arg.buf = &ds;
 if (semctl(semid, 0, IPC_STAT, arg) == -1)
 errExit("semctl");
 printf("Semaphore changed: %s", ctime(&ds.sem_ctime));
 printf("Last semop(): %s", ctime(&ds.sem_otime));
 /* Display per-semaphore information */
 arg.array = calloc(ds.sem_nsems, sizeof(arg.array[0]));
 if (arg.array == NULL)
 errExit("calloc");
 if (semctl(semid, 0, GETALL, arg) == -1)
 errExit("semctl-GETALL");
 printf("Sem # Value SEMPID SEMNCNT SEMZCNT\n");
 for (j = 0; j < ds.sem_nsems; j++)
 printf("%3d %5d %5d %5d %5d\n", j, arg.array[j],
 semctl(semid, j, GETPID, dummy),
 semctl(semid, j, GETNCNT, dummy),
 semctl(semid, j, GETZCNT, dummy));
 exit(EXIT_SUCCESS);
}
–––––––––––––––––––––––––––––––––––––––––––––––––––––––– svsem/svsem_mon.c
```

### **Initializing all semaphores in a set**

The program in [Listing 47-4](#page-97-0) provides a command-line interface for initializing all of the semaphores in an existing set. The first command-line argument is the identifier of the semaphore set to be initialized. The remaining command-line arguments specify the values to which the semaphores are to be initialized (there must be as many of these arguments as there are semaphores in the set).

<span id="page-97-0"></span>**Listing 47-4:** Using the SETALL operation to initialize a System V semaphore set

```
––––––––––––––––––––––––––––––––––––––––––––––––––––– svsem/svsem_setall.c
#include <sys/types.h>
#include <sys/sem.h>
#include "semun.h" /* Definition of semun union */
#include "tlpi_hdr.h"
int
main(int argc, char *argv[])
{
 struct semid_ds ds;
 union semun arg; /* Fourth argument for semctl() */
 int j, semid;
```

```
 if (argc < 3 || strcmp(argv[1], "--help") == 0)
 usageErr("%s semid val...\n", argv[0]);
 semid = getInt(argv[1], 0, "semid");
   /* Obtain size of semaphore set */
 arg.buf = &ds;
 if (semctl(semid, 0, IPC_STAT, arg) == -1)
 errExit("semctl");
 if (ds.sem_nsems != argc - 2)
 cmdLineErr("Set contains %ld semaphores, but %d values were supplied\n",
 (long) ds.sem_nsems, argc - 2);
 /* Set up array of values; perform semaphore initialization */
 arg.array = calloc(ds.sem_nsems, sizeof(arg.array[0]));
 if (arg.array == NULL)
 errExit("calloc");
 for (j = 2; j < argc; j++)
 arg.array[j - 2] = getInt(argv[j], 0, "val");
 if (semctl(semid, 0, SETALL, arg) == -1)
 errExit("semctl-SETALL");
 printf("Semaphore values changed (PID=%ld)\n", (long) getpid());
 exit(EXIT_SUCCESS);
}
––––––––––––––––––––––––––––––––––––––––––––––––––––– svsem/svsem_setall.c
```

# <span id="page-98-0"></span>**47.5 Semaphore Initialization**

According to SUSv3, an implementation is not required to initialize the values of the semaphores in a set created by semget(). Instead, the programmer must explicitly initialize the semaphores using the semctl() system call. (On Linux, the semaphores returned by semget() are in fact initialized to 0, but we can't portably rely on this.) As stated earlier, the fact that semaphore creation and initialization must be performed by separate system calls, instead of in a single atomic step, leads to possible race conditions when initializing a semaphore. In this section, we detail the nature of the race and look at a method of avoiding it based on an idea described in [Stevens, 1999].

Suppose that we have an application consisting of multiple peer processes employing a semaphore to coordinate their actions. Since no single process is guaranteed to be the first to use the semaphore (this is what is meant by the term peer), each process must be prepared to create and initialize the semaphore if it doesn't already exist. For this purpose, we might consider employing the code shown in [Listing 47-5.](#page-99-0)

```
–––––––––––––––––––––––––––––––––––––––––––––––––from svsem/svsem_bad_init.c
   /* Create a set containing 1 semaphore */
 semid = semget(key, 1, IPC_CREAT | IPC_EXCL | perms);
 if (semid != -1) { /* Successfully created the semaphore */
 union semun arg;
 /* XXXX */
 arg.val = 0; /* Initialize semaphore */
 if (semctl(semid, 0, SETVAL, arg) == -1)
 errExit("semctl");
   } else { /* We didn't create the semaphore */
 if (errno != EEXIST) { /* Unexpected error from semget() */
 errExit("semget");
 semid = semget(key, 1, perms); /* Retrieve ID of existing set */
 if (semid == -1)
 errExit("semget");
 }
 /* Now perform some operation on the semaphore */
 sops[0].sem_op = 1; /* Add 1... */
 sops[0].sem_num = 0; /* to semaphore 0 */
 sops[0].sem_flg = 0;
 if (semop(semid, sops, 1) == -1)
 errExit("semop");
–––––––––––––––––––––––––––––––––––––––––––––––––from svsem/svsem_bad_init.c
```

The problem with the code in Listing 47-5 is that if two processes execute it at the same time, then the sequence shown in [Figure 47-2](#page-101-1) could occur, if the first process's time slice happens to expire at the point marked XXXX in the code. This sequence is problematic for two reasons. First, process B performs a semop() on an uninitialized semaphore (i.e., one whose value is arbitrary). Second, the semctl() call in process A overwrites the changes made by process B.

The solution to this problem relies on a historical, and now standardized, feature of the initialization of the sem\_otime field in the semid\_ds data structure associated with the semaphore set. When a semaphore set is first created, the sem\_otime field is initialized to 0, and it is changed only by a subsequent semop() call. We can exploit this feature to eliminate the race condition described above. We do this by inserting extra code to force the second process (i.e., the one that does not create the semaphore) to wait until the first process has both initialized the semaphore and executed a semop() call that updates the sem\_otime field, but does not modify the semaphore's value. The modified code is shown in Listing 47-6.

> Unfortunately, the solution to the initialization problem described in the main text doesn't work on all UNIX implementations. In some versions of the modern BSD derivatives, semop() doesn't update the sem\_otime field.

```
–––––––––––––––––––––––––––––––––––––––––––––––– from svsem/svsem_good_init.c
   semid = semget(key, 1, IPC_CREAT | IPC_EXCL | perms);
 if (semid != -1) { /* Successfully created the semaphore */
 union semun arg;
 struct sembuf sop;
 arg.val = 0; /* So initialize it to 0 */
 if (semctl(semid, 0, SETVAL, arg) == -1)
 errExit("semctl");
 /* Perform a "no-op" semaphore operation - changes sem_otime
 so other processes can see we've initialized the set. */
 sop.sem_num = 0; /* Operate on semaphore 0 */
 sop.sem_op = 0; /* Wait for value to equal 0 */
 sop.sem_flg = 0;
 if (semop(semid, &sop, 1) == -1)
 errExit("semop");
   } else { /* We didn't create the semaphore set */
 const int MAX_TRIES = 10;
 int j;
 union semun arg;
 struct semid_ds ds;
 if (errno != EEXIST) { /* Unexpected error from semget() */
 errExit("semget");
 semid = semget(key, 1, perms); /* Retrieve ID of existing set */
 if (semid == -1)
 errExit("semget");
 /* Wait until another process has called semop() */
 arg.buf = &ds;
 for (j = 0; j < MAX_TRIES; j++) {
 if (semctl(semid, 0, IPC_STAT, arg) == -1)
 errExit("semctl");
 if (ds.sem_otime != 0) /* semop() performed? */
 break; /* Yes, quit loop */
 sleep(1); /* If not, wait and retry */
 }
 if (ds.sem_otime == 0) /* Loop ran to completion! */
 fatal("Existing semaphore not initialized");
 }
 /* Now perform some operation on the semaphore */
–––––––––––––––––––––––––––––––––––––––––––––––– from svsem/svsem_good_init.c
```

We can use variations of the technique shown in Listing 47-6 to ensure that multiple semaphores in a set are correctly initialized, or that a semaphore is initialized to a nonzero value.

This rather complex solution to the race problem is not required in all applications. We don't need it if one process is guaranteed to be able to create and initialize the semaphore before any other processes attempt to use it. This would be the case, for example, if a parent creates and initializes the semaphore before creating child processes with which it shares the semaphore. In such cases, it is sufficient for the first process to follow its semget() call by a semctl() SETVAL or SETALL operation.

```
              Process A                                                    Process B
              ---------                                                    ---------            
                   |                                                          |
                   |                                                          |
                   v                                                          v
   +----------------------------------+                      +----------------------------------+
   | First semget() succeeds          |                      |                                  |
   | (because set didn't exist)       |                      | First semget() fails             |
   +----------------------------------+                      +----------------------------------+
                   |                                                          |
                   |  time slice expires     time slice begins                |
                   | --------------->   | |  -------------------------------> |                                              
                   |                                                          v
                   |                                           +----------------------------------+
                   |                                           | First semget() fails (so this    |
                   |                                           | process knows set exists)        |
                   |                                           +----------------------------------+
                   |          
                   |                                           +----------------------------------+
                   |                                           | Second semget() succeeds        |
                   |                                           +----------------------------------+
                   |                                                           |
                   |                                                           v
                   |                                           +----------------------------------+
                   |                                           | Executes semop()                |
                   |                                           +----------------------------------+
                   |                                                           |
                   |                                                           |
                   |        time slice ends               time slice ends      |
                   |  <-----------------------   | |  <----------------------- v
                   v                                               
   +----------------------------------+       
   | semctl() initializes semaphore   |
   +----------------------------------+
                   |
                   v
   +----------------------------------+
   | Executes semop()                 |
   +----------------------------------+


```

<span id="page-101-1"></span>**Figure 47-2:** Two processes racing to initialize the same semaphore

# <span id="page-101-0"></span>**47.6 Semaphore Operations**

The semop() system call performs one or more operations on the semaphores in the semaphore set identified by semid.

```
#include <sys/types.h> /* For portability */
#include <sys/sem.h>
int semop(int semid, struct sembuf *sops, unsigned int nsops);
                                           Returns 0 on success, or –1 on error
```

The sops argument is a pointer to an array that contains the operations to be performed, and nsops gives the size of this array (which must contain at least one element). The operations are performed atomically and in array order. The elements of the sops array are structures of the following form:

```
struct sembuf {
 unsigned short sem_num; /* Semaphore number */
 short sem_op; /* Operation to be performed */
 short sem_flg; /* Operation flags (IPC_NOWAIT and SEM_UNDO) */
};
```

The sem\_num field identifies the semaphore within the set upon which the operation is to be performed. The sem\_op field specifies the operation to be performed:

-  If sem\_op is greater than 0, the value of sem\_op is added to the semaphore value. As a result, other processes waiting to decrease the semaphore value may be awakened and perform their operations. The calling process must have alter (write) permission on the semaphore.
-  If sem\_op equals 0, the value of the semaphore is checked to see whether it currently equals 0. If it does, the operation completes immediately; otherwise, semop() blocks until the semaphore value becomes 0. The calling process must have read permission on the semaphore.
-  If sem\_op is less than 0, decrease the value of the semaphore by the amount specified in sem\_op. If the current value of the semaphore is greater than or equal to the absolute value of sem\_op, the operation completes immediately. Otherwise, semop() blocks until the semaphore value has been increased to a level that permits the operation to be performed without resulting in a negative value. The calling process must have alter permission on the semaphore.

Semantically, increasing the value of a semaphore corresponds to making a resource available so that others can use it, while decreasing the value of a semaphore corresponds to reserving a resource for (exclusive) use by this process. When decreasing the value of a semaphore, the operation is blocked if the semaphore value is too low—that is, if some other process has already reserved the resource.

When a semop() call blocks, the process remains blocked until one of the following occurs:

-  Another process modifies the value of the semaphore such that the requested operation can proceed.
-  A signal interrupts the semop() call. In this case, the error EINTR results. (As noted in Section 21.5, semop() is never automatically restarted after being interrupted by a signal handler.)
-  Another process deletes the semaphore referred to by semid. In this case, semop() fails with the error EIDRM.

We can prevent semop() from blocking when performing an operation on a particular semaphore by specifying the IPC\_NOWAIT flag in the corresponding sem\_flg field. In this case, if semop() would have blocked, it instead fails with the error EAGAIN.

While it is usual to operate on a single semaphore at a time, it is possible to make a semop() call that performs operations on multiple semaphores in a set. The key point to note is that this group of operations is performed atomically; that is, semop() either performs all of the operations immediately, if possible, or blocks until it would be possible to perform all of the operations simultaneously.

> Few systems document the fact that semop() performs operations in array order, although all systems known to the author do so, and a few applications depend on this behavior. SUSv4 adds text that explicitly requires this behavior.

Listing 47-7 demonstrates the use of semop() to perform operations on three semaphores in a set. The operations on semaphores 0 and 2 may not be able to proceed immediately, depending on the current values of the semaphores. If the operation on semaphore 0 can't be performed immediately, then none of the requested operations is performed, and semop() blocks. On the other hand, if the operation on semaphore 0 could be performed immediately, but the operation on semaphore 2 could not, then—because the IPC\_NOWAIT flag was specified—none of the requested operations is performed, and semop() returns immediately with the error EAGAIN.

The semtimedop() system call performs the same task as semop(), except that the timeout argument specifies an upper limit on the time for which the call will block.

```
#define _GNU_SOURCE
#include <sys/types.h> /* For portability */
#include <sys/sem.h>
int semtimedop(int semid, struct sembuf *sops, unsigned int nsops,
 struct timespec *timeout);
                                         Returns 0 on success, or –1 on error
```

The timeout argument is a pointer to a timespec structure (Section 23.4.2), which allows a time interval to be expressed as a number of seconds and nanoseconds. If the specified time interval expires before it is possible to complete the semaphore operation, semtimedop() fails with the error EAGAIN. If timeout is specified as NULL, semtimedop() is exactly the same as semop().

The semtimedop() system call is provided as a more efficient method of setting a timeout on a semaphore operation than using setitimer() plus semop(). The small performance benefit that this confers is significant for certain applications (notably, some database systems) that need to frequently perform such operations. However, semtimedop() is not specified in SUSv3 and is present on only a few other UNIX implementations.

> The semtimedop() system call appeared as a new feature in Linux 2.6 and was subsequently back-ported into Linux 2.4, starting with kernel 2.4.22.

```
 struct sembuf sops[3];
 sops[0].sem_num = 0; /* Subtract 1 from semaphore 0 */
 sops[0].sem_op = -1;
 sops[0].sem_flg = 0;
 sops[1].sem_num = 1; /* Add 2 to semaphore 1 */
 sops[1].sem_op = 2;
 sops[1].sem_flg = 0;
 sops[2].sem_num = 2; /* Wait for semaphore 2 to equal 0 */
 sops[2].sem_op = 0;
 sops[2].sem_flg = IPC_NOWAIT; /* But don't block if operation
 can't be performed immediately */
 if (semop(semid, sops, 3) == -1) {
 if (errno == EAGAIN) /* Semaphore 2 would have blocked */
 printf("Operation would have blocked\n");
 else
 errExit("semop"); /* Some other error */
 }
```

## **Example program**

The program in [Listing 47-8](#page-105-0) provides a command-line interface to the semop() system call. The first argument to this program is the identifier of the semaphore set upon which operations are to be performed.

Each of the remaining command-line arguments specifies a group of semaphore operations to be performed in a single semop() call. The operations within a single command-line argument are delimited by commas. Each operation has one of the following forms:

-  semnum+value: add value to semaphore semnum.
-  semnum-value: subtract value from semaphore semnum.
-  semnum=0: test semaphore semnum to see if it equals 0.

At the end of each operation, we can optionally include an n, a u, or both. The letter n means include IPC\_NOWAIT in the sem\_flg value for this operation. The letter u means include SEM\_UNDO in sem\_flg. (We describe the SEM\_UNDO flag in Section [47.8.](#page-109-1))

The following command line specifies two semop() calls on the semaphore set whose identifier is 0:

#### \$ **./svsem\_op 0 0=0 0-1,1-2n**

The first command-line argument specifies a semop() call that waits until semaphore zero equals 0. The second argument specifies a semop() call that subtracts 1 from semaphore 0, and subtracts 2 from semaphore 1. For the operation on semaphore 0, sem\_flg is 0; for the operation on semaphore 1, sem\_flg is IPC\_NOWAIT.

<span id="page-105-0"></span>**Listing 47-8:** Performing System V semaphore operations with semop()

```
––––––––––––––––––––––––––––––––––––––––––––––––––––––––– svsem/svsem_op.c
#include <sys/types.h>
#include <sys/sem.h>
#include <ctype.h>
#include "curr_time.h" /* Declaration of currTime() */
#include "tlpi_hdr.h"
#define MAX_SEMOPS 1000 /* Maximum operations that we permit for
 a single semop() */
static void
usageError(const char *progName)
{
 fprintf(stderr, "Usage: %s semid op[,op...] ...\n\n", progName);
 fprintf(stderr, "'op' is either: <sem#>{+|-}<value>[n][u]\n");
 fprintf(stderr, " or: <sem#>=0[n]\n");
 fprintf(stderr, " \"n\" means include IPC_NOWAIT in 'op'\n");
 fprintf(stderr, " \"u\" means include SEM_UNDO in 'op'\n\n");
 fprintf(stderr, "The operations in each argument are "
 "performed in a single semop() call\n\n");
 fprintf(stderr, "e.g.: %s 12345 0+1,1-2un\n", progName);
 fprintf(stderr, " %s 12345 0=0n 1+1,2-1u 1=0\n", progName);
 exit(EXIT_FAILURE);
}
/* Parse comma-delimited operations in 'arg', returning them in the
 array 'sops'. Return number of operations as function result. */
static int
parseOps(char *arg, struct sembuf sops[])
{
 char *comma, *sign, *remaining, *flags;
 int numOps; /* Number of operations in 'arg' */
 for (numOps = 0, remaining = arg; ; numOps++) {
 if (numOps >= MAX_SEMOPS)
 cmdLineErr("Too many operations (maximum=%d): \"%s\"\n",
 MAX_SEMOPS, arg);
 if (*remaining == '\0')
 fatal("Trailing comma or empty argument: \"%s\"", arg);
 if (!isdigit((unsigned char) *remaining))
 cmdLineErr("Expected initial digit: \"%s\"\n", arg);
 sops[numOps].sem_num = strtol(remaining, &sign, 10);
 if (*sign == '\0' || strchr("+-=", *sign) == NULL)
 cmdLineErr("Expected '+', '-', or '=' in \"%s\"\n", arg);
 if (!isdigit((unsigned char) *(sign + 1)))
 cmdLineErr("Expected digit after '%c' in \"%s\"\n", *sign, arg);
 sops[numOps].sem_op = strtol(sign + 1, &flags, 10);
```

```
 if (*sign == '-') /* Reverse sign of operation */
 sops[numOps].sem_op = - sops[numOps].sem_op;
 else if (*sign == '=') /* Should be '=0' */
 if (sops[numOps].sem_op != 0)
 cmdLineErr("Expected \"=0\" in \"%s\"\n", arg);
 sops[numOps].sem_flg = 0;
 for (;; flags++) {
 if (*flags == 'n')
 sops[numOps].sem_flg |= IPC_NOWAIT;
 else if (*flags == 'u')
 sops[numOps].sem_flg |= SEM_UNDO;
 else
 break;
 }
 if (*flags != ',' && *flags != '\0')
 cmdLineErr("Bad trailing character (%c) in \"%s\"\n", *flags, arg);
 comma = strchr(remaining, ',');
 if (comma == NULL)
 break; /* No comma --> no more ops */
 else
 remaining = comma + 1;
 }
 return numOps + 1;
}
int
main(int argc, char *argv[])
{
 struct sembuf sops[MAX_SEMOPS];
 int ind, nsops;
 if (argc < 2 || strcmp(argv[1], "--help") == 0)
 usageError(argv[0]);
 for (ind = 2; argv[ind] != NULL; ind++) {
 nsops = parseOps(argv[ind], sops);
 printf("%5ld, %s: about to semop() [%s]\n", (long) getpid(),
 currTime("%T"), argv[ind]);
 if (semop(getInt(argv[1], 0, "semid"), sops, nsops) == -1)
 errExit("semop (PID=%ld)", (long) getpid());
 printf("%5ld, %s: semop() completed [%s]\n", (long) getpid(),
 currTime("%T"), argv[ind]);
 }
 exit(EXIT_SUCCESS);
}
––––––––––––––––––––––––––––––––––––––––––––––––––––––––– svsem/svsem_op.c
```

Using the program in [Listing 47-8](#page-105-0), along with various others shown in this chapter, we can study the operation of System V semaphores, as demonstrated in the following shell session. We begin by using a program that creates a semaphore set containing two semaphores, which we initialize to 1 and 0:

```
$ ./svsem_create -p 2
32769 ID of semaphore set
$ ./svsem_setall 32769 1 0
Semaphore values changed (PID=3658)
```

We don't show the code of the svsem/svsem\_create.c program in this chapter, but it is provided in the source code distribution for this book. This program performs the same function for semaphores as the program in [Listing 46-1](#page-61-1) (on page [938](#page-61-1)) performs for message queues; that is, it creates a semaphore set. The only notable difference is that svsem\_create.c takes an additional argument specifying the size of the semaphore set to be created.

Next, we start three background instances of the program in [Listing 47-8](#page-105-0) to perform semop() operations on the semaphore set. The program prints messages before and after each semaphore operation. These messages include the time, so that we can see when each operation starts and when it completes, and the process ID, so that we can track the operation of multiple instances of the program. The first command makes a request to decrease both semaphores by 1:

```
$ ./svsem_op 32769 0-1,1-1 & Operation 1
 3659, 16:02:05: about to semop() [0-1,1-1]
[1] 3659
```

In the above output, we see that the program printed a message saying that the semop() operation is about to be performed, but did not print any further messages, because the semop() call blocks. The call blocks because semaphore 1 has the value 0.

Next, we execute a command that makes a request to decrease semaphore 1 by 1:

```
$ ./svsem_op 32769 1-1 & Operation 2
 3660, 16:02:22: about to semop() [1-1]
[2] 3660
```

This command also blocks. Next, we execute a command that waits for the value of semaphore 0 to equal 0:

```
$ ./svsem_op 32769 0=0 & Operation 3
 3661, 16:02:27: about to semop() [0=0]
[3] 3661
```

Again, this command blocks, in this case because the value of semaphore 0 is currently 1.

Now, we use the program in [Listing 47-3](#page-96-0) to inspect the semaphore set:

```
$ ./svsem_mon 32769
Semaphore changed: Sun Jul 25 16:01:53 2010
Last semop(): Thu Jan 1 01:00:00 1970
Sem # Value SEMPID SEMNCNT SEMZCNT
 0 1 0 1 1
 1 0 0 2 0
```

When a semaphore set is created, the sem\_otime field of the associated semid\_ds data structure is initialized to 0. A calendar time value of 0 corresponds to the Epoch (Section 10.1), and ctime() displays this as 1 AM, 1 January 1970, since the local timezone is Central Europe, one hour ahead of UTC.

Examining the output further, we can see that, for semaphore 0, the semncnt value is 1 because operation 1 is waiting to decrease the semaphore value, and semzcnt is 1 because operation 3 is waiting for this semaphore to equal 0. For semaphore 1, the semncnt value of 2 reflects the fact that operation 1 and operation 2 are waiting to decrease the semaphore value.

Next, we try a nonblocking operation on the semaphore set. This operation waits for semaphore 0 to equal 0. Since this operation can't be immediately performed, semop() fails with the error EAGAIN:

```
$ ./svsem_op 32769 0=0n Operation 4
 3673, 16:03:13: about to semop() [0=0n]
ERROR [EAGAIN/EWOULDBLOCK Resource temporarily unavailable] semop (PID=3673)
```

Now we add 1 to semaphore 1. This causes two of the earlier blocked operations (1 and 3) to unblock:

```
$ ./svsem_op 32769 1+1 Operation 5
 3674, 16:03:29: about to semop() [1+1]
 3659, 16:03:29: semop() completed [0-1,1-1] Operation 1 completes
 3661, 16:03:29: semop() completed [0=0] Operation 3 completes
 3674, 16:03:29: semop() completed [1+1] Operation 5 completes
[1] Done ./svsem_op 32769 0-1,1-1
[3]+ Done ./svsem_op 32769 0=0
```

When we use our monitoring program to inspect the state of the semaphore set, we see that the sem\_otime field of the associated semid\_ds data structure has been updated, and the sempid values of both semaphores have been updated. We also see that the semncnt value for semaphore 1 is 1, since operation 2 is still blocked, waiting to decrease the value of this semaphore:

#### \$ **./svsem\_mon 32769** Semaphore changed: Sun Jul 25 16:01:53 2010 Last semop(): Sun Jul 25 16:03:29 2010 Sem # Value SEMPID SEMNCNT SEMZCNT 0 0 3661 0 0 1 0 3659 1 0

From the above output, we see that the sem\_otime value has been updated. We also see that semaphore 0 was last operated on by process ID 3661 (operation 3) and semaphore 1 was last operated on by process ID 3659 (operation 1).

Finally, we remove the semaphore set. This causes the still blocked operation 2 to fail with the error EIDRM:

```
$ ./svsem_rm 32769
ERROR [EIDRM Identifier removed] semop (PID=3660)
```

We don't show the source code for the svsem/svsem\_rm.c program in this chapter, but it is provided in the source code distribution for this book. This program removes the semaphore set identified by its command-line argument.

# **47.7 Handling of Multiple Blocked Semaphore Operations**

If multiple processes are blocked trying to decrease the value of a semaphore by the same amount, then it is indeterminate which process will be permitted to perform the operation first when it becomes possible (i.e., which process is able to perform the operation will depend on vagaries of the kernel process scheduling algorithm).

On the other hand, if processes are blocked trying to decrease a semaphore value by different amounts, then the requests are served in the order in which they become possible. Suppose that a semaphore currently has the value 0, and process A requests to decrease the semaphore's value by 2, and then process B requests to decrease the value by 1. If a third process then adds 1 to the semaphore, process B would be the first to unblock and perform its operation, even though process A was the first to request an operation against the semaphore. In poorly designed applications, such scenarios can lead to starvation, whereby a process remains blocked forever because the state of the semaphore is never such that the requested operation proceeds. Continuing our example, we can envisage scenarios where multiple processes adjust the semaphore in such a way that its value is never more than 1, with the result that process A remains blocked forever.

Starvation can also occur if a process is blocked trying to perform operations on multiple semaphores. Consider the following scenario, performed on a pair of semaphores, both of which initially have the value 0:

- 1. Process A makes a request to subtract 1 from semaphores 0 and 1 (blocks).
- 2. Process B makes a request to subtract 1 from semaphore 0 (blocks).
- 3. Process C adds 1 to semaphore 0.

At this point, process B unblocks and completes its request, even though it placed its request later than process A. Again, it is possible to devise scenarios in which process A is starved while other processes adjust and block on the values of the individual semaphores.

# <span id="page-109-1"></span>**47.8 Semaphore Undo Values**

<span id="page-109-0"></span>Suppose that, having adjusted the value of a semaphore (e.g., decreased the semaphore value so that it is now 0), a process then terminates, either deliberately or accidentally. By default, the semaphore's value is left unchanged. This may constitute a problem for other processes using the semaphore, since they may be blocked waiting on that semaphore—that is, waiting for the now-terminated process to undo the change it made.

To avoid such problems, we can employ the SEM\_UNDO flag when changing the value of a semaphore via semop(). When this flag is specified, the kernel records the effect of the semaphore operation, and then undoes the operation if the process terminates. The undo happens regardless of whether the process terminates normally or abnormally.

The kernel doesn't need to keep a record of all operations performed using SEM\_UNDO. It suffices to record the sum of all of the semaphore adjustments performed using SEM\_UNDO in a per-semaphore, per-process integer total called the semadj (semaphore adjustment) value. When the process terminates, all that is necessary is to subtract this total from the semaphore's current value.

> Since Linux 2.6, processes (threads) created using clone() share semadj values if the CLONE\_SYSVSEM flag is employed. Such sharing is required for a conforming implementation of POSIX threads. The NPTL threading implementation employs CLONE\_SYSVSEM for the implementation of pthread\_create().

When a semaphore value is set using the semctl() SETVAL or SETALL operation, the corresponding semadj values are cleared (i.e., set to 0) in all processes using the semaphore. This makes sense, since absolutely setting the value of a semaphore destroys the value associated with the historical record maintained in the semadj total.

A child created via fork() doesn't inherit its parent's semadj values; it doesn't make sense for a child to undo its parent's semaphore operations. On the other hand, semadj values are preserved across an exec(). This permits us to adjust a semaphore value using SEM\_UNDO, and then exec() a program that performs no operation on the semaphore, but does automatically adjust the semaphore on process termination. (This can be used as a technique that allows another process to discover when this process terminates.)

## **Example of the effect of SEM\_UNDO**

The following shell session log shows the effect of performing operations on two semaphores: one operation with the SEM\_UNDO flag and one without. We begin by creating a set containing two semaphores:

```
$ ./svsem_create -p 2
131073
```

Next, we execute a command that adds 1 to both semaphores and then terminates. The operation on semaphore 0 specifies the SEM\_UNDO flag:

```
$ ./svsem_op 131073 0+1u 1+1
 2248, 06:41:56: about to semop()
 2248, 06:41:56: semop() completed
```

Now, we use the program in [Listing 47-3](#page-96-0) to check the state of the semaphores:

```
$ ./svsem_mon 131073
Semaphore changed: Sun Jul 25 06:41:34 2010
Last semop(): Sun Jul 25 06:41:56 2010
Sem # Value SEMPID SEMNCNT SEMZCNT
 0 0 2248 0 0
 1 1 2248 0 0
```

Looking at the semaphore values in the last two lines of the above output, we can see that the operation on semaphore 0 was undone, but the operation on semaphore 1 was not undone.

## **Limitations of SEM\_UNDO**

We conclude by noting that the SEM\_UNDO flag is less useful than it first appears, for two reasons. One is that because modifying a semaphore typically corresponds to acquiring or releasing some shared resource, the use of SEM\_UNDO on its own may be insufficient to allow a multiprocess application to recover in the event that a process unexpectedly terminates. Unless process termination also automatically returns the shared resource state to a consistent state (unlikely in many scenarios), undoing a semaphore operation is probably insufficient to allow the application to recover.

The second factor limiting the utility of SEM\_UNDO is that, in some cases, it is not possible to perform semaphore adjustments when a process terminates. Consider the following scenario, applied to a semaphore whose initial value is 0:

- 1. Process A increases the value of a semaphore by 2, specifying the SEM\_UNDO flag for the operation.
- 2. Process B decreases the value of the semaphore by 1, so that it has the value 1.
- 3. Process A terminates.

At this point, it is impossible to completely undo the effect of process A's operation in step 1, since the value of the semaphore is too low. There are three possible ways to resolve this situation:

-  Force the process to block until the semaphore adjustment is possible.
-  Decrease the semaphore value as far as possible (i.e., to 0) and exit.
-  Exit without performing any semaphore adjustment.

The first solution is infeasible since it might force a terminating process to block forever. Linux adopts the second solution. Some other UNIX implementations adopt the third solution. SUSv3 is silent on what an implementation should do in this situation.

> An undo operation that attempts to raise a semaphore's value above its permitted maximum value of 32,767 (the SEMVMX limit, described Section [47.10](#page-114-0)) also causes anomalous behavior. In this case, the kernel always performs the adjustment, thus (illegitimately) raising the semaphore's value above SEMVMX.

## **47.9 Implementing a Binary Semaphores Protocol**

<span id="page-111-0"></span>The API for System V semaphores is complex, both because semaphore values can be adjusted by arbitrary amounts, and because semaphores are allocated and operated upon in sets. Both of these features provide more functionality than is typically needed within applications, and so it is useful to implement some simpler protocols (APIs) on top of System V semaphores.

One commonly used protocol is binary semaphores. A binary semaphore has two values: available (free) and reserved (in use). Two operations are defined for binary semaphores:

 Reserve: Attempt to reserve this semaphore for exclusive use. If the semaphore is already reserved by another process, then block until the semaphore is released.

 Release: Free a currently reserved semaphore, so that it can be reserved by another process.

> In academic computer science, these two operations often go by the names P and V, the first letters of the Dutch terms for these operations. This nomenclature was coined by the late Dutch computer scientist Edsger Dijkstra, who produced much of the early theoretical work on semaphores. The terms down (decrement the semaphore) and up (increment the semaphore) are also used. POSIX terms the two operations wait and post.

A third operation is also sometimes defined:

 Reserve conditionally: Make a nonblocking attempt to reserve this semaphore for exclusive use. If the semaphore is already reserved, then immediately return a status indicating that the semaphore is unavailable.

In implementing binary semaphores, we must choose how to represent the available and reserved states, and how to implement the above operations. A moment's reflection leads us to realize that the best way to represent the states is to use the value 1 for free and the value 0 for reserved, with the reserve and release operations decrementing and incrementing the semaphore value by one.

[Listing 47-9](#page-112-0) and [Listing 47-10](#page-113-0) provide an implementation of binary semaphores using System V semaphores. As well as providing the prototypes of the functions in the implementation, the header file in [Listing 47-9](#page-112-0) declares two global Boolean variables exposed by the implementation. The bsUseSemUndo variable controls whether the implementation uses the SEM\_UNDO flag in semop() calls. The bsRetryOnEintr variable controls whether the implementation restarts semop() calls that are interrupted by signals.

<span id="page-112-0"></span>**Listing 47-9:** Header file for binary\_sems.c

```
–––––––––––––––––––––––––––––––––––––––––––––––––––––– svsem/binary_sems.h
#ifndef BINARY_SEMS_H /* Prevent accidental double inclusion */
#define BINARY_SEMS_H
#include "tlpi_hdr.h"
/* Variables controlling operation of functions below */
extern Boolean bsUseSemUndo; /* Use SEM_UNDO during semop()? */
extern Boolean bsRetryOnEintr; /* Retry if semop() interrupted by
 signal handler? */
int initSemAvailable(int semId, int semNum);
int initSemInUse(int semId, int semNum);
int reserveSem(int semId, int semNum);
int releaseSem(int semId, int semNum);
#endif
–––––––––––––––––––––––––––––––––––––––––––––––––––––– svsem/binary_sems.h
```

[Listing 47-10](#page-113-0) shows the implementation of the binary semaphore functions. Each function in this implementation takes two arguments, which identify a semaphore set and the number of a semaphore within that set. (These functions don't deal with the creation and deletion of semaphore sets; nor do they handle the race condition described in Section [47.5.](#page-98-0)) We employ these functions in the example programs shown in Section [48.4](#page-124-0).

<span id="page-113-0"></span>**Listing 47-10:** Implementing binary semaphores using System V semaphores

```
–––––––––––––––––––––––––––––––––––––––––––––––––––––– svsem/binary_sems.c
#include <sys/types.h>
#include <sys/sem.h>
#include "semun.h" /* Definition of semun union */
#include "binary_sems.h"
Boolean bsUseSemUndo = FALSE;
Boolean bsRetryOnEintr = TRUE;
int /* Initialize semaphore to 1 (i.e., "available") */
initSemAvailable(int semId, int semNum)
{
 union semun arg;
 arg.val = 1;
 return semctl(semId, semNum, SETVAL, arg);
}
int /* Initialize semaphore to 0 (i.e., "in use") */
initSemInUse(int semId, int semNum)
{
 union semun arg;
 arg.val = 0;
 return semctl(semId, semNum, SETVAL, arg);
}
/* Reserve semaphore (blocking), return 0 on success, or -1 with 'errno'
 set to EINTR if operation was interrupted by a signal handler */
int /* Reserve semaphore - decrement it by 1 */
reserveSem(int semId, int semNum)
{
 struct sembuf sops;
 sops.sem_num = semNum;
 sops.sem_op = -1;
 sops.sem_flg = bsUseSemUndo ? SEM_UNDO : 0;
 while (semop(semId, &sops, 1) == -1)
 if (errno != EINTR || !bsRetryOnEintr)
 return -1;
 return 0;
}
```

```
int /* Release semaphore - increment it by 1 */
releaseSem(int semId, int semNum)
{
 struct sembuf sops;
 sops.sem_num = semNum;
 sops.sem_op = 1;
 sops.sem_flg = bsUseSemUndo ? SEM_UNDO : 0;
 return semop(semId, &sops, 1);
}
–––––––––––––––––––––––––––––––––––––––––––––––––––––– svsem/binary_sems.c
```

# <span id="page-114-0"></span>**47.10 Semaphore Limits**

Most UNIX implementations impose various limits on the operation of System V semaphores. The following is a list of the Linux semaphore limits. The system call affected by the limit and the error that results if the limit is reached are noted in parentheses.

SEMAEM

This is the maximum value that can be recorded in a semadj total. SEMAEM is defined to have the same value as SEMVMX (described below). (semop(), ERANGE)

SEMMNI

This is a system-wide limit on the number of semaphore identifiers (in other words, semaphore sets) that can be created. (semget(), ENOSPC)

SEMMSL

This is the maximum number of semaphores that can be allocated in a semaphore set. (semget(), EINVAL)

SEMMNS

This is a system-wide limit on the number of semaphores in all semaphore sets. The number of semaphores on the system is also limited by SEMMNI and SEMMSL; in fact, the default value for SEMMNS is the product of the defaults for these two limits. (semget(), ENOSPC)

SEMOPM

This is the maximum number of operations per semop() call. (semop(), E2BIG)

SEMVMX

This is the maximum value for a semaphore. (semop(), ERANGE)

The limits above appear on most UNIX implementations. Some UNIX implementations (but not Linux) impose the following additional limits relating to semaphore undo operations (Section [47.8\)](#page-109-1):

SEMMNU

This is a system-wide limit on the total number of semaphore undo structures. Undo structures are allocated to store semadj values.

SEMUME

This is the maximum number of undo entries per semaphore undo structure.

At system startup, the semaphore limits are set to default values. These defaults may vary across kernel versions. (Some distributors' kernels set different defaults from those provided by vanilla kernels.) Some of these limits can be modified by changing the values stored in the Linux-specific /proc/sys/kernel/sem file. This file contains four space-delimited numbers defining, in order, the limits SEMMSL, SEMMNS, SEMOPM, and SEMMNI. (The SEMVMX and SEMAEM limits can't be changed; both are fixed at 32,767.) As an example, here are the default limits that we see for Linux 2.6.31 on one x86-32 system:

```
$ cd /proc/sys/kernel
$ cat sem
250 32000 32 128
```

The formats employed in the Linux /proc file system are inconsistent for the three System V IPC mechanisms. For message queues and shared memory, each configurable limit is controlled by a separate file. For semaphores, one file holds all configurable limits. This is a historical accident that occurred during the development of these APIs and is difficult to rectify for compatibility reasons.

[Table 47-1](#page-115-0) shows the maximum value to which each limit can be raised on the x86-32 architecture. Note the following supplementary information to this table:

 It is possible to raise SEMMSL to values larger than 65,536, and create semaphore sets up to that larger size. However, it isn't possible to use semop() to adjust semaphores in the set beyond the 65,536th element.

> Because of certain limitations in the current implementation, the practical recommended upper limit on the size of a semaphore set is around 8000.

-  The practical ceiling for the SEMMNS limit is governed by the amount of RAM available on the system.
-  The ceiling value for the SEMOPM limit is determined by memory allocation primitives used within the kernel. The recommended maximum is 1000. In practical usage, it is rarely useful to perform more than a few operations in a single semop() call.

<span id="page-115-0"></span>**Table 47-1:** System V semaphore limits

| Limit  | Ceiling value (x86-32) |  |
|--------|------------------------|--|
| SEMMNI | 32768 (IPCMNI)         |  |
| SEMMSL | 65536                  |  |
| SEMMNS | 2147483647 (INT_MAX)   |  |
| SEMOPM | See text               |  |

The Linux-specific semctl() IPC\_INFO operation retrieves a structure of type seminfo, which contains the values of the various semaphore limits:

```
union semun arg;
struct seminfo buf;
arg.__buf = &buf;
semctl(0, 0, IPC_INFO, arg);
```

A related Linux-specific operation, SEM\_INFO, retrieves a seminfo structure that contains information about actual resources used for semaphore objects. An example of the use of SEM\_INFO is provided in the file svsem/svsem\_info.c in the source code distribution for this book.

<span id="page-116-0"></span>Details about IPC\_INFO, SEM\_INFO, and the seminfo structure can be found in the semctl(2) manual page.

# **47.11 Disadvantages of System V Semaphores**

System V semaphores have many of the same disadvantages as message queues (Section [46.9\)](#page-84-1), including the following:

-  Semaphores are referred to by identifiers, rather than the file descriptors used by most other UNIX I/O and IPC mechanisms. This makes it difficult to perform operations such as simultaneously waiting both on a semaphore and on input from a file descriptor. (It is possible to resolve this difficulty by creating a child process or thread that operates on the semaphore and writes messages to a pipe monitored, along with other file descriptors, using one of the methods described in Chapter 63.)
-  The use of keys, rather than filenames, to identify semaphores results in additional programming complexity.
-  The use of separate system calls for creating and initializing semaphores means that, in some cases, we must do extra programming work to avoid race conditions when initializing a semaphore.
-  The kernel doesn't maintain a count of the number of processes referring to a semaphore set. This complicates the decision about when it is appropriate to delete a semaphore set and makes it difficult to ensure that an unused set is deleted.
-  The programming interface provided by System V is overly complex. In the common case, a program operates on a single semaphore. The ability to simultaneously operate on multiple semaphores in a set is unnecessary.
-  There are various limits on the operation of semaphores. These limits are configurable, but if an application operates outside the range of the default limits, this nevertheless requires extra work when installing the application.

However, unlike the situation with message queues, there are fewer alternatives to System V semaphores, and consequently there are more situations in which we may choose to employ them. One alternative to the use of semaphores is record locking, which we describe in Chapter 55. Also, from kernel 2.6 onward, Linux supports the use of POSIX semaphores for process synchronization. We describe POSIX semaphores in Chapter 53.

# **47.12 Summary**

System V semaphores allow processes to synchronize their actions. This is useful when a process must gain exclusive access to some shared resource, such as a region of shared memory.

Semaphores are created and operated upon in sets containing one or more semaphores. Each semaphore within a set is an integer whose value is always greater than or equal to 0. The semop() system call allows the caller to add an integer to a semaphore, subtract an integer from a semaphore, or wait for a semaphore to equal 0. The last two of these operations may cause the caller to block.

A semaphore implementation is not required to initialize the members of a new semaphore set, so an application must initialize the set after creating it. When any of a number of peer processes may try to create and initialize the semaphore, special care must be taken to avoid the race condition that results from the fact that these two steps are performed via separate system calls.

Where multiple processes are trying to decrease a semaphore by the same amount, it is indeterminate which process will actually be permitted to perform the operation first. However, where different processes are trying to decrease a semaphore by different amounts, the operations complete in the order in which they become possible, and we may need to take care to avoid scenarios where a process is starved because the semaphore value never reaches a level that would allow the process's operation to proceed.

The SEM\_UNDO flag allows a process's semaphore operations to be automatically undone on process termination. This can be useful to avoid scenarios where a process accidentally terminates, leaving a semaphore in a state that causes other processes to block indefinitely waiting for the semaphore's value to be changed by the terminated process.

System V semaphores are allocated and operated upon in sets, and can be increased and decreased by arbitrary amounts. This provides more functionality than is needed by most applications. A common requirement is for individual binary semaphores, which take on only the values 0 and 1. We showed how to implement binary semaphores on top of System V semaphores.

## **Further information**

[Bovet & Cesati, 2005] and [Maxwell, 1999] provide some background on the implementation of semaphores on Linux. [Dijkstra, 1968] is a classic early paper on semaphore theory.

# **47.13 Exercises**

- **47-1.** Experiment with the program in [Listing 47-8](#page-105-0) (svsem\_op.c) to confirm your understanding of the semop() system call.
- **47-2.** Modify the program in Listing 24-6 (fork\_sig\_sync.c, on page 528) to use semaphores instead of signals to synchronize the parent and child processes.
- **47-3.** Experiment with the program in [Listing 47-8](#page-105-0) (svsem\_op.c) and the other semaphore programs provided in this chapter to see what happens to the sempid value if an exiting process performs a SEM\_UNDO adjustment to a semaphore.
- **47-4.** Add a reserveSemNB() function to the code in [Listing 47-10](#page-113-0) (binary\_sems.c) to implement the reserve conditionally operation, using the IPC\_NOWAIT flag.

- <span id="page-118-0"></span>**47-5.** For the VMS operating system, Digital provided a synchronization method similar to a binary semaphore, called an event flag. An event flag has two possible values, clear and set, and the following four operations can be performed: setEventFlag, to set the flag; clearEventFlag, to clear the flag; waitForEventFlag, to block until the flag is set; and getFlagState, to obtain the current state of the flag. Devise an implementation of event flags using System V semaphores. This implementation will require two arguments for each of the functions above: a semaphore identifier and a semaphore number. (Consideration of the waitForEventFlag operation will lead you to realize that the values chosen for clear and set are not the obvious choices.)
- **47-6.** Implement a binary semaphores protocol using named pipes. Provide functions to reserve, release, and conditionally reserve the semaphore.
- **47-7.** Write a program, analogous to the program in [Listing 46-6](#page-76-1) (svmsg\_ls.c, on page [953\)](#page-76-1), that uses the semctl() SEM\_INFO and SEM\_STAT operations to obtain and display a list of all semaphore sets on the system.


# <span id="page-0-0"></span>**INTRODUCTION TO POSIX IPC**

The POSIX.1b realtime extensions defined a set of IPC mechanisms that are analogous to the System V IPC mechanisms described in Chapters 45 to 48. (One of the POSIX.1b developers' aims was to devise a set of IPC mechanisms that did not suffer the deficiencies of the System V IPC facilities.) These IPC mechanisms are collectively referred to as POSIX IPC. The three POSIX IPC mechanisms are the following:

-  Message queues can be used to pass messages between processes. As with System V message queues, message boundaries are preserved, so that readers and writers communicate in units of messages (as opposed to the undelimited byte stream provided by a pipe). POSIX message queues permit each message to be assigned a priority, which allows high-priority messages to be queued ahead of low-priority messages. This provides some of the same functionality that is available via the type field of System V messages.
-  Semaphores permit multiple processes to synchronize their actions. As with System V semaphores, a POSIX semaphore is a kernel-maintained integer whose value is never permitted to go below 0. POSIX semaphores are simpler to use than System V semaphores: they are allocated individually (as opposed to System V semaphore sets), and they are operated on individually using two operations that increase and decrease a semaphore's value by one (as opposed to the ability of the semop() system call to atomically add or subtract arbitrary values from multiple semaphores in a System V semaphore set).

 Shared memory enables multiple processes to share the same region of memory. As with System V shared memory, POSIX shared memory provides fast IPC. Once one process has updated the shared memory, the change is immediately visible to other processes sharing the same region.

<span id="page-1-0"></span>This chapter provides an overview of the POSIX IPC facilities, focusing on their common features.

## **51.1 API Overview**

The three POSIX IPC mechanisms have a number of common features. Table 51-1 summarizes their APIs, and we go into the details of their common features in the next few pages.

> Except for a mention in Table 51-1, in the remainder of this chapter, we'll overlook the fact that POSIX semaphores come in two flavors: named semaphores and unnamed semaphores. Named semaphores are like the other POSIX IPC mechanisms that we describe in this chapter: they are identified by a name, and are accessible by any process that has suitable permissions on the object. An unnamed semaphore doesn't have an associated identifier; instead, it is placed in an area of memory that is shared by a group of processes or by the threads of a single process. We go into the details of both types of semaphores in Chapter [53](#page-32-0).

**Table 51-1:** Summary of programming interfaces for POSIX IPC objects

| Interface     | Message queues        | Semaphores                  | Shared memory         |
|---------------|-----------------------|-----------------------------|-----------------------|
| Header file   | <mqueue.h></mqueue.h> | <semaphore.h></semaphore.h> | <sys mman.h=""></sys> |
| Object handle | mqd_t                 | sem_t *                     | int (file descriptor) |
| Create/open   | mq_open()             | sem_open()                  | shm_open() + mmap()   |
| Close         | mq_close()            | sem_close()                 | munmap()              |
| Unlink        | mq_unlink()           | sem_unlink()                | shm_unlink()          |
| Perform IPC   | mq_send(),            | sem_post(), sem_wait(),     | operate on locations  |
|               | mq_receive()          | sem_getvalue()              | in shared region      |
| Miscellaneous | mq_setattr()—set      | sem_init()—initialize       | (none)                |
| operations    | attributes            | unnamed semaphore           |                       |
|               | mq_getattr()—get      | sem_destroy()—destroy       |                       |
|               | attributes            | unnamed semaphore           |                       |
|               | mq_notify()—request   |                             |                       |
|               | notification          |                             |                       |

#### **IPC object names**

To access a POSIX IPC object, we must have some means of identifying it. The only portable means that SUSv3 specifies to identify a POSIX IPC object is via a name consisting of an initial slash, followed by one of more nonslash characters; for example, /myobject. Linux and some other implementations (e.g., Solaris) permit this type of portable naming for IPC objects.

On Linux, names for POSIX shared memory and message queue objects are limited to NAME\_MAX (255) characters. For semaphores, the limit is 4 characters less, since the implementation prepends the string sem. to the semaphore name.

SUSv3 doesn't prohibit names of a form other than /myobject, but says that the semantics of such names are implementation-defined. The rules for creating IPC object names on some systems are different. For example, on Tru64 5.1, IPC object names are created as names within the standard file system, and the name is interpreted as an absolute or relative pathname. If the caller doesn't have permission to create a file in that directory, then the IPC open call fails. This means that unprivileged programs can't create names of the form /myobject on Tru64, since unprivileged users normally can't create files in the root directory (/). Some other implementations have similar implementation-specific rules for the construction of the names given to IPC open calls. Therefore, in portable applications, we should isolate the generation of IPC object names into a separate function or header file that can be tailored to the target implementation.

#### **Creating or opening an IPC object**

Each IPC mechanism has an associated open call (mq\_open(), sem\_open(), or shm\_open()), which is analogous to the traditional UNIX open() system call used for files. Given an IPC object name, the IPC open call either:

-  creates a new object with the given name, opens that object, and returns a handle for it; or
-  opens an existing object and returns a handle for that object.

The handle returned by the IPC open call is analogous to the file descriptor returned by the traditional open() system call—it is used in subsequent calls to refer to the object.

The type of handle returned by the IPC open call depends on the type of object. For message queues, it is a message queue descriptor, a value of type mqd\_t. For semaphores, it is a pointer of type sem\_t \*. For shared memory, it is a file descriptor.

All of the IPC open calls permit at least three arguments—name, oflag, and mode—as exemplified by the following shm\_open() call:

```
fd = shm_open("/mymem", O_CREAT | O_RDWR, S_IRUSR | S_IWUSR);
```

These arguments are analogous to the arguments of the traditional UNIX open() system call. The name argument identifies the object to be created or opened. The oflag argument is a bit mask that can include at least the following flags:

O\_CREAT

Create the object if it doesn't already exist. If this flag is not specified and the object doesn't exist, an error results (ENOENT).

O\_EXCL

If O\_CREAT is also specified and the object already exists, an error results (EEXIST). The two steps—check for existence and creation—are performed atomically (Section 5.1). This flag has no effect if O\_CREAT is not specified.

Depending on the type of object, oflag may also include one of the values O\_RDONLY, O\_WRONLY, or O\_RDWR, with meanings similar to open(). Additional flags are allowed for some IPC mechanisms.

The remaining argument, mode, is a bit mask specifying the permissions to be placed on a new object, if one is created by the call (i.e., O\_CREAT was specified and the object did not already exist). The values that may be specified for mode are the same as for files (Table 15-4, on page 295). As with the open() system call, the permissions mask in mode is masked against the process umask (Section 15.4.6). The ownership and group ownership of a new IPC object are taken from the effective user and group IDs of the process making the IPC open call. (To be strictly accurate, on Linux, the ownership of a new POSIX IPC object is determined by the process's file-system IDs, which normally have the same value as the corresponding effective IDs. Refer to Section 9.5.)

> On systems where IPC objects appear in the standard file system, SUSv3 permits an implementation to set the group ID of a new IPC object to the group ID of the parent directory.

#### **Closing an IPC object**

For POSIX message queues and semaphores, there is an IPC close call that indicates that the calling process has finished using the object and the system may deallocate any resources that were associated with the object for this process. A POSIX shared memory object is closed by unmapping it with munmap().

IPC objects are automatically closed if the process terminates or performs an exec().

#### **IPC object permissions**

IPC objects have a permissions mask that is the same as for files. Permissions for accessing an IPC object are similar to those for accessing files (Section 15.4.3), except that execute permission has no meaning for POSIX IPC objects.

Since kernel 2.6.19, Linux supports the use of access control lists (ACLs) for setting the permissions on POSIX shared memory objects and named semaphores. Currently, ACLs are not supported for POSIX message queues.

### **IPC object deletion and object persistence**

As with open files, POSIX IPC objects are reference counted—the kernel maintains a count of the number of open references to the object. By comparison with System V IPC objects, this makes it easier for applications to determine when the object can be safely deleted.

Each IPC object has a corresponding unlink call whose operation is analogous to the traditional unlink() system call for files. The unlink call immediately removes the object's name, and then destroys the object once all processes cease using it (i.e., when the reference count falls to zero). For message queues and semaphores, this means that the object is destroyed after all processes have closed the object; for shared memory, destruction occurs after all processes have unmapped the object using munmap().

After an object is unlinked, IPC open calls specifying the same object name will refer to a new object (or fail, if O\_CREAT was not specified).

As with System V IPC, POSIX IPC objects have kernel persistence. Once created, an object continues to exist until it is unlinked or the system is shut down. This allows a process to create an object, modify its state, and then exit, leaving the object to be accessed by some process that is started at a later time.

#### **Listing and removing POSIX IPC objects via the command line**

System V IPC provides two commands, ipcs and ipcrm, for listing and deleting IPC objects. No standard commands are provided to perform the analogous tasks for POSIX IPC objects. However, on many systems, including Linux, IPC objects are implemented within a real or virtual file system, mounted somewhere under the root directory (/), and the standard ls and rm commands can be used to list and remove IPC objects. (SUSv3 doesn't specify the use of ls and rm for these tasks.) The main problem with using these commands is the nonstandard nature of POSIX IPC object names and their location in the file system.

On Linux, POSIX IPC objects are contained in virtual file systems mounted under directories that have the sticky bit set. This bit is the restricted deletion flag (Section 15.4.5); setting it means that an unprivileged process can unlink only the POSIX IPC objects that it owns.

#### **Compiling programs that use POSIX IPC on Linux**

<span id="page-4-0"></span>On Linux, programs employing the POSIX IPC mechanisms must be linked with the realtime library, librt, by specifying the –lrt option to the cc command.

## **51.2 Comparison of System V IPC and POSIX IPC**

As we look at the POSIX IPC mechanisms in the following chapters, we'll compare each mechanism against its System V counterpart. Here, we consider a few general comparisons for these two types of IPC.

POSIX IPC has the following general advantages when compared to System V IPC:

-  The POSIX IPC interface is simpler than the System V IPC interface.
-  The POSIX IPC model—the use of names instead of keys, and the open, close, and unlink functions—is more consistent with the traditional UNIX file model.
-  POSIX IPC objects are reference counted. This simplifies object deletion, because we can unlink a POSIX IPC object, knowing that it will be destroyed only when all processes have closed it.

However, there is one notable advantage in favor of System V IPC: portability. POSIX IPC is less portable than System V IPC in the following respects:

 System V IPC is specified in SUSv3 and supported on nearly every UNIX implementation. By contrast, each of the POSIX IPC mechanisms is an optional component in SUSv3. Some UNIX implementations don't support (all of) the POSIX IPC mechanisms. This situation is reflected in microcosm on Linux: POSIX shared memory is supported only since kernel 2.4; a full implementation of POSIX semaphores is available only since kernel 2.6; and POSIX message queues are supported only since kernel 2.6.6.

-  Despite the SUSv3 specification for POSIX IPC object names, the various implementations follow different conventions for naming IPC objects. These differences require us to do (a little) extra work to write portable applications.
-  Various details of POSIX IPC are not specified in SUSv3. In particular, no commands are specified for displaying and deleting the IPC objects that exist on a system. (In many implementations, standard file-system commands are used, but the details of the pathnames used to identify IPC objects vary.)

## **51.3 Summary**

POSIX IPC is the general name given to three IPC mechanisms—message queues, semaphores, and shared memory—that were devised by POSIX.1b as alternatives to the analogous System V IPC mechanisms.

The POSIX IPC interface is more consistent with the traditional UNIX file model. IPC objects are identified by names, and managed using open, close, and unlink calls that operate in a manner similar to the analogous file-related system calls.

POSIX IPC provides an interface that is superior in many respects to the System V IPC interface. However, POSIX IPC is somewhat less portable than System V IPC.

# **POSIX MESSAGE QUEUES**

This chapter describes POSIX message queues, which allow processes to exchange data in the form of messages. POSIX message queues are similar to their System V counterparts, in that data is exchanged in units of whole messages. However, there are also some notable differences:

-  POSIX message queues are reference counted. A queue that is marked for deletion is removed only after it is closed by all processes that are currently using it.
-  Each System V message has an integer type, and messages can be selected in a variety of ways using msgrcv(). By contrast, POSIX messages have an associated priority, and messages are always strictly queued (and thus received) in priority order.
-  POSIX message queues provide a feature that allows a process to be asynchronously notified when a message is available on a queue.

POSIX message queues are a relatively recent addition to Linux. The required implementation support was added in kernel 2.6.6 (in addition, glibc 2.3.4 or later is required).

> POSIX message queue support is an optional kernel component that is configured via the CONFIG\_POSIX\_MQUEUE option.

## **52.1 Overview**

The main functions in the POSIX message queue API are the following:

-  The mq\_open() function creates a new message queue or opens an existing queue, returning a message queue descriptor for use in later calls.
-  The mq\_send() function writes a message to a queue.
-  The mq\_receive() function reads a message from a queue.
-  The mq\_close() function closes a message queue that the process previously opened.
-  The mq\_unlink() function removes a message queue name and marks the queue for deletion when all processes have closed it.

The above functions all serve fairly obvious purposes. In addition, a couple of features are peculiar to the POSIX message queue API:

-  Each message queue has an associated set of attributes. Some of these attributes can be set when the queue is created or opened using mq\_open(). Two functions are provided to retrieve and change queue attributes: mq\_getattr() and mq\_setattr().
-  The mq\_notify() function allows a process to register for message notification from a queue. After registering, the process is notified of the availability of a message by delivery of a signal or by the invocation of a function in a separate thread.

## **52.2 Opening, Closing, and Unlinking a Message Queue**

In this section, we look at the functions used to open, close, and remove message queues.

#### **Opening a message queue**

The mq\_open() function creates a new message queue or opens an existing queue.

```
#include <fcntl.h> /* Defines O_* constants */
#include <sys/stat.h> /* Defines mode constants */
#include <mqueue.h>
mqd_t mq_open(const char *name, int oflag, ...
 /* mode_t mode, struct mq_attr *attr */);
         Returns a message queue descriptor on success, or (mqd_t) –1 on error
```

The name argument identifies the message queue, and is specified according to the rules given in Section [51.1](#page-1-0).

The oflag argument is a bit mask that controls various aspects of the operation of mq\_open(). The values that can be included in this mask are summarized in [Table 52-1](#page-8-0).

<span id="page-8-0"></span>**Table 52-1:** Bit values for the mq\_open() oflag argument

| Flag       | Description                              |
|------------|------------------------------------------|
| O_CREAT    | Create queue if it doesn't already exist |
| O_EXCL     | With O_CREAT, create queue exclusively   |
| O_RDONLY   | Open for reading only                    |
| O_WRONLY   | Open for writing only                    |
| O_RDWR     | Open for reading and writing             |
| O_NONBLOCK | Open in nonblocking mode                 |

One of the purposes of the oflag argument is to determine whether we are opening an existing queue or creating and opening a new queue. If oflag doesn't include O\_CREAT, we are opening an existing queue. If oflag includes O\_CREAT, a new, empty queue is created if one with the given name doesn't already exist. If oflag specifies both O\_CREAT and O\_EXCL, and a queue with the given name already exists, then mq\_open() fails.

The oflag argument also indicates the kind of access that the calling process will make to the message queue, by specifying exactly one of the values O\_RDONLY, O\_WRONLY, or O\_RDWR.

The remaining flag value, O\_NONBLOCK, causes the queue to be opened in nonblocking mode. If a subsequent call to mq\_receive() or mq\_send() can't be performed without blocking, the call will fail immediately with the error EAGAIN.

If mq\_open() is being used to open an existing message queue, the call requires only two arguments. However, if O\_CREAT is specified in flags, two further arguments are required: mode and attr. (If the queue specified by name already exists, these two arguments are ignored.) These arguments are used as follows:

-  The mode argument is a bit mask that specifies the permissions to be placed on the new message queue. The bit values that may be specified are the same as for files (Table 15-4, on page 295), and, as with open(), the value in mode is masked against the process umask (Section 15.4.6). To read from a queue (mq\_receive()), read permission must be granted to the corresponding class of user; to write to a queue (mq\_send()), write permission is required.
-  The attr argument is an mq\_attr structure that specifies attributes for the new message queue. If attr is NULL, the queue is created with implementation-defined default attributes. We describe the mq\_attr structure in Section [52.4.](#page-11-0)

Upon successful completion, mq\_open() returns a message queue descriptor, a value of type mqd\_t, which is used in subsequent calls to refer to this open message queue. The only stipulation that SUSv3 makes about this data type is that it may not be an array; that is, it is guaranteed to be a type that can be used in an assignment statement or passed by value as a function argument. (On Linux, mqd\_t is an int, but, for example, on Solaris it is defined as void \*.)

An example of the use of mq\_open() is provided in [Listing 52-2.](#page-12-0)

## **Effect of fork(), exec(), and process termination on message queue descriptors**

During a fork(), the child process receives copies of its parent's message queue descriptors, and these descriptors refer to the same open message queue descriptions. (We explain message queue descriptions in Section [52.3.](#page-10-0)) The child doesn't inherit any of its parent's message notification registrations.

When a process performs an exec() or terminates, all of its open message queue descriptors are closed. As a consequence of closing its message queue descriptors, all of the process's message notification registrations on the corresponding queues are deregistered.

#### **Closing a message queue**

The mq\_close() function closes the message queue descriptor mqdes.

```
#include <mqueue.h>
int mq_close(mqd_t mqdes);
                                             Returns 0 on success, or –1 on error
```

If the calling process has registered via mqdes for message notification from the queue (Section [52.6](#page-20-0)), then the notification registration is automatically removed, and another process can subsequently register for message notification from the queue.

A message queue descriptor is automatically closed when a process terminates or calls exec(). As with file descriptors, we should explicitly close message queue descriptors that are no longer required, in order to prevent the process from running out of message queue descriptors.

As close() for files, closing a message queue doesn't delete it. For that purpose, we need mq\_unlink(), which is the message queue analog of unlink().

#### **Removing a message queue**

The mq\_unlink() function removes the message queue identified by name, and marks the queue to be destroyed once all processes cease using it (this may mean immediately, if all processes that had the queue open have already closed it).

```
#include <mqueue.h>
int mq_unlink(const char *name);
                                            Returns 0 on success, or –1 on error
```

[Listing 52-1](#page-9-0) demonstrates the use of mq\_unlink().

<span id="page-9-0"></span>**Listing 52-1:** Using mq\_unlink() to unlink a POSIX message queue

```
––––––––––––––––––––––––––––––––––––––––––––––––––––––– pmsg/pmsg_unlink.c
#include <mqueue.h>
#include "tlpi_hdr.h"
int
main(int argc, char *argv[])
{
```

```
 if (argc != 2 || strcmp(argv[1], "--help") == 0)
 usageErr("%s mq-name\n", argv[0]);
 if (mq_unlink(argv[1]) == -1)
 errExit("mq_unlink");
 exit(EXIT_SUCCESS);
}
––––––––––––––––––––––––––––––––––––––––––––––––––––––– pmsg/pmsg_unlink.c
```

## <span id="page-10-0"></span>**52.3 Relationship Between Descriptors and Message Queues**

The relationship between a message queue descriptor and an open message queue is analogous to the relationship between a file descriptor and an open file (Figure 5-2, on page 95). A message queue descriptor is a per-process handle that refers to an entry in the system-wide table of open message queue descriptions, and this entry in turn refers to a message queue object. This relationship is illustrated in [Figure 52-1.](#page-10-1)

> On Linux, POSIX message queues are implemented as i-nodes in a virtual file system, and message queue descriptors and open message queue descriptions are implemented as file descriptors and open file descriptions, respectively. However, these are implementation details that are not required by SUSv3 and don't hold true on some other UNIX implementations. Nevertheless, we return to this point in Section [52.7,](#page-26-0) because Linux provides some nonstandard features that are made possible by this implementation.

```
    Process A: Message queue descriptor table    Table of open MQ desc.              Message queue table
    +-------------------------------+               (system-wide)                        (system-wide)
    | (other info) | ptr to MQ desc |          +----------------------+        +------------------------------+
    +--------------+----------------+          | flags | ptr to MQ    |        | per-queue info:              |
    |                               |          +-------+--------------+        | MQ attrs; UID,GID;           |
    +--------------+----------------+          |       |              |        | notif settings; msg data     |
  x |                               |-----|    +-------+--------------+        +------------------------------+
    +--------------+----------------+  |--|--->|       |              |----|   |                              |   
  y |                               |--|---|   +-------+--------------+    |   +------------------------------+
    +--------------+----------------+  |   |   |       |              |    |-->|           /mq-p              |  
  z |                               |--||  |   +-------+--------------+        +------------------------------+
    +--------------+----------------+  ||  |-->|       |              |----|   |                              |  
    |                               |  ||      +-------+--------------+    |   +------------------------------+
    +--------------+----------------+  ||      |       |              |    |-->|           /mq-q              |               
                                       ||      +-------+--------------+        +------------------------------+                 
    Process B: MQ descriptor table     ||----->|       |              |----|   |                              |  
    +-------------------------------+  |       +-------+--------------+    |   +------------------------------+
    | (other info) | ptr to MQ desc |  |       |       |              |    |-->|           /mq-r              |  
    +--------------+----------------+  |       +-------+--------------+    |   +------------------------------+
    |                               |  |   |-->|       |              |    |   |                              |
    +--------------+----------------+  |   |   +-------+--------------+    |   +------------------------------+
  x |                               |--|   |   |       |              |----| 
    +--------------+----------------+      |   +-------+--------------+  
  y |                               |------|
    +--------------+----------------+
    |                               |
    +--------------+----------------+   
```

<span id="page-10-1"></span>**Figure 52-1:** Relationship between kernel data structures for POSIX message queues

[Figure 52-1](#page-10-1) helps clarify a number of details of the use of message queue descriptors (all of which are analogous to the use to file descriptors):

-  An open message queue description has an associated set of flags. SUSv3 specifies only one such flag, O\_NONBLOCK, which determines whether I/O is nonblocking.
-  Two processes can hold message queue descriptors (descriptor x in the diagram) that refer to the same open message queue description. This can occur because a process opens a message queue and then calls fork(). These descriptors share the state of the O\_NONBLOCK flag.
-  Two processes can hold open message queue descriptors that refer to different message queue descriptions that refer to the same message queue (e.g., descriptor z in process A and descriptor y in process B both refer to /mq-r). This occurs because the two processes each used mq\_open() to open the same queue.

## <span id="page-11-0"></span>**52.4 Message Queue Attributes**

The mq\_open(), mq\_getattr(), and mq\_setattr() functions all permit an argument that is a pointer to an mq\_attr structure. This structure is defined in <mqueue.h> as follows:

```
struct mq_attr {
 long mq_flags; /* Message queue description flags: 0 or
 O_NONBLOCK [mq_getattr(), mq_setattr()] */
 long mq_maxmsg; /* Maximum number of messages on queue
 [mq_open(), mq_getattr()] */
 long mq_msgsize; /* Maximum message size (in bytes)
 [mq_open(), mq_getattr()] */
 long mq_curmsgs; /* Number of messages currently in queue
 [mq_getattr()] */
};
```

Before we look at the mq\_attr structure in detail, it is worth noting the following points:

-  Only some of the fields are used by each of the three functions. The fields used by each function are indicated in the comments accompanying the structure definition above.
-  The structure contains information about the open message queue description (mq\_flags) associated with a message descriptor and information about the queue referred to by that descriptor (mq\_maxmsg, mq\_msgsize, mq\_curmsgs).
-  Some of the fields contain information that is fixed at the time the queue is created with mq\_open() (mq\_maxmsg and mq\_msgsize); the others return information about the current state of the message queue description (mq\_flags) or message queue (mq\_curmsgs).

#### **Setting message queue attributes during queue creation**

When we create a message queue with mq\_open(), the following mq\_attr fields determine the attributes of the queue:

 The mq\_maxmsg field defines the limit on the number of messages that can be placed on the queue using mq\_send(). This value must be greater than 0.

 The mq\_msgsize field defines the upper limit on the size of each message that may be placed on the queue. This value must be greater than 0.

Together, these two values allow the kernel to determine the maximum amount of memory that this message queue may require.

The mq\_maxmsg and mq\_msgsize attributes are fixed when a message queue is created; they can't subsequently be changed. In Section [52.8,](#page-28-0) we describe two /proc files that place system-wide limits on the values that can be specified for the mq\_maxmsg and mq\_msgsize attributes.

The program in [Listing 52-2](#page-12-0) provides a command-line interface to the mq\_open() function and shows how the mq\_attr structure is used with mq\_open().

Two command-line options allow message queue attributes to be specified: –m for mq\_maxmsg and –s for mq\_msgsize. If either of these options is supplied, a non-NULL attrp argument is passed to mq\_open(). Some default values are assigned to the fields of the mq\_attr structure to which attrp points, in case only one of the –m and –s options is specified on the command line. If neither of these options is supplied, attrp is specified as NULL when calling mq\_open(), which causes the queue to be created with the implementation-defined defaults for the queue attributes.

<span id="page-12-0"></span>**Listing 52-2:** Creating a POSIX message queue

```
––––––––––––––––––––––––––––––––––––––––––––––––––––––– pmsg/pmsg_create.c
#include <mqueue.h>
#include <sys/stat.h>
#include <fcntl.h>
#include "tlpi_hdr.h"
static void
usageError(const char *progName)
{
 fprintf(stderr, "Usage: %s [-cx] [-m maxmsg] [-s msgsize] mq-name "
 "[octal-perms]\n", progName);
 fprintf(stderr, " -c Create queue (O_CREAT)\n");
 fprintf(stderr, " -m maxmsg Set maximum # of messages\n");
 fprintf(stderr, " -s msgsize Set maximum message size\n");
 fprintf(stderr, " -x Create exclusively (O_EXCL)\n");
 exit(EXIT_FAILURE);
}
int
main(int argc, char *argv[])
{
 int flags, opt;
 mode_t perms;
 mqd_t mqd;
 struct mq_attr attr, *attrp;
 attrp = NULL;
 attr.mq_maxmsg = 50;
 attr.mq_msgsize = 2048;
 flags = O_RDWR;
```

```
 /* Parse command-line options */
 while ((opt = getopt(argc, argv, "cm:s:x")) != -1) {
 switch (opt) {
 case 'c':
 flags |= O_CREAT;
 break;
 case 'm':
 attr.mq_maxmsg = atoi(optarg);
 attrp = &attr;
 break;
 case 's':
 attr.mq_msgsize = atoi(optarg);
 attrp = &attr;
 break;
 case 'x':
 flags |= O_EXCL;
 break;
 default: 
         usageError(argv[0]);
 }
 }
 if (optind >= argc)
 usageError(argv[0]);
 perms = (argc <= optind + 1) ? (S_IRUSR | S_IWUSR) :
 getInt(argv[optind + 1], GN_BASE_8, "octal-perms");
 mqd = mq_open(argv[optind], flags, perms, attrp);
 if (mqd == (mqd_t) -1)
 errExit("mq_open");
 exit(EXIT_SUCCESS);
}
––––––––––––––––––––––––––––––––––––––––––––––––––––––– pmsg/pmsg_create.c
```

## **Retrieving message queue attributes**

The mq\_getattr() function returns an mq\_attr structure containing information about the message queue description and the message queue associated with the descriptor mqdes.

```
#include <mqueue.h>
int mq_getattr(mqd_t mqdes, struct mq_attr *attr);
                                             Returns 0 on success, or –1 on error
```

In addition to the mq\_maxmsg and mq\_msgsize fields, which we have already described, the following fields are returned in the structure pointed to by attr:

#### mq\_flags

These are flags for the open message queue description associated with the descriptor mqdes. Only one such flag is specified: O\_NONBLOCK. This flag is initialized from the oflag argument of mq\_open(), and can be changed using mq\_setattr().

#### mq\_curmsgs

This is the number of messages that are currently in the queue. This information may already have changed by the time mq\_getattr() returns, if other processes are reading messages from the queue or writing messages to it.

The program in [Listing 52-3](#page-14-0) employs mq\_getattr() to retrieve the attributes for the message queue specified in its command-line argument, and then displays those attributes on standard output.

<span id="page-14-0"></span>**Listing 52-3:** Retrieving POSIX message queue attributes

```
–––––––––––––––––––––––––––––––––––––––––––––––––––––– pmsg/pmsg_getattr.c
#include <mqueue.h>
#include "tlpi_hdr.h"
int
main(int argc, char *argv[])
{
 mqd_t mqd;
 struct mq_attr attr;
 if (argc != 2 || strcmp(argv[1], "--help") == 0)
 usageErr("%s mq-name\n", argv[0]);
 mqd = mq_open(argv[1], O_RDONLY);
 if (mqd == (mqd_t) -1)
 errExit("mq_open");
 if (mq_getattr(mqd, &attr) == -1)
 errExit("mq_getattr");
 printf("Maximum # of messages on queue: %ld\n", attr.mq_maxmsg);
 printf("Maximum message size: %ld\n", attr.mq_msgsize);
 printf("# of messages currently on queue: %ld\n", attr.mq_curmsgs);
 exit(EXIT_SUCCESS);
}
–––––––––––––––––––––––––––––––––––––––––––––––––––––– pmsg/pmsg_getattr.c
```

In the following shell session, we use the program in [Listing 52-2](#page-12-0) to create a message queue with implementation-defined default attributes (i.e., the final argument to mq\_open() is NULL), and then use the program in [Listing 52-3](#page-14-0) to display the queue attributes so that we can see the default settings on Linux.

```
$ ./pmsg_create -cx /mq
$ ./pmsg_getattr /mq
Maximum # of messages on queue: 10
Maximum message size: 8192
# of messages currently on queue: 0
$ ./pmsg_unlink /mq Remove message queue
```

From the above output, we see that the Linux default values for mq\_maxmsg and mq\_msgsize are 10 and 8192, respectively.

There is a wide variation in the implementation-defined defaults for mq\_maxmsg and mq\_msgsize. Portable applications generally need to choose explicit values for these attributes, rather than relying on the defaults.

#### **Modifying message queue attributes**

The mq\_setattr() function sets attributes of the message queue description associated with the message queue descriptor mqdes, and optionally returns information about the message queue.

```
#include <mqueue.h>
int mq_setattr(mqd_t mqdes, const struct mq_attr *newattr,
 struct mq_attr *oldattr);
                                         Returns 0 on success, or –1 on error
```

The mq\_setattr() function performs the following tasks:

-  It uses the mq\_flags field in the mq\_attr structure pointed to by newattr to change the flags of the message queue description associated with the descriptor mqdes.
-  If oldattr is non-NULL, it returns an mq\_attr structure containing the previous message queue description flags and message queue attributes (i.e., the same task as is performed by mq\_getattr()).

The only attribute that SUSv3 specifies that can be changed using mq\_setattr() is the state of the O\_NONBLOCK flag.

Allowing for the possibility that a particular implementation may define other modifiable flags, or that SUSv3 may add new flags in the future, a portable application should change the state of the O\_NONBLOCK flag by using mq\_getattr() to retrieve the mq\_flags value, modifying the O\_NONBLOCK bit, and calling mq\_setattr() to change the mq\_flags settings. For example, to enable O\_NONBLOCK, we would do the following:

```
if (mq_getattr(mqd, &attr) == -1)
 errExit("mq_getattr");
attr.mq_flags |= O_NONBLOCK;
if (mq_setattr(mqd, &attr, NULL) == -1)
 errExit("mq_getattr");
```

## **52.5 Exchanging Messages**

In this section, we look at the functions that are used to send messages to and receive messages from a queue.

### <span id="page-16-0"></span>**52.5.1 Sending Messages**

The mq\_send() function adds the message in the buffer pointed to by msg\_ptr to the message queue referred to by the descriptor mqdes.

```
#include <mqueue.h>
int mq_send(mqd_t mqdes, const char *msg_ptr, size_t msg_len,
 unsigned int msg_prio);
                                         Returns 0 on success, or –1 on error
```

The msg\_len argument specifies the length of the message pointed to by msg\_ptr. This value must be less than or equal to the mq\_msgsize attribute of the queue; otherwise, mq\_send() fails with the error EMSGSIZE. Zero-length messages are permitted.

Each message has a nonnegative integer priority, specified by the msg\_prio argument. Messages are ordered within the queue in descending order of priority (i.e., 0 is the lowest priority). When a new message is added to the queue, it is placed after any other messages of the same priority. If an application doesn't need to use message priorities, it is sufficient to always specify msg\_prio as 0.

> As noted at the beginning of this chapter, the type attribute of System V messages provides different functionality. System V messages are always queued in FIFO order, but msgrcv() allows us to select messages in various ways: in FIFO order, by exact type, or by highest type less than or equal to some value.

SUSv3 allows an implementation to advertise its upper limit for message priorities, either by defining the constant MQ\_PRIO\_MAX or via the return from sysconf(\_SC\_MQ\_PRIO\_MAX). SUSv3 requires this limit to be at least 32 (\_POSIX\_MQ\_PRIO\_MAX); that is, priorities at least in the range 0 to 31 are available. However, the actual range on implementations is highly variable. For example, on Linux, this constant has the value 32,768; on Solaris, it is 32; and on Tru64, it is 256.

If the message queue is already full (i.e., the mq\_maxmsg limit for the queue has been reached), then a further mq\_send() either blocks until space becomes available in the queue, or, if the O\_NONBLOCK flag is in effect, fails immediately with the error EAGAIN.

The program in [Listing 52-4](#page-17-0) provides a command-line interface to the mq\_send() function. We demonstrate the use of this program in the next section.

```
––––––––––––––––––––––––––––––––––––––––––––––––––––––––– pmsg/pmsg_send.c
#include <mqueue.h>
#include <fcntl.h> /* For definition of O_NONBLOCK */
#include "tlpi_hdr.h"
static void
usageError(const char *progName)
{
 fprintf(stderr, "Usage: %s [-n] name msg [prio]\n", progName);
 fprintf(stderr, " -n Use O_NONBLOCK flag\n");
 exit(EXIT_FAILURE);
}
int
main(int argc, char *argv[])
{
 int flags, opt;
 mqd_t mqd;
 unsigned int prio;
 flags = O_WRONLY;
 while ((opt = getopt(argc, argv, "n")) != -1) {
 switch (opt) {
 case 'n': flags |= O_NONBLOCK; break;
 default: usageError(argv[0]);
 }
 }
 if (optind + 1 >= argc)
 usageError(argv[0]);
 mqd = mq_open(argv[optind], flags);
 if (mqd == (mqd_t) -1)
 errExit("mq_open");
 prio = (argc > optind + 2) ? atoi(argv[optind + 2]) : 0;
 if (mq_send(mqd, argv[optind + 1], strlen(argv[optind + 1]), prio) == -1)
 errExit("mq_send");
 exit(EXIT_SUCCESS);
}
––––––––––––––––––––––––––––––––––––––––––––––––––––––––– pmsg/pmsg_send.c
```

## **52.5.2 Receiving Messages**

The mq\_receive() function removes the oldest message with the highest priority from the message queue referred to by mqdes and returns that message in the buffer pointed to by msg\_ptr.

```
#include <mqueue.h>
ssize_t mq_receive(mqd_t mqdes, char *msg_ptr, size_t msg_len,
 unsigned int *msg_prio);
       Returns number of bytes in received message on success, or –1 on error
```

The msg\_len argument is used by the caller to specify the number of bytes of space available in the buffer pointed to by msg\_ptr.

Regardless of the actual size of the message, msg\_len (and thus the size of the buffer pointed to by msg\_ptr) must be greater than or equal to the mq\_msgsize attribute of the queue; otherwise, mq\_receive() fails with the error EMSGSIZE. If we don't know the value of the mq\_msgsize attribute of a queue, we can obtain it using mq\_getattr(). (In an application consisting of cooperating processes, the use of mq\_getattr() can usually be dispensed with, because the application can typically decide on a queue's mq\_msgsize setting in advance.)

If msg\_prio is not NULL, then the priority of the received message is copied into the location pointed to by msg\_prio.

If the message queue is currently empty, then mq\_receive() either blocks until a message becomes available, or, if the O\_NONBLOCK flag is in effect, fails immediately with the error EAGAIN. (There is no equivalent of the pipe behavior where a reader sees end-of-file if there are no writers.)

The program in Listing 52-5 provides a command-line interface to the mq\_receive() function. The command format for this program is shown in the usageError() function.

The following shell session demonstrates the use of the programs in [Listing 52-4](#page-17-0) and Listing 52-5. We begin by creating a message queue and sending a few messages with different priorities:

```
$ ./pmsg_create -cx /mq
$ ./pmsg_send /mq msg-a 5
$ ./pmsg_send /mq msg-b 0
$ ./pmsg_send /mq msg-c 10
```

We then execute a series of commands to retrieve messages from the queue:

```
$ ./pmsg_receive /mq
Read 5 bytes; priority = 10
msg-c
$ ./pmsg_receive /mq
Read 5 bytes; priority = 5
msg-a
$ ./pmsg_receive /mq
Read 5 bytes; priority = 0
msg-b
```

As we can see from the above output, the messages were retrieved in order of priority.

At this point, the queue is now empty. When we perform another blocking receive, the operation blocks:

```
$ ./pmsg_receive /mq
Blocks; we type Control-C to terminate the program
```

On the other hand, if we perform a nonblocking receive, the call returns immediately with a failure status:

\$ **./pmsg\_receive -n /mq** ERROR [EAGAIN/EWOULDBLOCK Resource temporarily unavailable] mq\_receive

**Listing 52-5:** Reading a message from a POSIX message queue

```
–––––––––––––––––––––––––––––––––––––––––––––––––––––– pmsg/pmsg_receive.c
#include <mqueue.h>
#include <fcntl.h> /* For definition of O_NONBLOCK */
#include "tlpi_hdr.h"
static void
usageError(const char *progName)
{
 fprintf(stderr, "Usage: %s [-n] name\n", progName);
 fprintf(stderr, " -n Use O_NONBLOCK flag\n");
 exit(EXIT_FAILURE);
}
int
main(int argc, char *argv[])
{
 int flags, opt;
 mqd_t mqd;
 unsigned int prio;
 void *buffer;
 struct mq_attr attr;
 ssize_t numRead;
 flags = O_RDONLY;
 while ((opt = getopt(argc, argv, "n")) != -1) {
 switch (opt) {
 case 'n': flags |= O_NONBLOCK; break;
 default: usageError(argv[0]);
 }
 }
 if (optind >= argc)
 usageError(argv[0]);
 mqd = mq_open(argv[optind], flags);
 if (mqd == (mqd_t) -1)
 errExit("mq_open");
 if (mq_getattr(mqd, &attr) == -1)
 errExit("mq_getattr");
 buffer = malloc(attr.mq_msgsize);
 if (buffer == NULL)
 errExit("malloc");
```

```
 numRead = mq_receive(mqd, buffer, attr.mq_msgsize, &prio);
 if (numRead == -1)
 errExit("mq_receive");
 printf("Read %ld bytes; priority = %u\n", (long) numRead, prio);
 if (write(STDOUT_FILENO, buffer, numRead) == -1)
 errExit("write");
 write(STDOUT_FILENO, "\n", 1);
 exit(EXIT_SUCCESS);
}
–––––––––––––––––––––––––––––––––––––––––––––––––––––– pmsg/pmsg_receive.c
```

## **52.5.3 Sending and Receiving Messages with a Timeout**

The mq\_timedsend() and mq\_timedreceive() functions are exactly like mq\_send() and mq\_receive(), except that if the operation can't be performed immediately, and the O\_NONBLOCK flag is not in effect for the message queue description, then the abs\_timeout argument specifies a limit on the time for which the call will block.

```
#define _XOPEN_SOURCE 600
#include <mqueue.h>
#include <time.h>
int mq_timedsend(mqd_t mqdes, const char *msg_ptr, size_t msg_len,
 unsigned int msg_prio, const struct timespec *abs_timeout);
                                         Returns 0 on success, or –1 on error
ssize_t mq_timedreceive(mqd_t mqdes, char *msg_ptr, size_t msg_len,
 unsigned int *msg_prio, const struct timespec *abs_timeout);
       Returns number of bytes in received message on success, or –1 on error
```

The abs\_timeout argument is a timespec structure (Section 23.4.2) that specifies the timeout as an absolute value in seconds and nanoseconds since the Epoch. To perform a relative timeout, we can fetch the current value of the CLOCK\_REALTIME clock using clock\_gettime() and add the required amount to that value to produce a suitably initialized timespec structure.

If a call to mq\_timedsend() or mq\_timedreceive() times out without being able to complete its operation, then the call fails with the error ETIMEDOUT.

On Linux, specifying abs\_timeout as NULL means an infinite timeout. However, this behavior is not specified in SUSv3, and portable applications can't rely on it.

The mq\_timedsend() and mq\_timedreceive() functions originally derive from POSIX.1d (1999) and are not available on all UNIX implementations.

## <span id="page-20-0"></span>**52.6 Message Notification**

A feature that distinguishes POSIX message queues from their System V counterparts is the ability to receive asynchronous notification of the availability of a message on a previously empty queue (i.e., when the queue transitions from being empty to nonempty). This feature means that instead of making a blocking mq\_receive() call or marking the message queue descriptor nonblocking and performing periodic mq\_receive() calls ("polls") on the queue, a process can request a notification of message arrival and then perform other tasks until it is notified. A process can choose to be notified either via a signal or via invocation of a function in a separate thread.

> The notification feature of POSIX message queues is similar to the notification facility that we described for POSIX timers in Section 23.6. (Both of these APIs originated in POSIX.1b.)

The mq\_notify() function registers the calling process to receive a notification when a message arrives on the empty queue referred to by the descriptor mqdes.

```
#include <mqueue.h>
int mq_notify(mqd_t mqdes, const struct sigevent *notification);
                                             Returns 0 on success, or –1 on error
```

The notification argument specifies the mechanism by which the process is to be notified. Before going into the details of the notification argument, we note a few points about message notification:

-  At any time, only one process ("the registered process") can be registered to receive a notification from a particular message queue. If there is already a process registered for a message queue, further attempts to register for that queue fail (mq\_notify() fails with the error EBUSY).
-  The registered process is notified only when a new message arrives on a queue that was previously empty. If a queue already contains messages at the time of the registration, a notification will occur only after the queue is emptied and a new message arrives.
-  After one notification is sent to the registered process, the registration is removed, and any process can then register itself for notification. In other words, as long as a process wishes to keep receiving notifications, it must reregister itself after each notification by once again calling mq\_notify().
-  The registered process is notified only if some other process is not currently blocked in a call to mq\_receive() for the queue. If some other process is blocked in mq\_receive(), that process will read the message, and the registered process will remain registered.
-  A process can explicitly deregister itself as the target for message notification by calling mq\_notify() with a notification argument of NULL.

We already showed the sigevent structure that is used to type the notification argument in Section 23.6.1. Here, we present the structure in simplified form, showing just those fields relevant to the discussion of mq\_notify():

```
union sigval {
 int sival_int; /* Integer value for accompanying data */
 void *sival_ptr; /* Pointer value for accompanying data */
};
```

```
struct sigevent {
 int sigev_notify; /* Notification method */
 int sigev_signo; /* Notification signal for SIGEV_SIGNAL */
 union sigval sigev_value; /* Value passed to signal handler or
 thread function */
 void (*sigev_notify_function) (union sigval);
 /* Thread notification function */
 void *sigev_notify_attributes; /* Really 'pthread_attr_t' */
};
```

The sigev\_notify field of this structure is set to one of the following values:

#### SIGEV\_NONE

Register this process for notification, but when a message arrives on the previously empty queue, don't actually notify the process. As usual, the registration is removed when a new messages arrives on an empty queue.

#### SIGEV\_SIGNAL

Notify the process by generating the signal specified in the sigev\_signo field. If sigev\_signo is a realtime signal, then the sigev\_value field specifies data to accompany the signal (Section 22.8.1). This data can be retrieved via the si\_value field of the siginfo\_t structure that is passed to the signal handler or returned by a call to sigwaitinfo() or sigtimedwait(). The following fields in the siginfo\_t structure are also filled in: si\_code, with the value SI\_MESGQ; si\_signo, with the signal number; si\_pid, with the process ID of the process that sent the message; and si\_uid, with the real user ID of the process that sent the message. (The si\_pid and si\_uid fields are not set on most other implementations.)

#### SIGEV\_THREAD

Notify the process by calling the function specified in sigev\_notify\_function as if it were the start function in a new thread. The sigev\_notify\_attributes field can be specified as NULL or as a pointer to a pthread\_attr\_t structure that defines attributes for the thread (Section 29.8). The union sigval value specified in sigev\_value is passed as the argument of this function.

## **52.6.1 Receiving Notification via a Signal**

[Listing 52-6](#page-23-0) provides an example of message notification using signals. This program performs the following steps:

- 1. Open the message queue named on the command line in nonblocking mode q, determine the mq\_msgsize attribute for the queue w, and allocate a buffer of that size for receiving messages e.
- 2. Block the notification signal (SIGUSR1) and establish a handler for it r.
- 3. Make an initial call to mq\_notify() to register the process to receive message notification t.
- 4. Execute an infinite loop that performs the following steps:
  - a) Call sigsuspend(), which unblocks the notification signal and waits until the signal is caught y. Return from this system call indicates that a message

- notification has occurred. At this point, the process will have been deregistered for message notification.
- b) Call mq\_notify() to reregister this process to receive message notification u.
- c) Execute a while loop that drains the queue by reading as many messages as possible i.

<span id="page-23-0"></span>**Listing 52-6:** Receiving message notification via a signal

```
–––––––––––––––––––––––––––––––––––––––––––––––––––––– pmsg/mq_notify_sig.c
  #include <signal.h>
  #include <mqueue.h>
  #include <fcntl.h> /* For definition of O_NONBLOCK */
  #include "tlpi_hdr.h"
  #define NOTIFY_SIG SIGUSR1
  static void
  handler(int sig)
  {
   /* Just interrupt sigsuspend() */
  }
  int
  main(int argc, char *argv[])
  {
   struct sigevent sev;
   mqd_t mqd;
   struct mq_attr attr;
   void *buffer;
   ssize_t numRead;
   sigset_t blockMask, emptyMask;
   struct sigaction sa;
   if (argc != 2 || strcmp(argv[1], "--help") == 0)
   usageErr("%s mq-name\n", argv[0]);
q mqd = mq_open(argv[1], O_RDONLY | O_NONBLOCK);
   if (mqd == (mqd_t) -1)
   errExit("mq_open");
w if (mq_getattr(mqd, &attr) == -1)
   errExit("mq_getattr");
e buffer = malloc(attr.mq_msgsize);
   if (buffer == NULL)
   errExit("malloc");
r sigemptyset(&blockMask);
   sigaddset(&blockMask, NOTIFY_SIG);
   if (sigprocmask(SIG_BLOCK, &blockMask, NULL) == -1)
   errExit("sigprocmask");
```

```
 sigemptyset(&sa.sa_mask);
   sa.sa_flags = 0;
   sa.sa_handler = handler;
   if (sigaction(NOTIFY_SIG, &sa, NULL) == -1)
   errExit("sigaction");
t sev.sigev_notify = SIGEV_SIGNAL;
   sev.sigev_signo = NOTIFY_SIG;
   if (mq_notify(mqd, &sev) == -1)
   errExit("mq_notify");
   sigemptyset(&emptyMask);
   for (;;) {
y sigsuspend(&emptyMask); /* Wait for notification signal */
u if (mq_notify(mqd, &sev) == -1)
   errExit("mq_notify");
i while ((numRead = mq_receive(mqd, buffer, attr.mq_msgsize, NULL)) >= 0)
   printf("Read %ld bytes\n", (long) numRead);
   if (errno != EAGAIN) /* Unexpected error */
   errExit("mq_receive");
   }
  }
  –––––––––––––––––––––––––––––––––––––––––––––––––––––– pmsg/mq_notify_sig.c
```

Various aspects of the program in [Listing 52-6](#page-23-0) merit further comment:

-  We block the notification signal and use sigsuspend() to wait for it, rather than pause(), to prevent the possibility of missing a signal that is delivered while the program is executing elsewhere (i.e., is not blocked waiting for signals) in the for loop. If this occurred, and we were using pause() to wait for signals, then the next call to pause() would block, even though a signal had already been delivered.
-  We open the queue in nonblocking mode, and, whenever a notification occurs, we use a while loop to read all messages from the queue. Emptying the queue in this way ensures that a further notification is generated when a new message arrives. Employing nonblocking mode means that the while loop will terminate (mq\_receive() will fail with the error EAGAIN) when we have emptied the queue. (This approach is analogous to the use of nonblocking I/O with edge-triggered I/O notification, which we describe in Section 63.1.1, and is employed for similar reasons.)
-  Within the for loop, it is important that we reregister for message notification before reading all messages from the queue. If we reversed these steps, the following sequence could occur: all messages are read from the queue, and the while loop terminates; another message is placed on the queue; mq\_notify() is called to reregister for message notification. At this point, no further notification signal would be generated, because the queue is already nonempty. Consequently, the program would remain permanently blocked in its next call to sigsuspend().

## **52.6.2 Receiving Notification via a Thread**

[Listing 52-7](#page-25-0) provides an example of message notification using threads. This program shares a number of design features with the program in [Listing 52-6](#page-23-0):

-  When message notification occurs, the program reenables notification before draining the queue w.
-  Nonblocking mode is employed so that, after receiving a notification, we can completely drain the queue without blocking t.

<span id="page-25-0"></span>**Listing 52-7:** Receiving message notification via a thread

```
––––––––––––––––––––––––––––––––––––––––––––––––––– pmsg/mq_notify_thread.c
  #include <pthread.h>
  #include <mqueue.h>
  #include <fcntl.h> /* For definition of O_NONBLOCK */
  #include "tlpi_hdr.h"
  static void notifySetup(mqd_t *mqdp);
  static void /* Thread notification function */
q threadFunc(union sigval sv)
  {
   ssize_t numRead;
   mqd_t *mqdp;
   void *buffer;
   struct mq_attr attr;
   mqdp = sv.sival_ptr;
   if (mq_getattr(*mqdp, &attr) == -1)
   errExit("mq_getattr");
   buffer = malloc(attr.mq_msgsize);
   if (buffer == NULL)
   errExit("malloc");
w notifySetup(mqdp);
   while ((numRead = mq_receive(*mqdp, buffer, attr.mq_msgsize, NULL)) >= 0)
   printf("Read %ld bytes\n", (long) numRead);
   if (errno != EAGAIN) /* Unexpected error */
   errExit("mq_receive");
   free(buffer);
   pthread_exit(NULL);
  }
  static void
  notifySetup(mqd_t *mqdp)
  {
   struct sigevent sev;
```

```
e sev.sigev_notify = SIGEV_THREAD; /* Notify via thread */
   sev.sigev_notify_function = threadFunc;
   sev.sigev_notify_attributes = NULL;
   /* Could be pointer to pthread_attr_t structure */
r sev.sigev_value.sival_ptr = mqdp; /* Argument to threadFunc() */
   if (mq_notify(*mqdp, &sev) == -1)
   errExit("mq_notify");
  }
  int
  main(int argc, char *argv[])
  {
   mqd_t mqd;
   if (argc != 2 || strcmp(argv[1], "--help") == 0)
   usageErr("%s mq-name\n", argv[0]);
t mqd = mq_open(argv[1], O_RDONLY | O_NONBLOCK);
   if (mqd == (mqd_t) -1)
   errExit("mq_open");
y notifySetup(&mqd);
   pause(); /* Wait for notifications via thread function */
  }
  ––––––––––––––––––––––––––––––––––––––––––––––––––– pmsg/mq_notify_thread.c
```

Note the following further points regarding the design of the program in [Listing 52-7:](#page-25-0)

-  The program requests notification via a thread, by specifying SIGEV\_THREAD in the sigev\_notify field of the sigevent structure passed to mq\_notify(). The thread's start function, threadFunc(), is specified in the sigev\_notify\_function field e.
-  After enabling message notification, the main program pauses indefinitely y; timer notifications are delivered by invocations of threadFunc() in a separate thread q.
-  We could have made the message queue descriptor, mqd, visible in threadFunc() by making it a global variable. However, we adopted a different approach to illustrate the alternative: we place the address of the message queue descriptor in the sigev\_value.sival\_ptr field that is passed to mq\_notify() r. When threadFunc() is later invoked, this address is passed as its argument.

We must assign a pointer to the message queue descriptor to sigev\_value.sival\_ptr, rather than (some cast version of) the descriptor itself because, other than the stipulation that it is not an array type, SUSv3 makes no guarantee about the nature or size of the type used to represent the mqd\_t data type.

## <span id="page-26-0"></span>**52.7 Linux-Specific Features**

The Linux implementation of POSIX message queues provides a number of features that are unstandardized but nevertheless useful.

#### **Displaying and deleting message queue objects via the command line**

In Chapter [51](#page-0-0), we mentioned that POSIX IPC objects are implemented as files in virtual file systems, and that these files can be listed and removed with ls and rm. In order to do this with POSIX message queues, we must mount the message queue file system using a command of the following form:

```
# mount -t mqueue source target
```

The source can be any name at all (specifying the string none is typical). Its only significance is that it appears in /proc/mounts and is displayed by the mount and df commands. The target is the mount point for the message queue file system.

The following shell session shows how to mount the message queue file system and display its contents. We begin by creating a mount point for the file system and mounting it:

```
$ su Privilege is required for mount
Password:
# mkdir /dev/mqueue
# mount -t mqueue none /dev/mqueue
$ exit Terminate root shell session
```

Next, we display the record in /proc/mounts for the new mount, and then display the permissions for the mount directory:

```
$ cat /proc/mounts | grep mqueue
none /dev/mqueue mqueue rw 0 0
$ ls -ld /dev/mqueue
drwxrwxrwt 2 root root 40 Jul 26 12:09 /dev/mqueue
```

One point to note from the output of the ls command is that the message queue file system is automatically mounted with the sticky bit set for the mount directory. (We see this from the fact that there is a t in the other-execute permission field displayed by ls.) This means that an unprivileged process can unlink only message queues that it owns.

Next, we create a message queue, use ls to show that it is visible in the file system, and then delete the message queue:

```
$ ./pmsg_create -c /newq
$ ls /dev/mqueue
newq
$ rm /dev/mqueue/newq
```

#### **Obtaining information about a message queue**

We can display the contents of the files in the message queue file system. Each of these virtual files contains information about the associated message queue:

```
$ ./pmsg_create -c /mq Create a queue
$ ./pmsg_send /mq abcdefg Write 7 bytes to the queue
$ cat /dev/mqueue/mq
QSIZE:7 NOTIFY:0 SIGNO:0 NOTIFY_PID:0
```

The QSIZE field is a count of the total number of bytes of data in the queue. The remaining fields relate to message notification. If NOTIFY\_PID is nonzero, then the process with the specified process ID has registered for message notification from this queue, and the remaining fields provide information about the kind of notification:

-  NOTIFY is a value corresponding to one of the sigev\_notify constants: 0 for SIGEV\_SIGNAL, 1 for SIGEV\_NONE, or 2 for SIGEV\_THREAD.
-  If the notification method is SIGEV\_SIGNAL, the SIGNO field indicates which signal is delivered for message notification.

The following shell session illustrates the information that appears in these fields:

```
$ ./mq_notify_sig /mq & Notify using SIGUSR1 (signal 10 on x86)
[1] 18158
$ cat /dev/mqueue/mq
QSIZE:7 NOTIFY:0 SIGNO:10 NOTIFY_PID:18158
$ kill %1
[1] Terminated ./mq_notify_sig /mq
$ ./mq_notify_thread /mq & Notify using a thread
[2] 18160
$ cat /dev/mqueue/mq
QSIZE:7 NOTIFY:2 SIGNO:0 NOTIFY_PID:18160
```

#### **Using message queues with alternative I/O models**

In the Linux implementation, a message queue descriptor is really a file descriptor. We can monitor this file descriptor using I/O multiplexing system calls (select() and poll()) or the epoll API. (See Chapter 63 for further details of these APIs.) This allows us to avoid the difficulty that we encounter with System V messages queues when trying to wait for input on both a message queue and a file descriptor (refer to Section 46.9). However, this feature is nonstandard; SUSv3 doesn't require that message queue descriptors are implemented as file descriptors.

## <span id="page-28-0"></span>**52.8 Message Queue Limits**

SUSv3 defines two limits for POSIX message queues:

MQ\_PRIO\_MAX

We described this limit, which defines the maximum priority for a message, in Section [52.5.1.](#page-16-0)

MQ\_OPEN\_MAX

An implementation can define this limit to indicate the maximum number of message queues that a process can hold open. SUSv3 requires this limit to be at least \_POSIX\_MQ\_OPEN\_MAX (8). Linux doesn't define this limit. Instead, because Linux implements message queue descriptors as file descriptors (Section [52.7](#page-26-0)), the applicable limits are those that apply to file descriptors. (In other words, on Linux, the per-process and system-wide limits on the number of file descriptors actually apply to the sum of file descriptors and message queue descriptors.) For further details on the applicable limits, see the discussion of the RLIMIT\_NOFILE resource limit in Section 36.3.

As well as the above SUSv3-specified limits, Linux provides a number of /proc files for viewing and (with privilege) changing limits that control the use of POSIX message queues. The following three files reside in the directory /proc/sys/fs/mqueue:

msg\_max

This limit specifies a ceiling for the mq\_maxmsg attribute of new message queues (i.e., a ceiling for attr.mq\_maxmsg when creating a queue with mq\_open()). The default value for this limit is 10. The minimum value is 1 (10 in kernels before Linux 2.6.28). The maximum value is defined by the kernel constant HARD\_MSGMAX. The value for this constant is calculated as (131,072 / sizeof(void \*)), which evaluates to 32,768 on Linux/x86-32. When a privileged process (CAP\_SYS\_RESOURCE) calls mq\_open(), the msg\_max limit is ignored, but HARD\_MSGMAX still acts as a ceiling for attr.mq\_maxmsg.

msgsize\_max

This limit specifies a ceiling for the mq\_msgsize attribute of new message queues created by unprivileged processes (i.e., a ceiling for attr.mq\_msgsize when creating a queue with mq\_open()). The default value for this limit is 8192. The minimum value is 128 (8192 in kernels before Linux 2.6.28). The maximum value is 1,048,576 (INT\_MAX in kernels before 2.6.28). This limit is ignored when a privileged process (CAP\_SYS\_RESOURCE) calls mq\_open().

queues\_max

This is a system-wide limit on the number of message queues that may be created. Once this limit is reached, only a privileged process (CAP\_SYS\_RESOURCE) can create new queues. The default value for this limit is 256. It can be changed to any value in the range 0 to INT\_MAX.

Linux also provides the RLIMIT\_MSGQUEUE resource limit, which can be used to place a ceiling on the amount of space that can be consumed by all of the message queues belonging to the real user ID of the calling process. See Section 36.3 for details.

## **52.9 Comparison of POSIX and System V Message Queues**

Section [51.2](#page-4-0) listed various advantages of the POSIX IPC interface over the System V IPC interface: the POSIX IPC interface is simpler and more consistent with the traditional UNIX file model, and POSIX IPC objects are reference counted, which simplifies the task of determining when to delete an object. These general advantages also apply to POSIX message queues.

POSIX message queues also have the following specific advantages over System V message queues:

-  The message notification feature allows a (single) process to be asynchronously notified via a signal or the instantiation of a thread when a message arrives on a previously empty queue.
-  On Linux (but not other UNIX implementations), POSIX message queues can be monitored using poll(), select(), and epoll. System V message queues don't provide this feature.

However, POSIX message queues also have some disadvantages compared to System V message queues:

-  POSIX message queues are less portable. This problem applies even across Linux systems, since message queue support is available only since kernel 2.6.6.
-  The facility to select System V messages by type provides slightly greater flexibility than the strict priority ordering of POSIX messages.

There is a wide variation in the manner in which POSIX message queues are implemented on UNIX systems. Some systems provide implementations in user space, and on at least one such implementation (Solaris 10), the mq\_open() manual page explicitly notes that the implementation can't be considered secure. On Linux, one of the motives for selecting a kernel implementation of message queues was that it was not deemed possible to provide a secure userspace implementation.

## **52.10 Summary**

POSIX message queues allow processes to exchange data in the form of messages. Each message has an associated integer priority, and messages are queued (and thus received) in order of priority.

POSIX message queues have some advantages over System V message queues, notably that they are reference counted and that a process can be asynchronously notified of the arrival of a message on an empty queue. However, POSIX message queues are less portable than System V message queues.

#### **Further information**

[Stevens, 1999] provides an alternative presentation of POSIX message queues and shows a user-space implementation using memory-mapped files. POSIX message queues are also described in some detail in [Gallmeister, 1995].

## **52.11 Exercises**

- **52-1.** Modify the program in Listing 52-5 (pmsg\_receive.c) to accept a timeout (a relative number of seconds) on the command line, and use mq\_timedreceive() instead of mq\_receive().
- **52-2.** Recode the sequence-number client-server application of Section 44.8 to use POSIX message queues.
- **52-3.** Rewrite the file-server application of Section 46.8 to use POSIX message queues instead of System V message queues.
- **52-4.** Write a simple chat program (similar to talk(1), but without the curses interface) using POSIX messages queues.
- **52-5.** Modify the program in [Listing 52-6](#page-23-0) (mq\_notify\_sig.c) to demonstrate that message notification established by mq\_notify() occurs just once. This can be done by removing the mq\_notify() call inside the for loop.

- **52-6.** Replace the use of a signal handler in [Listing 52-6](#page-23-0) (mq\_notify\_sig.c) with the use of sigwaitinfo(). Upon return from sigwaitinfo(), display the values in the returned siginfo\_t structure. How could the program obtain the message queue descriptor in the siginfo\_t structure returned by sigwaitinfo()?
- **52-7.** In [Listing 52-7,](#page-25-0) could buffer be made a global variable and its memory allocated just once (in the main program)? Explain your answer.

# <span id="page-32-0"></span>**POSIX SEMAPHORES**

This chapter describes POSIX semaphores, which allow processes and threads to synchronize access to shared resources. In Chapter 47, we described System V semaphores, and we'll assume that the reader is familiar with the general semaphore concepts and rationale for using semaphores that were presented at the start of that chapter. During the course of this chapter, we'll make comparisons between POSIX semaphores and System V semaphores to clarify the ways in which these two semaphore APIs are the same and the ways in which they differ.

## **53.1 Overview**

SUSv3 specifies two types of POSIX semaphores:

-  Named semaphores: This type of semaphore has a name. By calling sem\_open() with the same name, unrelated processes can access the same semaphore.
-  Unnamed semaphores: This type of semaphore doesn't have a name; instead, it resides at an agreed-upon location in memory. Unnamed semaphores can be shared between processes or between a group of threads. When shared between processes, the semaphore must reside in a region of (System V, POSIX, or mmap()) shared memory. When shared between threads, the semaphore may reside in an area of memory shared by the threads (e.g., on the heap or in a global variable).

POSIX semaphores operate in a manner similar to System V semaphores; that is, a POSIX semaphore is an integer whose value is not permitted to fall below 0. If a process attempts to decrease the value of a semaphore below 0, then, depending on the function used, the call either blocks or fails with an error indicating that the operation was not currently possible.

Some systems don't provide a full implementation of POSIX semaphores. A typical restriction is that only unnamed thread-shared semaphores are supported. That was the situation on Linux 2.4; with Linux 2.6 and a glibc that provides NPTL, a full implementation of POSIX semaphores is available.

> On Linux 2.6 with NPTL, semaphore operations (increment and decrement) are implemented using the futex(2) system call.

## **53.2 Named Semaphores**

To work with a named semaphore, we employ the following functions:

-  The sem\_open() function opens or creates a semaphore, initializes the semaphore if it is created by the call, and returns a handle for use in later calls.
-  The sem\_post(sem) and sem\_wait(sem) functions respectively increment and decrement a semaphore's value.
-  The sem\_getvalue() function retrieves a semaphore's current value.
-  The sem\_close() function removes the calling process's association with a semaphore that it previously opened.
-  The sem\_unlink() function removes a semaphore name and marks the semaphore for deletion when all processes have closed it.

SUSv3 doesn't specify how named semaphores are to be implemented. Some UNIX implementations create them as files in a special location in the standard file system. On Linux, they are created as small POSIX shared memory objects with names of the form sem.name, in a dedicated tmpfs file system (Section 14.10) mounted under the directory /dev/shm. This file system has kernel persistence—the semaphore objects that it contains will persist, even if no process currently has them open, but they will be lost if the system is shut down.

Named semaphores are supported on Linux since kernel 2.6.

## **53.2.1 Opening a Named Semaphore**

The sem\_open() function creates and opens a new named semaphore or opens an existing semaphore.

```
#include <fcntl.h> /* Defines O_* constants */
#include <sys/stat.h> /* Defines mode constants */
#include <semaphore.h>
sem_t *sem_open(const char *name, int oflag, ...
 /* mode_t mode, unsigned int value */ );
              Returns pointer to semaphore on success, or SEM_FAILED on error
```

The name argument identifies the semaphore. It is specified according to the rules given in Section [51.1.](#page-1-0)

The oflag argument is a bit mask that determines whether we are opening an existing semaphore or creating and opening a new semaphore. If oflag is 0, we are accessing an existing semaphore. If O\_CREAT is specified in oflag, then a new semaphore is created if one with the given name doesn't already exist. If oflag specifies both O\_CREAT and O\_EXCL, and a semaphore with the given name already exists, then sem\_open() fails.

If sem\_open() is being used to open an existing semaphore, the call requires only two arguments. However, if O\_CREAT is specified in flags, then two further arguments are required: mode and value. (If the semaphore specified by name already exists, then these two arguments are ignored.) These arguments are as follows:

-  The mode argument is a bit mask that specifies the permissions to be placed on the new semaphore. The bit values are the same as for files (Table 15-4, on page 295), and, as with open(), the value in mode is masked against the process umask (Section 15.4.6). SUSv3 doesn't specify any access mode flags (O\_RDONLY, O\_WRONLY, and O\_RDWR) for oflag. Many implementations, including Linux, assume an access mode of O\_RDWR when opening a semaphore, since most applications using semaphores must employ both sem\_post() and sem\_wait(), which involve reading and modifying a semaphore's value. This means that we should ensure that both read and write permissions are granted to each category of user owner, group, and other—that needs to access the semaphore.
-  The value argument is an unsigned integer that specifies the initial value to be assigned to the new semaphore. The creation and initialization of the semaphore are performed atomically. This avoids the complexities required for the initialization of System V semaphores (Section 47.5).

Regardless of whether we are creating a new semaphore or opening an existing semaphore, sem\_open() returns a pointer to a sem\_t value, and we employ this pointer in subsequent calls to functions that operate on the semaphore. On error, sem\_open() returns the value SEM\_FAILED. (On most implementations, SEM\_FAILED is defined as either ((sem\_t \*) 0) or ((sem\_t \*) –1); Linux defines it as the former.)

SUSv3 states that the results are undefined if we attempt to perform operations (sem\_post(), sem\_wait(), and so on) on a copy of the sem\_t variable pointed to by the return value of sem\_open(). In other words, the following use of sem2 is not permissible:

```
sem_t *sp, sem2
sp = sem_open(...);
sem2 = *sp;
sem_wait(&sem2);
```

When a child is created via fork(), it inherits references to all of the named semaphores that are open in its parent. After the fork(), the parent and child can use these semaphores to synchronize their actions.

#### **Example program**

The program in [Listing 53-1](#page-35-0) provides a simple command-line interface to the sem\_open() function. The command format for this program is shown in the usageError() function.

The following shell session log demonstrates the use of this program. We first use the umask command to deny all permissions to users in the class other. We then exclusively create a semaphore and examine the contents of the Linux-specific virtual directory that contains named semaphores.

```
$ umask 007
$ ./psem_create -cx /demo 666 666 means read+write for all users
$ ls -l /dev/shm/sem.*
-rw-rw---- 1 mtk users 16 Jul 6 12:09 /dev/shm/sem.demo
```

The output of the ls command shows that the process umask overrode the specified permissions of read plus write for the user class other.

If we try once more to exclusively create a semaphore with the same name, the operation fails, because the name already exists.

```
$ ./psem_create -cx /demo 666
ERROR [EEXIST File exists] sem_open Failed because of O_EXCL
```

<span id="page-35-0"></span>**Listing 53-1:** Using sem\_open() to open or create a POSIX named semaphore

```
––––––––––––––––––––––––––––––––––––––––––––––––––––––– psem/psem_create.c
#include <semaphore.h>
#include <sys/stat.h>
#include <fcntl.h>
#include "tlpi_hdr.h"
static void
usageError(const char *progName)
{
 fprintf(stderr, "Usage: %s [-cx] name [octal-perms [value]]\n", progName);
 fprintf(stderr, " -c Create semaphore (O_CREAT)\n");
 fprintf(stderr, " -x Create exclusively (O_EXCL)\n");
 exit(EXIT_FAILURE);
}
int
main(int argc, char *argv[])
{
 int flags, opt;
 mode_t perms;
 unsigned int value;
 sem_t *sem;
 flags = 0;
 while ((opt = getopt(argc, argv, "cx")) != -1) {
 switch (opt) {
 case 'c': flags |= O_CREAT; break;
 case 'x': flags |= O_EXCL; break;
 default: usageError(argv[0]);
 }
 }
```

```
 if (optind >= argc)
 usageError(argv[0]);
 /* Default permissions are rw-------; default semaphore initialization
 value is 0 */
 perms = (argc <= optind + 1) ? (S_IRUSR | S_IWUSR) :
 getInt(argv[optind + 1], GN_BASE_8, "octal-perms");
 value = (argc <= optind + 2) ? 0 : getInt(argv[optind + 2], 0, "value");
 sem = sem_open(argv[optind], flags, perms, value);
 if (sem == SEM_FAILED)
 errExit("sem_open");
 exit(EXIT_SUCCESS);
}
––––––––––––––––––––––––––––––––––––––––––––––––––––––– psem/psem_create.c
```

## **53.2.2 Closing a Semaphore**

When a process opens a named semaphore, the system records the association between the process and the semaphore. The sem\_close() function terminates this association (i.e., closes the semaphore), releases any resources that the system has associated with the semaphore for this process, and decreases the count of processes referencing the semaphore.

```
#include <semaphore.h>
int sem_close(sem_t *sem);
                                             Returns 0 on success, or –1 on error
```

Open named semaphores are also automatically closed on process termination or if the process performs an exec().

Closing a semaphore does not delete it. For that purpose, we need to use sem\_unlink().

## **53.2.3 Removing a Named Semaphore**

The sem\_unlink() function removes the semaphore identified by name and marks the semaphore to be destroyed once all processes cease using it (this may mean immediately, if all processes that had the semaphore open have already closed it).

```
#include <semaphore.h>
int sem_unlink(const char *name);
                                            Returns 0 on success, or –1 on error
```

[Listing 53-2](#page-37-0) demonstrates the use of sem\_unlink().

```
––––––––––––––––––––––––––––––––––––––––––––––––––––––– psem/psem_unlink.c
#include <semaphore.h>
#include "tlpi_hdr.h"
int
main(int argc, char *argv[])
{
 if (argc != 2 || strcmp(argv[1], "--help") == 0)
 usageErr("%s sem-name\n", argv[0]);
 if (sem_unlink(argv[1]) == -1)
 errExit("sem_unlink");
   exit(EXIT_SUCCESS);
}
––––––––––––––––––––––––––––––––––––––––––––––––––––––– psem/psem_unlink.c
```

## **53.3 Semaphore Operations**

As with a System V semaphore, a POSIX semaphore is an integer that the system never allows to go below 0. However, POSIX semaphore operations differ from their System V counterparts in the following respects:

-  The functions for changing a semaphore's value—sem\_post() and sem\_wait() operate on just one semaphore at a time. By contrast, the System V semop() system call can operate on multiple semaphores in a set.
-  The sem\_post() and sem\_wait() functions increment and decrement a semaphore's value by exactly one. By contrast, semop() can add and subtract arbitrary values.
-  There is no equivalent of the wait-for-zero operation provided by System V semaphores (a semop() call where the sops.sem\_op field is specified as 0).

From this list, it may seem that POSIX semaphores are less powerful than System V semaphores. However, this is not the case—anything that we can do with System V semaphores can also be done with POSIX semaphores. In a few cases, a bit more programming effort may be required, but, for typical scenarios, using POSIX semaphores actually requires less programming effort. (The System V semaphore API is rather more complicated than is required for most applications.)

## **53.3.1 Waiting on a Semaphore**

The sem\_wait() function decrements (decreases by 1) the value of the semaphore referred to by sem.

```
#include <semaphore.h>
int sem_wait(sem_t *sem);
                                             Returns 0 on success, or –1 on error
```

If the semaphore currently has a value greater than 0, sem\_wait() returns immediately. If the value of the semaphore is currently 0, sem\_wait() blocks until the semaphore value rises above 0; at that time, the semaphore is then decremented and sem\_wait() returns.

If a blocked sem\_wait() call is interrupted by a signal handler, then it fails with the error EINTR, regardless of whether the SA\_RESTART flag was used when establishing the signal handler with sigaction(). (On some other UNIX implementations, SA\_RESTART does cause sem\_wait() to automatically restart.)

The program in [Listing 53-3](#page-38-0) provides a command-line interface to the sem\_wait() function. We demonstrate the use of this program shortly.

<span id="page-38-0"></span>**Listing 53-3:** Using sem\_wait() to decrement a POSIX semaphore

```
––––––––––––––––––––––––––––––––––––––––––––––––––––––––– psem/psem_wait.c
#include <semaphore.h>
#include "tlpi_hdr.h"
int
main(int argc, char *argv[])
{
 sem_t *sem;
 if (argc < 2 || strcmp(argv[1], "--help") == 0)
 usageErr("%s sem-name\n", argv[0]);
 sem = sem_open(argv[1], 0);
 if (sem == SEM_FAILED)
 errExit("sem_open");
 if (sem_wait(sem) == -1)
 errExit("sem_wait");
 printf("%ld sem_wait() succeeded\n", (long) getpid());
 exit(EXIT_SUCCESS);
}
––––––––––––––––––––––––––––––––––––––––––––––––––––––––– psem/psem_wait.c
```

The sem\_trywait() function is a nonblocking version of sem\_wait().

```
#include <semaphore.h>
int sem_trywait(sem_t *sem);
                                             Returns 0 on success, or –1 on error
```

If the decrement operation can't be performed immediately, sem\_trywait() fails with the error EAGAIN.

The sem\_timedwait() function is another variation on sem\_wait(). It allows the caller to specify a limit on the time for which the call will block.

```
#define _XOPEN_SOURCE 600
#include <semaphore.h>
int sem_timedwait(sem_t *sem, const struct timespec *abs_timeout);
                                             Returns 0 on success, or –1 on error
```

If a sem\_timedwait() call times out without being able to decrement the semaphore, then the call fails with the error ETIMEDOUT.

The abs\_timeout argument is a timespec structure (Section 23.4.2) that specifies the timeout as an absolute value in seconds and nanoseconds since the Epoch. If we want to perform a relative timeout, then we must fetch the current value of the CLOCK\_REALTIME clock using clock\_gettime() and add the required amount to that value to produce a timespec structure suitable for use with sem\_timedwait().

The sem\_timedwait() function was originally specified in POSIX.1d (1999) and is not available on all UNIX implementations.

## **53.3.2 Posting a Semaphore**

The sem\_post() function increments (increases by 1) the value of the semaphore referred to by sem.

```
#include <semaphore.h>
int sem_post(sem_t *sem);
                                             Returns 0 on success, or –1 on error
```

If the value of the semaphore was 0 before the sem\_post() call, and some other process (or thread) is blocked waiting to decrement the semaphore, then that process is awoken, and its sem\_wait() call proceeds to decrement the semaphore. If multiple processes (or threads) are blocked in sem\_wait(), then, if the processes are being scheduled under the default round-robin time-sharing policy, it is indeterminate which one will be awoken and allowed to decrement the semaphore. (Like their System V counterparts, POSIX semaphores are only a synchronization mechanism, not a queuing mechanism.)

> SUSv3 specifies that if processes or threads are being executed under a realtime scheduling policy, then the process or thread that will be awoken is the one with the highest priority that has been waiting the longest.

As with System V semaphores, incrementing a POSIX semaphore corresponds to releasing some shared resource for use by another process or thread.

The program in [Listing 53-4](#page-40-0) provides a command-line interface to the sem\_post() function. We demonstrate the use of this program shortly.

```
––––––––––––––––––––––––––––––––––––––––––––––––––––––––– psem/psem_post.c
#include <semaphore.h>
#include "tlpi_hdr.h"
int
main(int argc, char *argv[])
{
 sem_t *sem;
 if (argc != 2)
 usageErr("%s sem-name\n", argv[0]);
 sem = sem_open(argv[1], 0);
 if (sem == SEM_FAILED)
 errExit("sem_open");
 if (sem_post(sem) == -1)
 errExit("sem_post");
 exit(EXIT_SUCCESS);
}
––––––––––––––––––––––––––––––––––––––––––––––––––––––––– psem/psem_post.c
```

## **53.3.3 Retrieving the Current Value of a Semaphore**

The sem\_getvalue() function returns the current value of the semaphore referred to by sem in the int pointed to by sval.

```
#include <semaphore.h>
int sem_getvalue(sem_t *sem, int *sval);
                                             Returns 0 on success, or –1 on error
```

If one or more processes (or threads) are currently blocked waiting to decrement the semaphore's value, then the value returned in sval depends on the implementation. SUSv3 permits two possibilities: 0 or a negative number whose absolute value is the number of waiters blocked in sem\_wait(). Linux and several other implementations adopt the former behavior; a few other implementations adopt the latter behavior.

> Although returning a negative sval if there are blocked waiters can be useful, especially for debugging purposes, SUSv3 doesn't require this behavior because the techniques that some systems use to efficiently implement POSIX semaphores don't (in fact, can't) record counts of blocked waiters.

Note that by the time sem\_getvalue() returns, the value returned in sval may already be out of date. A program that depends on the information returned by sem\_getvalue() being unchanged by the time of a subsequent operation will be subject to time-ofcheck, time-of-use race conditions (Section 38.6).

The program in [Listing 53-5](#page-41-0) uses sem\_getvalue() to retrieve the value of the semaphore named in its command-line argument, and then displays that value on standard output.

<span id="page-41-0"></span>**Listing 53-5:** Using sem\_getvalue() to retrieve the value of a POSIX semaphore

```
–––––––––––––––––––––––––––––––––––––––––––––––––––––– psem/psem_getvalue.c
#include <semaphore.h>
#include "tlpi_hdr.h"
int
main(int argc, char *argv[])
{
 int value;
 sem_t *sem;
 if (argc != 2)
 usageErr("%s sem-name\n", argv[0]);
 sem = sem_open(argv[1], 0);
 if (sem == SEM_FAILED)
 errExit("sem_open");
 if (sem_getvalue(sem, &value) == -1)
 errExit("sem_getvalue");
 printf("%d\n", value);
 exit(EXIT_SUCCESS);
}
–––––––––––––––––––––––––––––––––––––––––––––––––––––– psem/psem_getvalue.c
```

#### **Example**

The following shell session log demonstrates the use of the programs we have shown so far in this chapter. We begin by creating a semaphore whose initial value is zero, and then start a program in the background that attempts to decrement the semaphore:

```
$ ./psem_create -c /demo 600 0
$ ./psem_wait /demo &
[1] 31208
```

The background command blocks, because the semaphore value is currently 0 and therefore can't be decreased.

We then retrieve the semaphore value:

```
$ ./psem_getvalue /demo
0
```

We see the value 0 above. On some other implementations, we might see the value –1, indicating that one process is waiting on the semaphore.

We then execute a command that increments the semaphore. This causes the blocked sem\_wait() in the background program to complete:

```
$ ./psem_post /demo
$ 31208 sem_wait() succeeded
```

(The last line of output above shows the shell prompt mixed with the output of the background job.)

We press Enter to see the next shell prompt, which also causes the shell to report on the terminated background job, and then perform further operations on the semaphore:

```
Press Enter
[1]- Done ./psem_wait /demo
$ ./psem_post /demo Increment semaphore
$ ./psem_getvalue /demo Retrieve semaphore value
1
$ ./psem_unlink /demo We're done with this semaphore
```

## **53.4 Unnamed Semaphores**

Unnamed semaphores (also known as memory-based semaphores) are variables of type sem\_t that are stored in memory allocated by the application. The semaphore is made available to the processes or threads that use it by placing it in an area of memory that they share.

Operations on unnamed semaphores use the same functions (sem\_wait(), sem\_post(), sem\_getvalue(), and so on) that are used to operate on named semaphores. In addition, two further functions are required:

-  The sem\_init() function initializes a semaphore and informs the system of whether the semaphore will be shared between processes or between the threads of a single process.
-  The sem\_destroy(sem) function destroys a semaphore.

These functions should not be used with named semaphores.

#### **Unnamed versus named semaphores**

Using an unnamed semaphore allows us to avoid the work of creating a name for a semaphore. This can be useful in the following cases:

-  A semaphore that is shared between threads doesn't need a name. Making an unnamed semaphore a shared (global or heap) variable automatically makes it accessible to all threads.
-  A semaphore that is being shared between related processes doesn't need a name. If a parent process allocates an unnamed semaphore in a region of shared memory (e.g., a shared anonymous mapping), then a child automatically inherits the mapping and thus the semaphore as part of the operation of fork().

 If we are building a dynamic data structure (e.g., a binary tree), each of whose items requires an associated semaphore, then the simplest approach is to allocate an unnamed semaphore within each item. Opening a named semaphore for each item would require us to design a convention for generating a (unique) semaphore name for each item and to manage those names (e.g., unlinking them when they are no longer required).

## **53.4.1 Initializing an Unnamed Semaphore**

The sem\_init() function initializes the unnamed semaphore pointed to by sem to the value specified by value.

```
#include <semaphore.h>
int sem_init(sem_t *sem, int pshared, unsigned int value);
                                            Returns 0 on success, or –1 on error
```

The pshared argument indicates whether the semaphore is to be shared between threads or between processes.

-  If pshared is 0, then the semaphore is to be shared between the threads of the calling process. In this case, sem is typically specified as the address of either a global variable or a variable allocated on the heap. A thread-shared semaphore has process persistence; it is destroyed when the process terminates.
-  If pshared is nonzero, then the semaphore is to be shared between processes. In this case, sem must be the address of a location in a region of shared memory (a POSIX shared memory object, a shared mapping created using mmap(), or a System V shared memory segment). The semaphore persists as long as the shared memory in which it resides. (The shared memory regions created by most of these techniques have kernel persistence. The exception is shared anonymous mappings, which persist only as long as at least one process maintains the mapping.) Since a child produced via fork() inherits its parent's memory mappings, process-shared semaphores are inherited by the child of a fork(), and the parent and child can use these semaphores to synchronize their actions.

The pshared argument is necessary for the following reasons:

-  Some implementations don't support process-shared semaphores. On these systems, specifying a nonzero value for pshared causes sem\_init() to return an error. Linux did not support unnamed process-shared semaphores until kernel 2.6 and the advent of the NPTL threading implementation. (The older LinuxThreads implementation of sem\_init() fails with the error ENOSYS if a nonzero value is specified for pshared.)
-  On implementations that support both process-shared and thread-shared semaphores, specifying which kind of sharing is required may be necessary because the system must take special actions to support the requested sharing. Providing this information may also permit the system to perform optimizations depending on the type of sharing.

The NPTL sem\_init() implementation ignores pshared, since no special action is required for either type of sharing. Nevertheless, portable and future-proof applications should specify an appropriate value for pshared.

> The SUSv3 specification for sem\_init() defines a failure return of –1, but makes no statement about the return value on success. Nevertheless, the manual pages on most modern UNIX implementations document a 0 return on success. (One notable exception is Solaris, where the description of the return value is similar to the SUSv3 specification. However, inspecting the OpenSolaris source code shows that, on that implementation, sem\_init() does return 0 on success.) SUSv4 rectifies the situation, specifying that sem\_init() shall return 0 on success.

There are no permission settings associated with an unnamed semaphore (i.e., sem\_init() has no analog of the mode argument of sem\_open()). Access to an unnamed semaphore is governed by the permissions that are granted to the process for the underlying shared memory region.

SUSv3 specifies that initializing an already initialized unnamed semaphore results in undefined behavior. In other words, we must design our applications so that just one process or thread calls sem\_init() to initialize a semaphore.

As with named semaphores, SUSv3 says that the results are undefined if we attempt to perform operations on a copy of the sem\_t variable whose address is passed as the sem argument of sem\_init(). Operations should always be performed only on the "original" semaphore.

#### **Example program**

In Section 30.1.2, we presented a program (Listing 30-2) that used mutexes to protect a critical section in which two threads accessed the same global variable. The program in [Listing 53-6](#page-44-0) solves the same problem using an unnamed thread-shared semaphore.

<span id="page-44-0"></span>**Listing 53-6:** Using a POSIX unnamed semaphore to protect access to a global variable

––––––––––––––––––––––––––––––––––––––––––––––––––– **psem/thread\_incr\_psem.c** #include <semaphore.h> #include <pthread.h> #include "tlpi\_hdr.h" static int glob = 0; static sem\_t sem; static void \* /\* Loop 'arg' times incrementing 'glob' \*/ threadFunc(void \*arg) { int loops = \*((int \*) arg); int loc, j; for (j = 0; j < loops; j++) { if (sem\_wait(&sem) == -1) errExit("sem\_wait");

```
 loc = glob;
 loc++;
 glob = loc;
 if (sem_post(&sem) == -1)
 errExit("sem_post");
 }
 return NULL;
}
int
main(int argc, char *argv[])
{
 pthread_t t1, t2;
 int loops, s;
 loops = (argc > 1) ? getInt(argv[1], GN_GT_0, "num-loops") : 10000000;
 /* Initialize a thread-shared mutex with the value 1 */
 if (sem_init(&sem, 0, 1) == -1)
 errExit("sem_init");
   /* Create two threads that increment 'glob' */
 s = pthread_create(&t1, NULL, threadFunc, &loops);
 if (s != 0)
 errExitEN(s, "pthread_create");
 s = pthread_create(&t2, NULL, threadFunc, &loops);
 if (s != 0)
 errExitEN(s, "pthread_create");
   /* Wait for threads to terminate */
 s = pthread_join(t1, NULL);
 if (s != 0)
 errExitEN(s, "pthread_join");
 s = pthread_join(t2, NULL);
 if (s != 0)
 errExitEN(s, "pthread_join");
 printf("glob = %d\n", glob);
 exit(EXIT_SUCCESS);
}
––––––––––––––––––––––––––––––––––––––––––––––––––– psem/thread_incr_psem.c
```

## **53.4.2 Destroying an Unnamed Semaphore**

The sem\_destroy() function destroys the semaphore sem, which must be an unnamed semaphore that was previously initialized using sem\_init(). It is safe to destroy a semaphore only if no processes or threads are waiting on it.

```
#include <semaphore.h>
int sem_destroy(sem_t *sem);
                                             Returns 0 on success, or –1 on error
```

After an unnamed semaphore segment has been destroyed with sem\_destroy(), it can be reinitialized with sem\_init().

An unnamed semaphore should be destroyed before its underlying memory is deallocated. For example, if the semaphore is an automatically allocated variable, it should be destroyed before its host function returns. If the semaphore resides in a POSIX shared memory region, then it should be destroyed after all processes have ceased using the semaphore and before the shared memory object is unlinked with shm\_unlink().

On some implementations, omitting calls to sem\_destroy() doesn't cause problems. However, on other implementations, failing to call sem\_destroy() can result in resource leaks. Portable applications should call sem\_destroy() to avoid such problems.

## <span id="page-46-0"></span>**53.5 Comparisons with Other Synchronization Techniques**

In this section, we compare POSIX semaphores with two other synchronization techniques: System V semaphores and mutexes.

#### **POSIX semaphores versus System V semaphores**

POSIX semaphores and System V semaphores can both be used to synchronize the actions of processes. Section [51.2](#page-4-0) listed various advantages of POSIX IPC over System V IPC: the POSIX IPC interface is simpler and more consistent with the traditional UNIX file model, and POSIX IPC objects are reference counted, which simplifies the task of determining when to delete an IPC object. These general advantages also apply to the specific case of POSIX (named) semaphores versus System V semaphores.

POSIX semaphores have the following further advantages over System V semaphores:

-  The POSIX semaphore interface is much simpler than the System V semaphore interface. This simplicity is achieved without loss of functional power.
-  POSIX named semaphores eliminate the initialization problem associated with System V semaphores (Section 47.5).
-  It is easier to associate a POSIX unnamed semaphore with a dynamically allocated memory object: the semaphore can simply be embedded inside the object.
-  In scenarios where there is a high degree of contention for a semaphore (i.e., operations on the semaphore are frequently blocked because another process has set the semaphore to a value that prevents the operation proceeding immediately), then the performance of POSIX semaphores and System V semaphores is similar. However, in cases where there is low contention for a semaphore (i.e., the semaphore's value is such that operations can normally

proceed without blocking), then POSIX semaphores perform considerably better than System V semaphores. (On the systems tested by the author, the difference in performance is more than an order of magnitude; see Exercise 53-4.) POSIX semaphores perform so much better in this case because the way in which they are implemented only requires a system call when contention occurs, whereas System V semaphore operations always require a system call, regardless of contention.

However, POSIX semaphores also have the following disadvantages compared to System V semaphores:

-  POSIX semaphores are somewhat less portable. (On Linux, named semaphores have been supported only since kernel 2.6.)
-  POSIX semaphores don't provide an equivalent of the System V semaphore undo feature. (However, as we noted in Section 47.8, this feature may not be useful in some circumstances.)

#### **POSIX semaphores versus Pthreads mutexes**

POSIX semaphores and Pthreads mutexes can both be used to synchronize the actions of threads within the same process, and their performance is similar. However, mutexes are usually preferable, because the ownership property of mutexes enforces good structuring of code (only the thread that locks a mutex can unlock it). By contrast, one thread can increment a semaphore that was decremented by another thread. This flexibility can lead to poorly structured synchronization designs. (For this reason, semaphores are sometimes referred to as the "gotos" of concurrent programming.)

There is one circumstance in which mutexes can't be used in a multithreaded application and semaphores may therefore be preferable. Because it is async-signalsafe (see Table 21-1, on page 426), the sem\_post() function can be used from within a signal handler to synchronize with another thread. This is not possible with mutexes, because the Pthreads functions for operating on mutexes are not asyncsignal-safe. However, because it is usually preferable to deal with asynchronous signals by accepting them using sigwaitinfo() (or similar), rather than using signal handlers (see Section 33.2.4), this advantage of semaphores over mutexes is seldom required.

## **53.6 Semaphore Limits**

SUSv3 defines two limits applying to semaphores:

SEM\_NSEMS\_MAX

This is the maximum number of POSIX semaphores that a process may have. SUSv3 requires that this limit be at least 256. On Linux, the number of POSIX semaphores is effectively limited only by available memory.

SEM\_VALUE\_MAX

This is the maximum value that a POSIX semaphore may reach. Semaphores may assume any value from 0 up to this limit. SUSv3 requires this limit to be at least 32,767; the Linux implementation allows values up to INT\_MAX (2,147,483,647 on Linux/x86-32).

## **53.7 Summary**

POSIX semaphores allow processes or threads to synchronize their actions. POSIX semaphores come in two types: named and unnamed. A named semaphore is identified by a name, and can be shared by any processes that have permission to open the semaphore. An unnamed semaphore has no name, but processes or threads can share the same semaphore by placing it in a region of memory that they share (e.g., in a POSIX shared memory object for process sharing, or in a global variable for thread sharing).

The POSIX semaphore interface is simpler than the System V semaphore interface. Semaphores are allocated and operated on individually, and the wait and post operations adjust a semaphore's value by one.

POSIX semaphores have a number of advantages over System V semaphores, but they are somewhat less portable. For synchronization within multithreaded applications, mutexes are generally preferred over semaphores.

#### **Further information**

[Stevens, 1999] provides an alternative presentation of POSIX semaphores and shows user-space implementations using various other IPC mechanisms (FIFOs, memory-mapped files, and System V semaphores). [Butenhof, 1996] describes the use of POSIX semaphores in multithreaded applications.

## **53.8 Exercises**

- **53-1.** Rewrite the programs in Listing 48-2 and Listing 48-3 (Section 48.4) as a threaded application, with the two threads passing data to each other via a global buffer, and using POSIX semaphores for synchronization.
- **53-2.** Modify the program in [Listing 53-3](#page-38-0) (psem\_wait.c) to use sem\_timedwait() instead of sem\_wait(). The program should take an additional command-line argument that specifies a (relative) number of seconds to be used as the timeout for the sem\_timedwait() call.
- **53-3.** Devise an implementation of POSIX semaphores using System V semaphores.
- **53-4.** In Section [53.5](#page-46-0), we noted that POSIX semaphores perform much better than System V semaphores in the case where the semaphore is uncontended. Write two programs (one for each semaphore type) to verify this. Each program should simply increment and decrement a semaphore a specified number of times. Compare the times required for the two programs.
